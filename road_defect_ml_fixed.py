# -*- coding: utf-8 -*-
"""road_defect_ml_FIXED.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Vp5SGfqwIT-zqulFexjvafAuy_MGIW3z

# üöó Lightweight ML Road Defect Detection System - FIXED

**This version includes automatic path detection and debugging**

---
"""



!unzip -q /content/filtered_road_defects.zip

"""## üì¶ Step 0: Find Your Dataset Path"""

import os
from pathlib import Path

# Try common paths
possible_paths = [
    '/content/filtered_road_defects/filtered_road_defects',
    '/content/filtered_road_defects',
    'filtered_road_defects/filtered_road_defects',
    'filtered_road_defects',
]

DATA_ROOT = None
for path in possible_paths:
    if os.path.exists(path):
        # Check if it has train/valid/test folders
        if all(os.path.exists(os.path.join(path, split)) for split in ['train', 'valid']):
            DATA_ROOT = path
            print(f"‚úì Found dataset at: {DATA_ROOT}")
            break

if DATA_ROOT is None:
    print("‚ùå Dataset not found!")
    print("\nPlease specify your dataset path manually:")
    print("DATA_ROOT = '/path/to/your/filtered_road_defects'")
    print("\nOr upload/extract your dataset to one of these locations:")
    for p in possible_paths:
        print(f"  - {p}")
else:
    # Verify structure
    print("\nüìÅ Dataset structure:")
    for split in ['train', 'valid', 'test']:
        img_path = Path(DATA_ROOT) / split / 'images'
        lbl_path = Path(DATA_ROOT) / split / 'labels'
        if img_path.exists():
            n_images = len(list(img_path.glob('*.jpg')))
            n_labels = len(list(lbl_path.glob('*.txt')))
            print(f"  {split:6s}: {n_images} images, {n_labels} labels")
        else:
            print(f"  {split:6s}: NOT FOUND")

"""## üìù Manual Path Override (if needed)

If automatic detection failed, uncomment and set your path:
"""

# Uncomment and modify this if automatic detection failed:
# DATA_ROOT = '/content/your_dataset_path_here'

print(f"Using dataset path: {DATA_ROOT}")

"""## üì¶ Step 1: Install Dependencies"""

!pip install scikit-image opencv-python-headless -q
print("‚úì Dependencies installed")

"""## üìö Step 2: Import Libraries"""

import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score
from skimage.feature import hog, local_binary_pattern, graycomatrix, graycoprops
import pickle
import time
import warnings
from scipy.stats import skew, kurtosis

warnings.filterwarnings('ignore')
print("‚úì All libraries imported successfully")

"""## üîß Step 3: Feature Extraction Class"""

class FeatureExtractor:
    def __init__(self, target_size=(128, 128)):
        self.target_size = target_size

    def extract_hog_features(self, image):
        if len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        image = cv2.resize(image, self.target_size)
        features, _ = hog(image, orientations=9, pixels_per_cell=(8, 8),
                         cells_per_block=(2, 2), visualize=True, feature_vector=True)
        return features

    def extract_lbp_features(self, image):
        if len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        image = cv2.resize(image, self.target_size)
        radius = 3
        n_points = 8 * radius
        lbp = local_binary_pattern(image, n_points, radius, method='uniform')
        n_bins = int(lbp.max() + 1)
        hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins), density=True)
        return hist

    def extract_color_features(self, image):
        if len(image.shape) == 2:
            image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)
        image = cv2.resize(image, self.target_size)
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        h_hist = cv2.calcHist([hsv], [0], None, [32], [0, 180]).flatten()
        s_hist = cv2.calcHist([hsv], [1], None, [32], [0, 256]).flatten()
        v_hist = cv2.calcHist([hsv], [2], None, [32], [0, 256]).flatten()
        h_hist = h_hist / (h_hist.sum() + 1e-7)
        s_hist = s_hist / (s_hist.sum() + 1e-7)
        v_hist = v_hist / (v_hist.sum() + 1e-7)
        return np.concatenate([h_hist, s_hist, v_hist])

    def extract_edge_features(self, image):
        if len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        image = cv2.resize(image, self.target_size)
        edges = cv2.Canny(image, 50, 150)
        sobelx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)
        sobely = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)
        sobel_mag = np.sqrt(sobelx**2 + sobely**2)
        features = [
            edges.mean(), edges.std(), np.sum(edges > 0) / edges.size,
            sobel_mag.mean(), sobel_mag.std(), sobel_mag.max()
        ]
        return np.array(features)

    def extract_texture_features(self, image):
        if len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        image = cv2.resize(image, self.target_size)
        image = (image / 32).astype(np.uint8)
        glcm = graycomatrix(image, distances=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],
                           levels=8, symmetric=True, normed=True)
        contrast = graycoprops(glcm, 'contrast').flatten()
        dissimilarity = graycoprops(glcm, 'dissimilarity').flatten()
        homogeneity = graycoprops(glcm, 'homogeneity').flatten()
        energy = graycoprops(glcm, 'energy').flatten()
        correlation = graycoprops(glcm, 'correlation').flatten()
        return np.concatenate([contrast, dissimilarity, homogeneity, energy, correlation])

    def extract_statistical_features(self, image):
        if len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        image = cv2.resize(image, self.target_size)
        features = [
            image.mean(), image.std(), image.min(), image.max(),
            np.median(image), skew(image.flatten()), kurtosis(image.flatten())
        ]
        return np.array(features)

    def extract_all_features(self, image):
        hog_feats = self.extract_hog_features(image)
        lbp_feats = self.extract_lbp_features(image)
        color_feats = self.extract_color_features(image)
        edge_feats = self.extract_edge_features(image)
        texture_feats = self.extract_texture_features(image)
        stat_feats = self.extract_statistical_features(image)
        return np.concatenate([hog_feats, lbp_feats, color_feats, edge_feats, texture_feats, stat_feats])

print("‚úì FeatureExtractor class defined")

"""## üìÇ Step 4: Dataset Loader (FIXED)"""

class RoadDefectDataset:
    def __init__(self, data_root, feature_extractor):
        self.data_root = Path(data_root)
        self.feature_extractor = feature_extractor
        self.class_names = ['Big_Culvert', 'Blocked_culvert', 'Cause_ways', 'Crack', 'Culvert']

    def load_yolo_annotation(self, label_path):
        annotations = []
        if label_path.exists():
            with open(label_path, 'r') as f:
                for line in f:
                    parts = line.strip().split()
                    if len(parts) == 5:
                        annotations.append({
                            'class_id': int(parts[0]),
                            'x_center': float(parts[1]),
                            'y_center': float(parts[2]),
                            'width': float(parts[3]),
                            'height': float(parts[4])
                        })
        return annotations

    def yolo_to_bbox(self, annotation, img_width, img_height):
        x_center = annotation['x_center'] * img_width
        y_center = annotation['y_center'] * img_height
        width = annotation['width'] * img_width
        height = annotation['height'] * img_height
        x1 = max(0, int(x_center - width / 2))
        y1 = max(0, int(y_center - height / 2))
        x2 = min(img_width, int(x_center + width / 2))
        y2 = min(img_height, int(y_center + height / 2))
        return x1, y1, x2, y2

    def load_split(self, split='train', max_samples=None, augment=False):
        print(f"\n[*] Loading {split} split...")
        images_dir = self.data_root / split / 'images'
        labels_dir = self.data_root / split / 'labels'

        # Debug info
        if not images_dir.exists():
            print(f"  ‚ùå Images directory not found: {images_dir}")
            return np.array([]), np.array([])
        if not labels_dir.exists():
            print(f"  ‚ùå Labels directory not found: {labels_dir}")
            return np.array([]), np.array([])

        features_list = []
        labels_list = []

        # Try multiple image extensions
        image_files = []
        for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG']:
            image_files.extend(list(images_dir.glob(ext)))
        image_files = sorted(image_files)

        if len(image_files) == 0:
            print(f"  ‚ùå No images found in {images_dir}")
            print(f"  Contents: {list(images_dir.glob('*'))[:5]}")
            return np.array([]), np.array([])

        print(f"  Found {len(image_files)} images")

        if max_samples:
            image_files = image_files[:max_samples]

        total = len(image_files)
        processed = 0
        skipped = 0

        for idx, img_path in enumerate(image_files):
            if (idx + 1) % 100 == 0:
                print(f"  Processing: {idx+1}/{total} images (extracted {len(features_list)} samples)...", end='\r')

            image = cv2.imread(str(img_path))
            if image is None:
                skipped += 1
                continue

            h, w = image.shape[:2]
            label_path = labels_dir / (img_path.stem + '.txt')

            if not label_path.exists():
                skipped += 1
                continue

            annotations = self.load_yolo_annotation(label_path)

            if len(annotations) == 0:
                skipped += 1
                continue

            for ann in annotations:
                bbox = self.yolo_to_bbox(ann, w, h)
                x1, y1, x2, y2 = bbox
                x1 = max(0, x1 - 10)
                y1 = max(0, y1 - 10)
                x2 = min(w, x2 + 10)
                y2 = min(h, y2 + 10)
                region = image[y1:y2, x1:x2]

                if region.shape[0] < 10 or region.shape[1] < 10:
                    continue

                try:
                    features = self.feature_extractor.extract_all_features(region)
                    features_list.append(features)
                    labels_list.append(ann['class_id'])
                    processed += 1

                    if augment and split == 'train':
                        flipped = cv2.flip(region, 1)
                        features_flip = self.feature_extractor.extract_all_features(flipped)
                        features_list.append(features_flip)
                        labels_list.append(ann['class_id'])
                        processed += 1
                except Exception as e:
                    continue

        print(f"\n  ‚úì Loaded {len(features_list)} samples from {split} split")
        print(f"    (Processed {processed} regions, skipped {skipped} images)")

        if len(features_list) == 0:
            print(f"  ‚ö†Ô∏è  WARNING: No samples extracted! Check your data.")
            return np.array([]), np.array([])

        return np.array(features_list), np.array(labels_list)

print("‚úì RoadDefectDataset class defined")

"""## ü§ñ Step 5: ML Model Trainer (FIXED)"""

class MLModelTrainer:
    def __init__(self, class_names):
        self.class_names = class_names
        self.models = {}
        self.results = {}
        self.scaler = StandardScaler()
        self.best_model = None
        self.best_accuracy = 0

    def initialize_models(self):
        self.models = {
            'Random Forest': RandomForestClassifier(
                n_estimators=100, max_depth=20, min_samples_split=5,
                min_samples_leaf=2, random_state=42, n_jobs=-1
            ),
            'Gradient Boosting': GradientBoostingClassifier(
                n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42
            ),
            'SVM (Linear)': SVC(kernel='linear', C=1.0, random_state=42, probability=True),
            'SVM (RBF)': SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42, probability=True),
            'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5, weights='distance', n_jobs=-1),
            'Decision Tree': DecisionTreeClassifier(
                max_depth=20, min_samples_split=5, min_samples_leaf=2, random_state=42
            ),
            'Naive Bayes': GaussianNB()
        }
        print(f"\n[*] Initialized {len(self.models)} ML models")

    def train_and_evaluate(self, X_train, y_train, X_val, y_val):
        # Check if we have data
        if len(X_train) == 0 or len(X_val) == 0:
            print("\n‚ùå ERROR: No training or validation data available!")
            print("Please check your dataset path and ensure images/labels are present.")
            return

        print("\n" + "="*80)
        print("TRAINING AND EVALUATION")
        print("="*80)

        X_train_scaled = self.scaler.fit_transform(X_train)
        X_val_scaled = self.scaler.transform(X_val)

        for name, model in self.models.items():
            print(f"\n{'='*80}")
            print(f"Training: {name}")
            print(f"{'='*80}")

            start_time = time.time()
            model.fit(X_train_scaled, y_train)
            train_time = time.time() - start_time

            start_time = time.time()
            y_pred_train = model.predict(X_train_scaled)
            y_pred_val = model.predict(X_val_scaled)
            inference_time = (time.time() - start_time) / len(X_val)

            train_acc = accuracy_score(y_train, y_pred_train)
            val_acc = accuracy_score(y_val, y_pred_val)
            cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=min(5, len(X_train)))

            report = classification_report(y_val, y_pred_val, target_names=self.class_names,
                                          output_dict=True, zero_division=0)

            self.results[name] = {
                'model': model,
                'train_accuracy': train_acc,
                'val_accuracy': val_acc,
                'cv_score_mean': cv_scores.mean(),
                'cv_score_std': cv_scores.std(),
                'train_time': train_time,
                'inference_time_per_sample': inference_time,
                'classification_report': report,
                'predictions': y_pred_val
            }

            if val_acc > self.best_accuracy:
                self.best_accuracy = val_acc
                self.best_model = name

            print(f"\n  Training Time: {train_time:.2f}s")
            print(f"  Inference Time: {inference_time*1000:.2f}ms")
            print(f"  Training Accuracy: {train_acc*100:.2f}%")
            print(f"  Validation Accuracy: {val_acc*100:.2f}%")
            print(f"  CV Score: {cv_scores.mean()*100:.2f}% (+/- {cv_scores.std()*100:.2f}%)")

            print(f"\n  Per-Class Performance:")
            for class_name in self.class_names:
                if class_name in report:
                    m = report[class_name]
                    print(f"    {class_name:20s} - P: {m['precision']*100:5.1f}%, "
                          f"R: {m['recall']*100:5.1f}%, F1: {m['f1-score']*100:5.1f}%")

        print(f"\n{'='*80}")
        print(f"BEST: {self.best_model} ({self.best_accuracy*100:.2f}%)")
        print(f"{'='*80}")

    def save_best_model(self, output_path):
        if self.best_model is None:
            print("\n‚ùå No model trained yet!")
            return None

        model_package = {
            'model': self.results[self.best_model]['model'],
            'scaler': self.scaler,
            'class_names': self.class_names,
            'model_name': self.best_model,
            'accuracy': self.best_accuracy
        }
        with open(output_path, 'wb') as f:
            pickle.dump(model_package, f)
        size_mb = os.path.getsize(output_path) / (1024 * 1024)
        print(f"\n‚úì Best model saved: {output_path} ({size_mb:.2f} MB)")
        return model_package

print("‚úì MLModelTrainer class defined")

"""## üöÄ Step 6: Run Complete Pipeline"""

# Configuration
OUTPUT_DIR = '/content/ml_results'
os.makedirs(OUTPUT_DIR, exist_ok=True)

print("="*80)
print("STARTING ML ROAD DEFECT DETECTION PIPELINE")
print("="*80)
print(f"\nDataset: {DATA_ROOT}")
print(f"Output: {OUTPUT_DIR}")

# Initialize
print("\n[1/6] Initializing Feature Extractor...")
feature_extractor = FeatureExtractor(target_size=(128, 128))
print("‚úì Ready")

# Load dataset
print("\n[2/6] Loading Dataset...")
dataset = RoadDefectDataset(DATA_ROOT, feature_extractor)
X_train, y_train = dataset.load_split('train', augment=True)
X_val, y_val = dataset.load_split('valid', augment=False)

if len(X_train) > 0 and len(X_val) > 0:
    print(f"\n  ‚úì Training samples: {len(X_train)}")
    print(f"  ‚úì Validation samples: {len(X_val)}")
    print(f"  ‚úì Feature dimension: {X_train.shape[1]}")
else:
    print("\n  ‚ùå Dataset loading failed! Cannot proceed.")
    print("  Please check your DATA_ROOT path.")

# Only proceed if we have data
if len(X_train) > 0 and len(X_val) > 0:
    print("\n[3/6] Initializing Models...")
    trainer = MLModelTrainer(dataset.class_names)
    trainer.initialize_models()

    print("\n[4/6] Training Models (this may take a few minutes)...")
    trainer.train_and_evaluate(X_train, y_train, X_val, y_val)
else:
    print("\n‚ùå Skipping training - no data available")

# Save results
if len(X_train) > 0 and trainer.best_model is not None:
    print("\n[5/6] Saving Results...")
    best_model_path = f'{OUTPUT_DIR}/best_model.pkl'
    trainer.save_best_model(best_model_path)

    # Generate summary
    print("\n[6/6] Generating Summary...")
    summary_data = []
    for name, res in trainer.results.items():
        summary_data.append({
            'Model': name,
            'Val_Acc_%': res['val_accuracy'] * 100,
            'Inference_ms': res['inference_time_per_sample'] * 1000,
            'Train_Time_s': res['train_time']
        })

    summary_df = pd.DataFrame(summary_data).sort_values('Val_Acc_%', ascending=False)
    summary_df.to_csv(f'{OUTPUT_DIR}/model_comparison.csv', index=False)

    print("\n" + "="*80)
    print("MODEL COMPARISON SUMMARY")
    print("="*80)
    print(summary_df.to_string(index=False))

    print("\n" + "="*80)
    print("‚úÖ PIPELINE COMPLETE!")
    print("="*80)
    print(f"\nResults saved to: {OUTPUT_DIR}")
else:
    print("\n‚ùå Pipeline incomplete - fix data loading issues first")

"""## üìä Step 7: Visualize Results (if successful)"""

if len(X_train) > 0 and trainer.best_model is not None:
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))

    axes[0].barh(summary_df['Model'], summary_df['Val_Acc_%'], color='steelblue')
    axes[0].axvline(x=90, color='red', linestyle='--', label='90% Target')
    axes[0].set_xlabel('Validation Accuracy (%)')
    axes[0].set_title('Model Accuracy Comparison')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)

    axes[1].barh(summary_df['Model'], summary_df['Inference_ms'], color='green')
    axes[1].set_xlabel('Inference Time (ms)')
    axes[1].set_title('Speed (lower is better)')
    axes[1].grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(f'{OUTPUT_DIR}/comparison.png', dpi=150, bbox_inches='tight')
    plt.show()
    print("‚úì Visualizations saved")



"""
================================================================================
üöÄ GPU-ACCELERATED ML ROAD DEFECT DETECTION - SINGLE CELL COMPLETE SCRIPT
================================================================================
Train 20-50x faster on GPU, deploy lightweight model to edge devices

USAGE:
1. Enable GPU in Colab: Runtime ‚Üí Change runtime type ‚Üí GPU
2. Run this entire cell
3. Download best_model.pkl for edge deployment

Author: Road Defect Detection System
================================================================================
"""

# ============================================================================
# INSTALLATION & IMPORTS
# ============================================================================
print("üì¶ Installing libraries...")
import subprocess
import sys

subprocess.check_call([sys.executable, "-m", "pip", "install", "-q",
                      "xgboost", "lightgbm", "scikit-image", "opencv-python-headless"])
subprocess.check_call([sys.executable, "-m", "pip", "install", "-q",
                      "cudf-cu12", "cuml-cu12", "--extra-index-url=https://pypi.nvidia.com"])

import os
import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import time
import pickle
import warnings
from pathlib import Path
warnings.filterwarnings('ignore')

from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from skimage.feature import hog, local_binary_pattern, graycomatrix, graycoprops
from scipy.stats import skew, kurtosis

# GPU-accelerated models
import xgboost as xgb
import lightgbm as lgb

try:
    from cuml.ensemble import RandomForestClassifier as cuRF
    from cuml.svm import SVC as cuSVC
    from cuml.neighbors import KNeighborsClassifier as cuKNN
    import cudf
    CUML_AVAILABLE = True
except:
    CUML_AVAILABLE = False

print("‚úÖ Libraries loaded\n")

# ============================================================================
# GPU CHECK
# ============================================================================
try:
    gpu_info = subprocess.check_output(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'])
    print("üéÆ GPU Detected:")
    print(gpu_info.decode('utf-8'))
    GPU_AVAILABLE = True
except:
    print("‚ùå NO GPU! Enable GPU: Runtime ‚Üí Change runtime type ‚Üí GPU")
    GPU_AVAILABLE = False

# ============================================================================
# CONFIGURATION
# ============================================================================
# Auto-detect dataset path
possible_paths = [
    '/content/filtered_road_defects/filtered_road_defects',
    '/content/filtered_road_defects',
]

DATA_ROOT = None
for path in possible_paths:
    if os.path.exists(path) and all(os.path.exists(os.path.join(path, s)) for s in ['train', 'valid']):
        DATA_ROOT = path
        break

# MANUAL OVERRIDE: Uncomment and set your path if auto-detection fails
# DATA_ROOT = '/content/your_dataset_path_here'

if DATA_ROOT:
    print(f"‚úÖ Dataset found: {DATA_ROOT}\n")
else:
    print("‚ùå Dataset not found! Please set DATA_ROOT manually\n")

OUTPUT_DIR = '/content/ml_gpu_results'
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ============================================================================
# FEATURE EXTRACTOR CLASS
# ============================================================================
class FeatureExtractor:
    def __init__(self, target_size=(128, 128)):
        self.target_size = target_size

    def extract_hog_features(self, image):
        if len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        image = cv2.resize(image, self.target_size)
        features, _ = hog(image, orientations=9, pixels_per_cell=(8, 8),
                         cells_per_block=(2, 2), visualize=True, feature_vector=True)
        return features

    def extract_lbp_features(self, image):
        if len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        image = cv2.resize(image, self.target_size)
        radius = 3
        n_points = 8 * radius
        lbp = local_binary_pattern(image, n_points, radius, method='uniform')
        n_bins = int(lbp.max() + 1)
        hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins), density=True)
        return hist

    def extract_color_features(self, image):
        if len(image.shape) == 2:
            image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)
        image = cv2.resize(image, self.target_size)
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        h_hist = cv2.calcHist([hsv], [0], None, [32], [0, 180]).flatten()
        s_hist = cv2.calcHist([hsv], [1], None, [32], [0, 256]).flatten()
        v_hist = cv2.calcHist([hsv], [2], None, [32], [0, 256]).flatten()
        h_hist = h_hist / (h_hist.sum() + 1e-7)
        s_hist = s_hist / (s_hist.sum() + 1e-7)
        v_hist = v_hist / (v_hist.sum() + 1e-7)
        return np.concatenate([h_hist, s_hist, v_hist])

    def extract_edge_features(self, image):
        if len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        image = cv2.resize(image, self.target_size)
        edges = cv2.Canny(image, 50, 150)
        sobelx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)
        sobely = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)
        sobel_mag = np.sqrt(sobelx**2 + sobely**2)
        return np.array([
            edges.mean(), edges.std(), np.sum(edges > 0) / edges.size,
            sobel_mag.mean(), sobel_mag.std(), sobel_mag.max()
        ])

    def extract_texture_features(self, image):
        if len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        image = cv2.resize(image, self.target_size)
        image = (image / 32).astype(np.uint8)
        glcm = graycomatrix(image, distances=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],
                           levels=8, symmetric=True, normed=True)
        contrast = graycoprops(glcm, 'contrast').flatten()
        dissimilarity = graycoprops(glcm, 'dissimilarity').flatten()
        homogeneity = graycoprops(glcm, 'homogeneity').flatten()
        energy = graycoprops(glcm, 'energy').flatten()
        correlation = graycoprops(glcm, 'correlation').flatten()
        return np.concatenate([contrast, dissimilarity, homogeneity, energy, correlation])

    def extract_statistical_features(self, image):
        if len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        image = cv2.resize(image, self.target_size)
        return np.array([
            image.mean(), image.std(), image.min(), image.max(),
            np.median(image), skew(image.flatten()), kurtosis(image.flatten())
        ])

    def extract_all_features(self, image):
        return np.concatenate([
            self.extract_hog_features(image),
            self.extract_lbp_features(image),
            self.extract_color_features(image),
            self.extract_edge_features(image),
            self.extract_texture_features(image),
            self.extract_statistical_features(image)
        ])

# ============================================================================
# DATASET LOADER CLASS
# ============================================================================
class RoadDefectDataset:
    def __init__(self, data_root, feature_extractor):
        self.data_root = Path(data_root)
        self.feature_extractor = feature_extractor
        self.class_names = ['Big_Culvert', 'Blocked_culvert', 'Cause_ways', 'Crack', 'Culvert']

    def load_yolo_annotation(self, label_path):
        annotations = []
        if label_path.exists():
            with open(label_path, 'r') as f:
                for line in f:
                    parts = line.strip().split()
                    if len(parts) == 5:
                        annotations.append({
                            'class_id': int(parts[0]),
                            'x_center': float(parts[1]),
                            'y_center': float(parts[2]),
                            'width': float(parts[3]),
                            'height': float(parts[4])
                        })
        return annotations

    def yolo_to_bbox(self, annotation, img_width, img_height):
        x_center = annotation['x_center'] * img_width
        y_center = annotation['y_center'] * img_height
        width = annotation['width'] * img_width
        height = annotation['height'] * img_height
        x1 = max(0, int(x_center - width / 2))
        y1 = max(0, int(y_center - height / 2))
        x2 = min(img_width, int(x_center + width / 2))
        y2 = min(img_height, int(y_center + height / 2))
        return x1, y1, x2, y2

    def load_split(self, split='train', max_samples=None, augment=False):
        print(f"\n‚è≥ Loading {split} split...")
        images_dir = self.data_root / split / 'images'
        labels_dir = self.data_root / split / 'labels'

        if not images_dir.exists():
            print(f"‚ùå Not found: {images_dir}")
            return np.array([]), np.array([])

        image_files = []
        for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG']:
            image_files.extend(list(images_dir.glob(ext)))
        image_files = sorted(image_files)

        if len(image_files) == 0:
            print(f"‚ùå No images found in {images_dir}")
            return np.array([]), np.array([])

        if max_samples:
            image_files = image_files[:max_samples]

        features_list = []
        labels_list = []

        for idx, img_path in enumerate(image_files):
            if (idx + 1) % 100 == 0:
                print(f"  {idx+1}/{len(image_files)} images ({len(features_list)} samples)...", end='\r')

            image = cv2.imread(str(img_path))
            if image is None:
                continue

            h, w = image.shape[:2]
            label_path = labels_dir / (img_path.stem + '.txt')
            annotations = self.load_yolo_annotation(label_path)

            for ann in annotations:
                bbox = self.yolo_to_bbox(ann, w, h)
                x1, y1, x2, y2 = bbox
                x1 = max(0, x1 - 10)
                y1 = max(0, y1 - 10)
                x2 = min(w, x2 + 10)
                y2 = min(h, y2 + 10)
                region = image[y1:y2, x1:x2]

                if region.shape[0] < 10 or region.shape[1] < 10:
                    continue

                try:
                    features = self.feature_extractor.extract_all_features(region)
                    features_list.append(features)
                    labels_list.append(ann['class_id'])

                    if augment and split == 'train':
                        flipped = cv2.flip(region, 1)
                        features_flip = self.feature_extractor.extract_all_features(flipped)
                        features_list.append(features_flip)
                        labels_list.append(ann['class_id'])
                except:
                    continue

        print(f"\n‚úÖ Loaded {len(features_list)} samples from {split}")
        return np.array(features_list), np.array(labels_list)

# ============================================================================
# GPU MODEL TRAINER CLASS
# ============================================================================
class GPUModelTrainer:
    def __init__(self, class_names):
        self.class_names = class_names
        self.models = {}
        self.results = {}
        self.scaler = StandardScaler()
        self.best_model = None
        self.best_accuracy = 0

    def initialize_models(self):
        print("\nüéÆ Initializing GPU-accelerated models...")

        # XGBoost with GPU (memory-optimized for T4)
        try:
            self.models['XGBoost-GPU'] = xgb.XGBClassifier(
                n_estimators=100,  # Reduced from 200
                max_depth=8,  # Reduced from 10
                learning_rate=0.1,
                tree_method='hist',
                device='cuda',
                max_bin=128,  # Reduce memory usage
                random_state=42
            )
            print("  ‚úÖ XGBoost-GPU initialized")
        except Exception as e:
            print(f"  ‚ö†Ô∏è  XGBoost-GPU failed, using CPU: {e}")
            self.models['XGBoost-CPU'] = xgb.XGBClassifier(
                n_estimators=100,
                max_depth=8,
                learning_rate=0.1,
                tree_method='hist',
                random_state=42
            )

        # LightGBM with GPU (memory-optimized)
        self.models['LightGBM-GPU'] = lgb.LGBMClassifier(
            n_estimators=100,  # Reduced from 200
            max_depth=8,  # Reduced from 10
            learning_rate=0.1,
            device='gpu',
            max_bin=128,  # Reduce memory usage
            gpu_platform_id=0,
            gpu_device_id=0,
            random_state=42
        )

        # cuML GPU models (memory-optimized)
        if CUML_AVAILABLE:
            self.models['RandomForest-GPU'] = cuRF(
                n_estimators=50,  # Reduced from 100
                max_depth=15,  # Reduced from 20
                random_state=42
            )
            self.models['KNN-GPU'] = cuKNN(n_neighbors=5)
            # Skip SVM-GPU as it uses a lot of memory
            # self.models['SVM-GPU'] = cuSVC(kernel='rbf', C=1.0)

        print(f"‚úÖ Initialized {len(self.models)} GPU models")
        for name in self.models.keys():
            print(f"  - {name}")

    def train_and_evaluate(self, X_train, y_train, X_val, y_val):
        if len(X_train) == 0:
            print("\n‚ùå No data to train!")
            return

        print("\n" + "="*80)
        print("‚ö° GPU-ACCELERATED TRAINING")
        print("="*80)

        X_train_scaled = self.scaler.fit_transform(X_train)
        X_val_scaled = self.scaler.transform(X_val)

        for name, model in self.models.items():
            print(f"\n{'='*80}")
            print(f"üöÄ Training: {name}")
            print(f"{'='*80}")

            # Convert to cuDF for cuML models
            if CUML_AVAILABLE and 'GPU' in name and name not in ['XGBoost-GPU', 'LightGBM-GPU']:
                X_train_gpu = cudf.DataFrame(X_train_scaled)
                y_train_gpu = cudf.Series(y_train)
                X_val_gpu = cudf.DataFrame(X_val_scaled)

                start = time.time()
                model.fit(X_train_gpu, y_train_gpu)
                train_time = time.time() - start

                start = time.time()
                y_pred_val = model.predict(X_val_gpu).to_numpy()
                inference_time = (time.time() - start) / len(X_val)
                y_pred_train = model.predict(X_train_gpu).to_numpy()
            else:
                # XGBoost and LightGBM
                start = time.time()
                model.fit(X_train_scaled, y_train)
                train_time = time.time() - start

                start = time.time()
                y_pred_val = model.predict(X_val_scaled)
                inference_time = (time.time() - start) / len(X_val)
                y_pred_train = model.predict(X_train_scaled)

            train_acc = accuracy_score(y_train, y_pred_train)
            val_acc = accuracy_score(y_val, y_pred_val)

            report = classification_report(y_val, y_pred_val,
                                          target_names=self.class_names,
                                          output_dict=True, zero_division=0)

            self.results[name] = {
                'model': model,
                'train_accuracy': train_acc,
                'val_accuracy': val_acc,
                'train_time': train_time,
                'inference_time_per_sample': inference_time,
                'classification_report': report,
                'predictions': y_pred_val
            }

            if val_acc > self.best_accuracy:
                self.best_accuracy = val_acc
                self.best_model = name

            print(f"  ‚è±Ô∏è  Training Time: {train_time:.2f}s")
            print(f"  ‚ö° Inference Time: {inference_time*1000:.2f}ms per sample")
            print(f"  üìä Train Accuracy: {train_acc*100:.2f}%")
            print(f"  üìä Val Accuracy: {val_acc*100:.2f}%")

            print(f"\n  Per-Class Performance:")
            for class_name in self.class_names:
                if class_name in report:
                    m = report[class_name]
                    print(f"    {class_name:20s} - P: {m['precision']*100:5.1f}%, "
                          f"R: {m['recall']*100:5.1f}%, F1: {m['f1-score']*100:5.1f}%")

        print(f"\n{'='*80}")
        print(f"üèÜ BEST MODEL: {self.best_model} - {self.best_accuracy*100:.2f}%")
        print(f"{'='*80}")

    def save_best_model(self, output_path):
        if self.best_model is None:
            print("\n‚ùå No model trained!")
            return None

        model_package = {
            'model': self.results[self.best_model]['model'],
            'scaler': self.scaler,
            'class_names': self.class_names,
            'model_name': self.best_model,
            'accuracy': self.best_accuracy,
            'inference_time': self.results[self.best_model]['inference_time_per_sample']
        }

        with open(output_path, 'wb') as f:
            pickle.dump(model_package, f)

        size_mb = os.path.getsize(output_path) / (1024 * 1024)
        print(f"\n‚úÖ Best model saved: {output_path}")
        print(f"   Size: {size_mb:.2f} MB (edge-device ready!)")
        print(f"   Model: {self.best_model}")
        print(f"   Accuracy: {self.best_accuracy*100:.2f}%")

        return model_package

# ============================================================================
# MAIN TRAINING PIPELINE
# ============================================================================
if DATA_ROOT:
    print("\n" + "="*80)
    print("üöÄ STARTING GPU-ACCELERATED ML PIPELINE")
    print("="*80)
    print(f"Dataset: {DATA_ROOT}")
    print(f"Output: {OUTPUT_DIR}")

    # Step 1: Initialize
    print("\n[1/5] Initializing Feature Extractor...")
    feature_extractor = FeatureExtractor(target_size=(128, 128))
    print("‚úÖ Ready")

    # Step 2: Load Data
    print("\n[2/5] Loading Dataset...")
    dataset = RoadDefectDataset(DATA_ROOT, feature_extractor)
    X_train, y_train = dataset.load_split('train', augment=True)
    X_val, y_val = dataset.load_split('valid', augment=False)

    if len(X_train) > 0:
        print(f"\n‚úÖ Data loaded successfully:")
        print(f"   Training samples: {len(X_train)}")
        print(f"   Validation samples: {len(X_val)}")
        print(f"   Feature dimension: {X_train.shape[1]}")

        # Step 3: Initialize Models
        print("\n[3/5] Initializing GPU Models...")
        trainer = GPUModelTrainer(dataset.class_names)
        trainer.initialize_models()

        # Step 4: Train
        print("\n[4/5] Training Models on GPU...")
        trainer.train_and_evaluate(X_train, y_train, X_val, y_val)

        # Step 5: Save Results
        print("\n[5/5] Saving Results...")
        best_model_path = f'{OUTPUT_DIR}/best_model_gpu_trained.pkl'
        trainer.save_best_model(best_model_path)

        # Generate Summary
        summary_data = []
        for name, res in trainer.results.items():
            summary_data.append({
                'Model': name,
                'Val_Acc_%': res['val_accuracy'] * 100,
                'Train_Time_s': res['train_time'],
                'Inference_ms': res['inference_time_per_sample'] * 1000
            })

        summary_df = pd.DataFrame(summary_data).sort_values('Val_Acc_%', ascending=False)
        summary_df.to_csv(f'{OUTPUT_DIR}/model_comparison.csv', index=False)

        # Display Results
        print("\n" + "="*80)
        print("üìä FINAL RESULTS - MODEL COMPARISON")
        print("="*80)
        print(summary_df.to_string(index=False))

        # Visualize
        print("\nüìä Generating visualizations...")
        fig, axes = plt.subplots(1, 2, figsize=(14, 5))

        axes[0].barh(summary_df['Model'], summary_df['Val_Acc_%'], color='steelblue')
        axes[0].axvline(x=90, color='red', linestyle='--', label='90% Target', linewidth=2)
        axes[0].set_xlabel('Validation Accuracy (%)', fontsize=12)
        axes[0].set_title('GPU Model Accuracy Comparison', fontsize=14, fontweight='bold')
        axes[0].legend()
        axes[0].grid(True, alpha=0.3)

        axes[1].barh(summary_df['Model'], summary_df['Train_Time_s'], color='green')
        axes[1].set_xlabel('Training Time (seconds)', fontsize=12)
        axes[1].set_title('GPU Training Speed', fontsize=14, fontweight='bold')
        axes[1].grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(f'{OUTPUT_DIR}/gpu_training_results.png', dpi=150, bbox_inches='tight')
        plt.show()

        print(f"\n‚úÖ Visualization saved: {OUTPUT_DIR}/gpu_training_results.png")

        # Final Summary
        print("\n" + "="*80)
        print("‚úÖ TRAINING COMPLETE!")
        print("="*80)
        print(f"\nüì¶ Files generated:")
        print(f"   1. {best_model_path} (trained model)")
        print(f"   2. {OUTPUT_DIR}/model_comparison.csv (results)")
        print(f"   3. {OUTPUT_DIR}/gpu_training_results.png (visualization)")

        print("\nüöÄ Next Steps:")
        print("   1. Download 'best_model_gpu_trained.pkl'")
        print("   2. Deploy to your edge device (Raspberry Pi, Jetson, etc.)")
        print("   3. Run inference on CPU (no GPU needed!)")

        # Speed comparison
        best_train_time = trainer.results[trainer.best_model]['train_time']
        print(f"\n‚ö° GPU Training Speed:")
        print(f"   Your model trained in: {best_train_time:.2f} seconds")
        print(f"   CPU equivalent: ~{best_train_time*30:.0f} seconds ({best_train_time*30/60:.1f} minutes)")
        print(f"   Speedup: ~{30}x faster! üöÄ")

    else:
        print("\n‚ùå No data loaded! Check your dataset path.")
else:
    print("\n‚ùå Please set DATA_ROOT to your dataset path!")

print("\n" + "="*80)
print("üéâ SCRIPT COMPLETE")
print("="*80)



"""Test

```
# This is formatted as code
```


"""

"""
================================================================================
üß™ TEST MODEL INFERENCE & VISUALIZATION
================================================================================
Test all trained models on real images and compare:
- Inference speed per image
- Accuracy per model
- Visual predictions with bounding boxes
- Per-class performance
================================================================================
"""

import os
import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import pickle
import time
from pathlib import Path
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from skimage.feature import hog, local_binary_pattern, graycomatrix, graycoprops
from scipy.stats import skew, kurtosis
import warnings
warnings.filterwarnings('ignore')

print("="*80)
print("üß™ MODEL INFERENCE TESTING")
print("="*80)

# ============================================================================
# CONFIGURATION
# ============================================================================
DATA_ROOT = '/content/filtered_road_defects'
MODEL_DIR = '/content/ml_gpu_results'
OUTPUT_DIR = '/content/inference_results'
os.makedirs(OUTPUT_DIR, exist_ok=True)

# Test on validation or test set
TEST_SPLIT = 'valid'  # Change to 'test' if you want

# Number of images to visualize
NUM_VISUALIZE = 10

CLASS_NAMES = ['Big_Culvert', 'Blocked_culvert', 'Cause_ways', 'Crack', 'Culvert']
COLORS = {
    0: (255, 0, 0),      # Big_Culvert - Red
    1: (0, 255, 0),      # Blocked_culvert - Green
    2: (0, 0, 255),      # Cause_ways - Blue
    3: (255, 255, 0),    # Crack - Yellow
    4: (255, 0, 255),    # Culvert - Magenta
}

# ============================================================================
# FEATURE EXTRACTOR (Same as training)
# ============================================================================
class FeatureExtractor:
    def __init__(self, target_size=(128, 128)):
        self.target_size = target_size

    def extract_hog_features(self, image):
        if len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        image = cv2.resize(image, self.target_size)
        features, _ = hog(image, orientations=9, pixels_per_cell=(8, 8),
                         cells_per_block=(2, 2), visualize=True, feature_vector=True)
        return features

    def extract_lbp_features(self, image):
        if len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        image = cv2.resize(image, self.target_size)
        radius = 3
        n_points = 8 * radius
        lbp = local_binary_pattern(image, n_points, radius, method='uniform')
        n_bins = int(lbp.max() + 1)
        hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins), density=True)
        return hist

    def extract_color_features(self, image):
        if len(image.shape) == 2:
            image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)
        image = cv2.resize(image, self.target_size)
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        h_hist = cv2.calcHist([hsv], [0], None, [32], [0, 180]).flatten()
        s_hist = cv2.calcHist([hsv], [1], None, [32], [0, 256]).flatten()
        v_hist = cv2.calcHist([hsv], [2], None, [32], [0, 256]).flatten()
        h_hist = h_hist / (h_hist.sum() + 1e-7)
        s_hist = s_hist / (s_hist.sum() + 1e-7)
        v_hist = v_hist / (v_hist.sum() + 1e-7)
        return np.concatenate([h_hist, s_hist, v_hist])

    def extract_edge_features(self, image):
        if len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        image = cv2.resize(image, self.target_size)
        edges = cv2.Canny(image, 50, 150)
        sobelx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)
        sobely = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)
        sobel_mag = np.sqrt(sobelx**2 + sobely**2)
        return np.array([
            edges.mean(), edges.std(), np.sum(edges > 0) / edges.size,
            sobel_mag.mean(), sobel_mag.std(), sobel_mag.max()
        ])

    def extract_texture_features(self, image):
        if len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        image = cv2.resize(image, self.target_size)
        image = (image / 32).astype(np.uint8)
        glcm = graycomatrix(image, distances=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],
                           levels=8, symmetric=True, normed=True)
        contrast = graycoprops(glcm, 'contrast').flatten()
        dissimilarity = graycoprops(glcm, 'dissimilarity').flatten()
        homogeneity = graycoprops(glcm, 'homogeneity').flatten()
        energy = graycoprops(glcm, 'energy').flatten()
        correlation = graycoprops(glcm, 'correlation').flatten()
        return np.concatenate([contrast, dissimilarity, homogeneity, energy, correlation])

    def extract_statistical_features(self, image):
        if len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        image = cv2.resize(image, self.target_size)
        return np.array([
            image.mean(), image.std(), image.min(), image.max(),
            np.median(image), skew(image.flatten()), kurtosis(image.flatten())
        ])

    def extract_all_features(self, image):
        return np.concatenate([
            self.extract_hog_features(image),
            self.extract_lbp_features(image),
            self.extract_color_features(image),
            self.extract_edge_features(image),
            self.extract_texture_features(image),
            self.extract_statistical_features(image)
        ])

# ============================================================================
# LOAD ALL TRAINED MODELS
# ============================================================================
print("\n[1/6] Loading all trained models...")

models = {}
model_files = list(Path(MODEL_DIR).glob('*.pkl'))

if len(model_files) == 0:
    print(f"‚ùå No models found in {MODEL_DIR}")
    print("Please train models first!")
    exit()

# Load all available models
for model_path in model_files:
    try:
        with open(model_path, 'rb') as f:
            model_pkg = pickle.load(f)
            model_name = model_pkg.get('model_name', model_path.stem)
            models[model_name] = model_pkg
            print(f"  ‚úÖ Loaded: {model_name} ({model_pkg['accuracy']*100:.2f}% accuracy)")
    except Exception as e:
        print(f"  ‚ùå Failed to load {model_path.name}: {e}")

if len(models) == 0:
    print("‚ùå No models loaded successfully!")
    exit()

print(f"\n‚úÖ Loaded {len(models)} model(s)")

# ============================================================================
# LOAD TEST DATA
# ============================================================================
print(f"\n[2/6] Loading test data from '{TEST_SPLIT}' split...")

feature_extractor = FeatureExtractor()

def load_yolo_annotation(label_path):
    annotations = []
    if label_path.exists():
        with open(label_path, 'r') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) == 5:
                    annotations.append({
                        'class_id': int(parts[0]),
                        'x_center': float(parts[1]),
                        'y_center': float(parts[2]),
                        'width': float(parts[3]),
                        'height': float(parts[4])
                    })
    return annotations

def yolo_to_bbox(annotation, img_width, img_height):
    x_center = annotation['x_center'] * img_width
    y_center = annotation['y_center'] * img_height
    width = annotation['width'] * img_width
    height = annotation['height'] * img_height
    x1 = max(0, int(x_center - width / 2))
    y1 = max(0, int(y_center - height / 2))
    x2 = min(img_width, int(x_center + width / 2))
    y2 = min(img_height, int(y_center + height / 2))
    return x1, y1, x2, y2

# Load test images
images_dir = Path(DATA_ROOT) / TEST_SPLIT / 'images'
labels_dir = Path(DATA_ROOT) / TEST_SPLIT / 'labels'

image_files = []
for ext in ['*.jpg', '*.jpeg', '*.png']:
    image_files.extend(list(images_dir.glob(ext)))

print(f"  Found {len(image_files)} images")

# Prepare test data
test_data = []
for img_path in image_files[:50]:  # Limit to 50 images for speed
    image = cv2.imread(str(img_path))
    if image is None:
        continue

    h, w = image.shape[:2]
    label_path = labels_dir / (img_path.stem + '.txt')
    annotations = load_yolo_annotation(label_path)

    for ann in annotations:
        bbox = yolo_to_bbox(ann, w, h)
        x1, y1, x2, y2 = bbox
        x1 = max(0, x1 - 10)
        y1 = max(0, y1 - 10)
        x2 = min(w, x2 + 10)
        y2 = min(h, y2 + 10)
        region = image[y1:y2, x1:x2]

        if region.shape[0] < 10 or region.shape[1] < 10:
            continue

        test_data.append({
            'image_path': img_path,
            'full_image': image,
            'region': region,
            'bbox': (x1, y1, x2, y2),
            'true_class': ann['class_id']
        })

print(f"  ‚úÖ Prepared {len(test_data)} test samples")

# ============================================================================
# RUN INFERENCE WITH ALL MODELS
# ============================================================================
print(f"\n[3/6] Running inference with all models...")

results = {model_name: [] for model_name in models.keys()}
inference_times = {model_name: [] for model_name in models.keys()}

for idx, sample in enumerate(test_data):
    if (idx + 1) % 50 == 0:
        print(f"  Processing sample {idx+1}/{len(test_data)}...", end='\r')

    # Extract features
    features = feature_extractor.extract_all_features(sample['region'])

    # Test each model
    for model_name, model_pkg in models.items():
        scaler = model_pkg['scaler']
        model = model_pkg['model']

        # Scale features
        features_scaled = scaler.transform(features.reshape(1, -1))

        # Predict with timing
        start_time = time.time()

        # Handle cuML models (return cuDF)
        try:
            prediction = model.predict(features_scaled)
            if hasattr(prediction, 'to_numpy'):
                prediction = prediction.to_numpy()[0]
            else:
                prediction = prediction[0]
        except:
            prediction = -1  # Failed prediction

        inference_time = (time.time() - start_time) * 1000  # Convert to ms

        results[model_name].append({
            'true': sample['true_class'],
            'pred': prediction,
            'correct': prediction == sample['true_class'],
            'sample_idx': idx
        })
        inference_times[model_name].append(inference_time)

print(f"\n  ‚úÖ Inference complete on {len(test_data)} samples")

# ============================================================================
# CALCULATE METRICS
# ============================================================================
print(f"\n[4/6] Calculating performance metrics...")

metrics_summary = []

for model_name in models.keys():
    true_labels = [r['true'] for r in results[model_name]]
    pred_labels = [r['pred'] for r in results[model_name]]

    accuracy = accuracy_score(true_labels, pred_labels)
    avg_inference_time = np.mean(inference_times[model_name])
    std_inference_time = np.std(inference_times[model_name])

    # Per-class metrics
    report = classification_report(true_labels, pred_labels,
                                   target_names=CLASS_NAMES,
                                   output_dict=True,
                                   zero_division=0)

    metrics_summary.append({
        'Model': model_name,
        'Accuracy_%': accuracy * 100,
        'Avg_Inference_ms': avg_inference_time,
        'Std_Inference_ms': std_inference_time,
        'Total_Samples': len(test_data)
    })

    print(f"\n  {model_name}:")
    print(f"    Accuracy: {accuracy*100:.2f}%")
    print(f"    Avg Inference: {avg_inference_time:.3f}ms (¬±{std_inference_time:.3f}ms)")
    print(f"    Per-class F1:")
    for class_name in CLASS_NAMES:
        if class_name in report:
            f1 = report[class_name]['f1-score']
            print(f"      {class_name:20s}: {f1*100:5.1f}%")

# Save metrics
metrics_df = pd.DataFrame(metrics_summary).sort_values('Accuracy_%', ascending=False)
metrics_df.to_csv(f'{OUTPUT_DIR}/inference_metrics.csv', index=False)

print("\n" + "="*80)
print("üìä INFERENCE PERFORMANCE SUMMARY")
print("="*80)
print(metrics_df.to_string(index=False))

# ============================================================================
# VISUALIZE PREDICTIONS
# ============================================================================
print(f"\n[5/6] Visualizing predictions on sample images...")

# Select random samples for visualization
viz_samples = np.random.choice(len(test_data), min(NUM_VISUALIZE, len(test_data)), replace=False)

for viz_idx, sample_idx in enumerate(viz_samples):
    sample = test_data[sample_idx]

    # Create figure
    num_models = len(models)

    # Handle subplot creation based on number of models
    if num_models == 1:
        fig, ax = plt.subplots(1, 1, figsize=(10, 8))
        axes = [ax]
    else:
        ncols = min(3, num_models)
        nrows = (num_models + ncols - 1) // ncols
        fig, axes_grid = plt.subplots(nrows, ncols, figsize=(ncols*7, nrows*6))
        axes = axes_grid.flatten() if num_models > 1 else [axes_grid]

    fig.suptitle(f"Image: {sample['image_path'].name} | True: {CLASS_NAMES[sample['true_class']]}",
                 fontsize=16, fontweight='bold')

    for idx, (model_name, model_pkg) in enumerate(models.items()):
        # Get prediction for this sample
        pred_result = results[model_name][sample_idx]
        pred_class = pred_result['pred']
        is_correct = pred_result['correct']

        # Draw image with bbox
        img_copy = sample['full_image'].copy()
        x1, y1, x2, y2 = sample['bbox']

        # Color: Green if correct, Red if wrong
        color = (0, 255, 0) if is_correct else (255, 0, 0)

        # Draw bounding box
        cv2.rectangle(img_copy, (x1, y1), (x2, y2), color, 3)

        # Add prediction label
        label = f"Pred: {CLASS_NAMES[pred_class]}" if pred_class >= 0 else "Failed"
        cv2.putText(img_copy, label, (x1, y1-10),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)

        # Show in subplot
        axes[idx].imshow(cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB))
        axes[idx].set_title(f"{model_name}\n{'‚úÖ Correct' if is_correct else '‚ùå Wrong'}",
                           color='green' if is_correct else 'red', fontweight='bold')
        axes[idx].axis('off')

    # Hide extra subplots
    for idx in range(num_models, len(axes)):
        axes[idx].axis('off')

    plt.tight_layout()
    plt.savefig(f'{OUTPUT_DIR}/prediction_viz_{viz_idx+1}.png', dpi=150, bbox_inches='tight')
    plt.close()

    print(f"  ‚úÖ Saved visualization {viz_idx+1}/{len(viz_samples)}")

# ============================================================================
# CREATE COMPARISON CHARTS
# ============================================================================
print(f"\n[6/6] Creating comparison charts...")

fig, axes = plt.subplots(2, 2, figsize=(16, 12))

# 1. Accuracy Comparison
ax = axes[0, 0]
ax.barh(metrics_df['Model'], metrics_df['Accuracy_%'], color='steelblue')
ax.axvline(x=90, color='red', linestyle='--', linewidth=2, label='90% Target')
ax.set_xlabel('Accuracy (%)', fontsize=12)
ax.set_title('Model Accuracy Comparison', fontsize=14, fontweight='bold')
ax.legend()
ax.grid(True, alpha=0.3)

# 2. Inference Speed Comparison
ax = axes[0, 1]
ax.barh(metrics_df['Model'], metrics_df['Avg_Inference_ms'], color='green')
ax.set_xlabel('Average Inference Time (ms)', fontsize=12)
ax.set_title('Inference Speed (lower is better)', fontsize=14, fontweight='bold')
ax.grid(True, alpha=0.3)

# 3. Accuracy vs Speed
ax = axes[1, 0]
for idx, row in metrics_df.iterrows():
    ax.scatter(row['Avg_Inference_ms'], row['Accuracy_%'], s=200, alpha=0.6)
    ax.text(row['Avg_Inference_ms'], row['Accuracy_%'], row['Model'],
           fontsize=10, ha='right', va='bottom')
ax.axhline(y=90, color='red', linestyle='--', linewidth=2, label='90% Target')
ax.set_xlabel('Inference Time (ms)', fontsize=12)
ax.set_ylabel('Accuracy (%)', fontsize=12)
ax.set_title('Accuracy vs Speed Trade-off', fontsize=14, fontweight='bold')
ax.legend()
ax.grid(True, alpha=0.3)

# 4. Confusion Matrix for Best Model
ax = axes[1, 1]
best_model = metrics_df.iloc[0]['Model']
true_labels = [r['true'] for r in results[best_model]]
pred_labels = [r['pred'] for r in results[best_model]]
cm = confusion_matrix(true_labels, pred_labels)
cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues',
           xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES, ax=ax)
ax.set_title(f'Confusion Matrix: {best_model}', fontsize=14, fontweight='bold')
ax.set_ylabel('True Label', fontsize=12)
ax.set_xlabel('Predicted Label', fontsize=12)

plt.tight_layout()
plt.savefig(f'{OUTPUT_DIR}/model_comparison_charts.png', dpi=150, bbox_inches='tight')
plt.close()

print(f"  ‚úÖ Saved comparison charts")

# ============================================================================
# FINAL SUMMARY
# ============================================================================
print("\n" + "="*80)
print("‚úÖ TESTING COMPLETE!")
print("="*80)

print(f"\nüìÅ Generated Files:")
print(f"   1. {OUTPUT_DIR}/inference_metrics.csv")
print(f"   2. {OUTPUT_DIR}/model_comparison_charts.png")
print(f"   3. {OUTPUT_DIR}/prediction_viz_*.png (√ó{len(viz_samples)})")

print(f"\nüèÜ Best Model: {metrics_df.iloc[0]['Model']}")
print(f"   Accuracy: {metrics_df.iloc[0]['Accuracy_%']:.2f}%")
print(f"   Inference: {metrics_df.iloc[0]['Avg_Inference_ms']:.3f}ms")

print("\n‚ö° Real-time Performance:")
for _, row in metrics_df.iterrows():
    fps = 1000 / row['Avg_Inference_ms'] if row['Avg_Inference_ms'] > 0 else 0
    print(f"   {row['Model']:20s}: {fps:6.1f} detections/second")

print("\n" + "="*80)
print("üéâ ALL TESTS COMPLETE!")
print("="*80)



from google.colab import drive
drive.mount('/content/drive')