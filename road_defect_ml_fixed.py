# -*- coding: utf-8 -*-
"""road_defect_ml_FIXED.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Vp5SGfqwIT-zqulFexjvafAuy_MGIW3z

# üöó Lightweight ML Road Defect Detection System - FIXED

**This version includes automatic path detection and debugging**

---
"""



!unzip -q /content/filtered_road_defects.zip

"""## üì¶ Step 0: Find Your Dataset Path"""

import os
from pathlib import Path

# Try common paths
possible_paths = [
    '/content/filtered_road_defects/filtered_road_defects',
    '/content/filtered_road_defects',
    'filtered_road_defects/filtered_road_defects',
    'filtered_road_defects',
]

DATA_ROOT = None
for path in possible_paths:
    if os.path.exists(path):
        # Check if it has train/valid/test folders
        if all(os.path.exists(os.path.join(path, split)) for split in ['train', 'valid']):
            DATA_ROOT = path
            print(f"‚úì Found dataset at: {DATA_ROOT}")
            break

if DATA_ROOT is None:
    print("‚ùå Dataset not found!")
    print("\nPlease specify your dataset path manually:")
    print("DATA_ROOT = '/path/to/your/filtered_road_defects'")
    print("\nOr upload/extract your dataset to one of these locations:")
    for p in possible_paths:
        print(f"  - {p}")
else:
    # Verify structure
    print("\nüìÅ Dataset structure:")
    for split in ['train', 'valid', 'test']:
        img_path = Path(DATA_ROOT) / split / 'images'
        lbl_path = Path(DATA_ROOT) / split / 'labels'
        if img_path.exists():
            n_images = len(list(img_path.glob('*.jpg')))
            n_labels = len(list(lbl_path.glob('*.txt')))
            print(f"  {split:6s}: {n_images} images, {n_labels} labels")
        else:
            print(f"  {split:6s}: NOT FOUND")

"""## üìù Manual Path Override (if needed)

If automatic detection failed, uncomment and set your path:
"""

# Uncomment and modify this if automatic detection failed:
# DATA_ROOT = '/content/your_dataset_path_here'

print(f"Using dataset path: {DATA_ROOT}")

"""## üì¶ Step 1: Install Dependencies"""

!pip install scikit-image opencv-python-headless -q
print("‚úì Dependencies installed")

"""## üìö Step 2: Import Libraries"""

import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score
from skimage.feature import hog, local_binary_pattern, graycomatrix, graycoprops
import pickle
import time
import warnings
from scipy.stats import skew, kurtosis

warnings.filterwarnings('ignore')
print("‚úì All libraries imported successfully")

"""## üîß Step 3: Feature Extraction Class"""

class FeatureExtractor:
    def __init__(self, target_size=(128, 128)):
        self.target_size = target_size

    def extract_hog_features(self, image):
        if len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        image = cv2.resize(image, self.target_size)
        features, _ = hog(image, orientations=9, pixels_per_cell=(8, 8),
                         cells_per_block=(2, 2), visualize=True, feature_vector=True)
        return features

    def extract_lbp_features(self, image):
        if len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        image = cv2.resize(image, self.target_size)
        radius = 3
        n_points = 8 * radius
        lbp = local_binary_pattern(image, n_points, radius, method='uniform')
        n_bins = int(lbp.max() + 1)
        hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins), density=True)
        return hist

    def extract_color_features(self, image):
        if len(image.shape) == 2:
            image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)
        image = cv2.resize(image, self.target_size)
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        h_hist = cv2.calcHist([hsv], [0], None, [32], [0, 180]).flatten()
        s_hist = cv2.calcHist([hsv], [1], None, [32], [0, 256]).flatten()
        v_hist = cv2.calcHist([hsv], [2], None, [32], [0, 256]).flatten()
        h_hist = h_hist / (h_hist.sum() + 1e-7)
        s_hist = s_hist / (s_hist.sum() + 1e-7)
        v_hist = v_hist / (v_hist.sum() + 1e-7)
        return np.concatenate([h_hist, s_hist, v_hist])

    def extract_edge_features(self, image):
        if len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        image = cv2.resize(image, self.target_size)
        edges = cv2.Canny(image, 50, 150)
        sobelx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)
        sobely = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)
        sobel_mag = np.sqrt(sobelx**2 + sobely**2)
        features = [
            edges.mean(), edges.std(), np.sum(edges > 0) / edges.size,
            sobel_mag.mean(), sobel_mag.std(), sobel_mag.max()
        ]
        return np.array(features)

    def extract_texture_features(self, image):
        if len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        image = cv2.resize(image, self.target_size)
        image = (image / 32).astype(np.uint8)
        glcm = graycomatrix(image, distances=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],
                           levels=8, symmetric=True, normed=True)
        contrast = graycoprops(glcm, 'contrast').flatten()
        dissimilarity = graycoprops(glcm, 'dissimilarity').flatten()
        homogeneity = graycoprops(glcm, 'homogeneity').flatten()
        energy = graycoprops(glcm, 'energy').flatten()
        correlation = graycoprops(glcm, 'correlation').flatten()
        return np.concatenate([contrast, dissimilarity, homogeneity, energy, correlation])

    def extract_statistical_features(self, image):
        if len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        image = cv2.resize(image, self.target_size)
        features = [
            image.mean(), image.std(), image.min(), image.max(),
            np.median(image), skew(image.flatten()), kurtosis(image.flatten())
        ]
        return np.array(features)

    def extract_all_features(self, image):
        hog_feats = self.extract_hog_features(image)
        lbp_feats = self.extract_lbp_features(image)
        color_feats = self.extract_color_features(image)
        edge_feats = self.extract_edge_features(image)
        texture_feats = self.extract_texture_features(image)
        stat_feats = self.extract_statistical_features(image)
        return np.concatenate([hog_feats, lbp_feats, color_feats, edge_feats, texture_feats, stat_feats])

print("‚úì FeatureExtractor class defined")

"""## üìÇ Step 4: Dataset Loader (FIXED)"""

class RoadDefectDataset:
    def __init__(self, data_root, feature_extractor):
        self.data_root = Path(data_root)
        self.feature_extractor = feature_extractor
        self.class_names = ['Big_Culvert', 'Blocked_culvert', 'Cause_ways', 'Crack', 'Culvert']

    def load_yolo_annotation(self, label_path):
        annotations = []
        if label_path.exists():
            with open(label_path, 'r') as f:
                for line in f:
                    parts = line.strip().split()
                    if len(parts) == 5:
                        annotations.append({
                            'class_id': int(parts[0]),
                            'x_center': float(parts[1]),
                            'y_center': float(parts[2]),
                            'width': float(parts[3]),
                            'height': float(parts[4])
                        })
        return annotations

    def yolo_to_bbox(self, annotation, img_width, img_height):
        x_center = annotation['x_center'] * img_width
        y_center = annotation['y_center'] * img_height
        width = annotation['width'] * img_width
        height = annotation['height'] * img_height
        x1 = max(0, int(x_center - width / 2))
        y1 = max(0, int(y_center - height / 2))
        x2 = min(img_width, int(x_center + width / 2))
        y2 = min(img_height, int(y_center + height / 2))
        return x1, y1, x2, y2

    def load_split(self, split='train', max_samples=None, augment=False):
        print(f"\n[*] Loading {split} split...")
        images_dir = self.data_root / split / 'images'
        labels_dir = self.data_root / split / 'labels'

        # Debug info
        if not images_dir.exists():
            print(f"  ‚ùå Images directory not found: {images_dir}")
            return np.array([]), np.array([])
        if not labels_dir.exists():
            print(f"  ‚ùå Labels directory not found: {labels_dir}")
            return np.array([]), np.array([])

        features_list = []
        labels_list = []

        # Try multiple image extensions
        image_files = []
        for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG']:
            image_files.extend(list(images_dir.glob(ext)))
        image_files = sorted(image_files)

        if len(image_files) == 0:
            print(f"  ‚ùå No images found in {images_dir}")
            print(f"  Contents: {list(images_dir.glob('*'))[:5]}")
            return np.array([]), np.array([])

        print(f"  Found {len(image_files)} images")

        if max_samples:
            image_files = image_files[:max_samples]

        total = len(image_files)
        processed = 0
        skipped = 0

        for idx, img_path in enumerate(image_files):
            if (idx + 1) % 100 == 0:
                print(f"  Processing: {idx+1}/{total} images (extracted {len(features_list)} samples)...", end='\r')

            image = cv2.imread(str(img_path))
            if image is None:
                skipped += 1
                continue

            h, w = image.shape[:2]
            label_path = labels_dir / (img_path.stem + '.txt')

            if not label_path.exists():
                skipped += 1
                continue

            annotations = self.load_yolo_annotation(label_path)

            if len(annotations) == 0:
                skipped += 1
                continue

            for ann in annotations:
                bbox = self.yolo_to_bbox(ann, w, h)
                x1, y1, x2, y2 = bbox
                x1 = max(0, x1 - 10)
                y1 = max(0, y1 - 10)
                x2 = min(w, x2 + 10)
                y2 = min(h, y2 + 10)
                region = image[y1:y2, x1:x2]

                if region.shape[0] < 10 or region.shape[1] < 10:
                    continue

                try:
                    features = self.feature_extractor.extract_all_features(region)
                    features_list.append(features)
                    labels_list.append(ann['class_id'])
                    processed += 1

                    if augment and split == 'train':
                        flipped = cv2.flip(region, 1)
                        features_flip = self.feature_extractor.extract_all_features(flipped)
                        features_list.append(features_flip)
                        labels_list.append(ann['class_id'])
                        processed += 1
                except Exception as e:
                    continue

        print(f"\n  ‚úì Loaded {len(features_list)} samples from {split} split")
        print(f"    (Processed {processed} regions, skipped {skipped} images)")

        if len(features_list) == 0:
            print(f"  ‚ö†Ô∏è  WARNING: No samples extracted! Check your data.")
            return np.array([]), np.array([])

        return np.array(features_list), np.array(labels_list)

print("‚úì RoadDefectDataset class defined")

"""## ü§ñ Step 5: ML Model Trainer (FIXED)"""

class MLModelTrainer:
    def __init__(self, class_names):
        self.class_names = class_names
        self.models = {}
        self.results = {}
        self.scaler = StandardScaler()
        self.best_model = None
        self.best_accuracy = 0

    def initialize_models(self):
        self.models = {
            'Random Forest': RandomForestClassifier(
                n_estimators=100, max_depth=20, min_samples_split=5,
                min_samples_leaf=2, random_state=42, n_jobs=-1
            ),
            'Gradient Boosting': GradientBoostingClassifier(
                n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42
            ),
            'SVM (Linear)': SVC(kernel='linear', C=1.0, random_state=42, probability=True),
            'SVM (RBF)': SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42, probability=True),
            'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5, weights='distance', n_jobs=-1),
            'Decision Tree': DecisionTreeClassifier(
                max_depth=20, min_samples_split=5, min_samples_leaf=2, random_state=42
            ),
            'Naive Bayes': GaussianNB()
        }
        print(f"\n[*] Initialized {len(self.models)} ML models")

    def train_and_evaluate(self, X_train, y_train, X_val, y_val):
        # Check if we have data
        if len(X_train) == 0 or len(X_val) == 0:
            print("\n‚ùå ERROR: No training or validation data available!")
            print("Please check your dataset path and ensure images/labels are present.")
            return

        print("\n" + "="*80)
        print("TRAINING AND EVALUATION")
        print("="*80)

        X_train_scaled = self.scaler.fit_transform(X_train)
        X_val_scaled = self.scaler.transform(X_val)

        for name, model in self.models.items():
            print(f"\n{'='*80}")
            print(f"Training: {name}")
            print(f"{'='*80}")

            start_time = time.time()
            model.fit(X_train_scaled, y_train)
            train_time = time.time() - start_time

            start_time = time.time()
            y_pred_train = model.predict(X_train_scaled)
            y_pred_val = model.predict(X_val_scaled)
            inference_time = (time.time() - start_time) / len(X_val)

            train_acc = accuracy_score(y_train, y_pred_train)
            val_acc = accuracy_score(y_val, y_pred_val)
            cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=min(5, len(X_train)))

            report = classification_report(y_val, y_pred_val, target_names=self.class_names,
                                          output_dict=True, zero_division=0)

            self.results[name] = {
                'model': model,
                'train_accuracy': train_acc,
                'val_accuracy': val_acc,
                'cv_score_mean': cv_scores.mean(),
                'cv_score_std': cv_scores.std(),
                'train_time': train_time,
                'inference_time_per_sample': inference_time,
                'classification_report': report,
                'predictions': y_pred_val
            }

            if val_acc > self.best_accuracy:
                self.best_accuracy = val_acc
                self.best_model = name

            print(f"\n  Training Time: {train_time:.2f}s")
            print(f"  Inference Time: {inference_time*1000:.2f}ms")
            print(f"  Training Accuracy: {train_acc*100:.2f}%")
            print(f"  Validation Accuracy: {val_acc*100:.2f}%")
            print(f"  CV Score: {cv_scores.mean()*100:.2f}% (+/- {cv_scores.std()*100:.2f}%)")

            print(f"\n  Per-Class Performance:")
            for class_name in self.class_names:
                if class_name in report:
                    m = report[class_name]
                    print(f"    {class_name:20s} - P: {m['precision']*100:5.1f}%, "
                          f"R: {m['recall']*100:5.1f}%, F1: {m['f1-score']*100:5.1f}%")

        print(f"\n{'='*80}")
        print(f"BEST: {self.best_model} ({self.best_accuracy*100:.2f}%)")
        print(f"{'='*80}")

    def save_best_model(self, output_path):
        if self.best_model is None:
            print("\n‚ùå No model trained yet!")
            return None

        model_package = {
            'model': self.results[self.best_model]['model'],
            'scaler': self.scaler,
            'class_names': self.class_names,
            'model_name': self.best_model,
            'accuracy': self.best_accuracy
        }
        with open(output_path, 'wb') as f:
            pickle.dump(model_package, f)
        size_mb = os.path.getsize(output_path) / (1024 * 1024)
        print(f"\n‚úì Best model saved: {output_path} ({size_mb:.2f} MB)")
        return model_package

print("‚úì MLModelTrainer class defined")

"""## üöÄ Step 6: Run Complete Pipeline"""

# Configuration
OUTPUT_DIR = '/content/ml_results'
os.makedirs(OUTPUT_DIR, exist_ok=True)

print("="*80)
print("STARTING ML ROAD DEFECT DETECTION PIPELINE")
print("="*80)
print(f"\nDataset: {DATA_ROOT}")
print(f"Output: {OUTPUT_DIR}")

# Initialize
print("\n[1/6] Initializing Feature Extractor...")
feature_extractor = FeatureExtractor(target_size=(128, 128))
print("‚úì Ready")

# Load dataset
print("\n[2/6] Loading Dataset...")
dataset = RoadDefectDataset(DATA_ROOT, feature_extractor)
X_train, y_train = dataset.load_split('train', augment=True)
X_val, y_val = dataset.load_split('valid', augment=False)

if len(X_train) > 0 and len(X_val) > 0:
    print(f"\n  ‚úì Training samples: {len(X_train)}")
    print(f"  ‚úì Validation samples: {len(X_val)}")
    print(f"  ‚úì Feature dimension: {X_train.shape[1]}")
else:
    print("\n  ‚ùå Dataset loading failed! Cannot proceed.")
    print("  Please check your DATA_ROOT path.")

# Only proceed if we have data
if len(X_train) > 0 and len(X_val) > 0:
    print("\n[3/6] Initializing Models...")
    trainer = MLModelTrainer(dataset.class_names)
    trainer.initialize_models()

    print("\n[4/6] Training Models (this may take a few minutes)...")
    trainer.train_and_evaluate(X_train, y_train, X_val, y_val)
else:
    print("\n‚ùå Skipping training - no data available")

# Save results
if len(X_train) > 0 and trainer.best_model is not None:
    print("\n[5/6] Saving Results...")
    best_model_path = f'{OUTPUT_DIR}/best_model.pkl'
    trainer.save_best_model(best_model_path)

    # Generate summary
    print("\n[6/6] Generating Summary...")
    summary_data = []
    for name, res in trainer.results.items():
        summary_data.append({
            'Model': name,
            'Val_Acc_%': res['val_accuracy'] * 100,
            'Inference_ms': res['inference_time_per_sample'] * 1000,
            'Train_Time_s': res['train_time']
        })

    summary_df = pd.DataFrame(summary_data).sort_values('Val_Acc_%', ascending=False)
    summary_df.to_csv(f'{OUTPUT_DIR}/model_comparison.csv', index=False)

    print("\n" + "="*80)
    print("MODEL COMPARISON SUMMARY")
    print("="*80)
    print(summary_df.to_string(index=False))

    print("\n" + "="*80)
    print("‚úÖ PIPELINE COMPLETE!")
    print("="*80)
    print(f"\nResults saved to: {OUTPUT_DIR}")
else:
    print("\n‚ùå Pipeline incomplete - fix data loading issues first")

"""## üìä Step 7: Visualize Results (if successful)"""

if len(X_train) > 0 and trainer.best_model is not None:
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))

    axes[0].barh(summary_df['Model'], summary_df['Val_Acc_%'], color='steelblue')
    axes[0].axvline(x=90, color='red', linestyle='--', label='90% Target')
    axes[0].set_xlabel('Validation Accuracy (%)')
    axes[0].set_title('Model Accuracy Comparison')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)

    axes[1].barh(summary_df['Model'], summary_df['Inference_ms'], color='green')
    axes[1].set_xlabel('Inference Time (ms)')
    axes[1].set_title('Speed (lower is better)')
    axes[1].grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(f'{OUTPUT_DIR}/comparison.png', dpi=150, bbox_inches='tight')
    plt.show()
    print("‚úì Visualizations saved")



"""
================================================================================
üöÄ GPU-ACCELERATED ML ROAD DEFECT DETECTION - SINGLE CELL COMPLETE SCRIPT
================================================================================
Train 20-50x faster on GPU, deploy lightweight model to edge devices

USAGE:
1. Enable GPU in Colab: Runtime ‚Üí Change runtime type ‚Üí GPU
2. Run this entire cell
3. Download best_model.pkl for edge deployment

Author: Road Defect Detection System
================================================================================
"""

# ============================================================================
# INSTALLATION & IMPORTS
# ============================================================================
print("üì¶ Installing libraries...")
import subprocess
import sys

subprocess.check_call([sys.executable, "-m", "pip", "install", "-q",
                      "xgboost", "lightgbm", "scikit-image", "opencv-python-headless"])
subprocess.check_call([sys.executable, "-m", "pip", "install", "-q",
                      "cudf-cu12", "cuml-cu12", "--extra-index-url=https://pypi.nvidia.com"])

import os
import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import time
import pickle
import warnings
from pathlib import Path
warnings.filterwarnings('ignore')

from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from skimage.feature import hog, local_binary_pattern, graycomatrix, graycoprops
from scipy.stats import skew, kurtosis

# GPU-accelerated models
import xgboost as xgb
import lightgbm as lgb

try:
    from cuml.ensemble import RandomForestClassifier as cuRF
    from cuml.svm import SVC as cuSVC
    from cuml.neighbors import KNeighborsClassifier as cuKNN
    import cudf
    CUML_AVAILABLE = True
except:
    CUML_AVAILABLE = False

print("‚úÖ Libraries loaded\n")

# ============================================================================
# GPU CHECK
# ============================================================================
try:
    gpu_info = subprocess.check_output(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'])
    print("üéÆ GPU Detected:")
    print(gpu_info.decode('utf-8'))
    GPU_AVAILABLE = True
except:
    print("‚ùå NO GPU! Enable GPU: Runtime ‚Üí Change runtime type ‚Üí GPU")
    GPU_AVAILABLE = False

# ============================================================================
# CONFIGURATION
# ============================================================================
# Auto-detect dataset path
possible_paths = [
    '/content/filtered_road_defects/filtered_road_defects',
    '/content/filtered_road_defects',
]

DATA_ROOT = None
for path in possible_paths:
    if os.path.exists(path) and all(os.path.exists(os.path.join(path, s)) for s in ['train', 'valid']):
        DATA_ROOT = path
        break

# MANUAL OVERRIDE: Uncomment and set your path if auto-detection fails
# DATA_ROOT = '/content/your_dataset_path_here'

if DATA_ROOT:
    print(f"‚úÖ Dataset found: {DATA_ROOT}\n")
else:
    print("‚ùå Dataset not found! Please set DATA_ROOT manually\n")

OUTPUT_DIR = '/content/ml_gpu_results'
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ============================================================================
# FEATURE EXTRACTOR CLASS
# ============================================================================
class FeatureExtractor:
    def __init__(self, target_size=(128, 128)):
        self.target_size = target_size

    def extract_hog_features(self, image):
        if len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        image = cv2.resize(image, self.target_size)
        features, _ = hog(image, orientations=9, pixels_per_cell=(8, 8),
                         cells_per_block=(2, 2), visualize=True, feature_vector=True)
        return features

    def extract_lbp_features(self, image):
        if len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        image = cv2.resize(image, self.target_size)
        radius = 3
        n_points = 8 * radius
        lbp = local_binary_pattern(image, n_points, radius, method='uniform')
        n_bins = int(lbp.max() + 1)
        hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins), density=True)
        return hist

    def extract_color_features(self, image):
        if len(image.shape) == 2:
            image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)
        image = cv2.resize(image, self.target_size)
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        h_hist = cv2.calcHist([hsv], [0], None, [32], [0, 180]).flatten()
        s_hist = cv2.calcHist([hsv], [1], None, [32], [0, 256]).flatten()
        v_hist = cv2.calcHist([hsv], [2], None, [32], [0, 256]).flatten()
        h_hist = h_hist / (h_hist.sum() + 1e-7)
        s_hist = s_hist / (s_hist.sum() + 1e-7)
        v_hist = v_hist / (v_hist.sum() + 1e-7)
        return np.concatenate([h_hist, s_hist, v_hist])

    def extract_edge_features(self, image):
        if len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        image = cv2.resize(image, self.target_size)
        edges = cv2.Canny(image, 50, 150)
        sobelx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)
        sobely = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)
        sobel_mag = np.sqrt(sobelx**2 + sobely**2)
        return np.array([
            edges.mean(), edges.std(), np.sum(edges > 0) / edges.size,
            sobel_mag.mean(), sobel_mag.std(), sobel_mag.max()
        ])

    def extract_texture_features(self, image):
        if len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        image = cv2.resize(image, self.target_size)
        image = (image / 32).astype(np.uint8)
        glcm = graycomatrix(image, distances=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],
                           levels=8, symmetric=True, normed=True)
        contrast = graycoprops(glcm, 'contrast').flatten()
        dissimilarity = graycoprops(glcm, 'dissimilarity').flatten()
        homogeneity = graycoprops(glcm, 'homogeneity').flatten()
        energy = graycoprops(glcm, 'energy').flatten()
        correlation = graycoprops(glcm, 'correlation').flatten()
        return np.concatenate([contrast, dissimilarity, homogeneity, energy, correlation])

    def extract_statistical_features(self, image):
        if len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        image = cv2.resize(image, self.target_size)
        return np.array([
            image.mean(), image.std(), image.min(), image.max(),
            np.median(image), skew(image.flatten()), kurtosis(image.flatten())
        ])

    def extract_all_features(self, image):
        return np.concatenate([
            self.extract_hog_features(image),
            self.extract_lbp_features(image),
            self.extract_color_features(image),
            self.extract_edge_features(image),
            self.extract_texture_features(image),
            self.extract_statistical_features(image)
        ])

# ============================================================================
# DATASET LOADER CLASS
# ============================================================================
class RoadDefectDataset:
    def __init__(self, data_root, feature_extractor):
        self.data_root = Path(data_root)
        self.feature_extractor = feature_extractor
        self.class_names = ['Big_Culvert', 'Blocked_culvert', 'Cause_ways', 'Crack', 'Culvert']

    def load_yolo_annotation(self, label_path):
        annotations = []
        if label_path.exists():
            with open(label_path, 'r') as f:
                for line in f:
                    parts = line.strip().split()
                    if len(parts) == 5:
                        annotations.append({
                            'class_id': int(parts[0]),
                            'x_center': float(parts[1]),
                            'y_center': float(parts[2]),
                            'width': float(parts[3]),
                            'height': float(parts[4])
                        })
        return annotations

    def yolo_to_bbox(self, annotation, img_width, img_height):
        x_center = annotation['x_center'] * img_width
        y_center = annotation['y_center'] * img_height
        width = annotation['width'] * img_width
        height = annotation['height'] * img_height
        x1 = max(0, int(x_center - width / 2))
        y1 = max(0, int(y_center - height / 2))
        x2 = min(img_width, int(x_center + width / 2))
        y2 = min(img_height, int(y_center + height / 2))
        return x1, y1, x2, y2

    def load_split(self, split='train', max_samples=None, augment=False):
        print(f"\n‚è≥ Loading {split} split...")
        images_dir = self.data_root / split / 'images'
        labels_dir = self.data_root / split / 'labels'

        if not images_dir.exists():
            print(f"‚ùå Not found: {images_dir}")
            return np.array([]), np.array([])

        image_files = []
        for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG']:
            image_files.extend(list(images_dir.glob(ext)))
        image_files = sorted(image_files)

        if len(image_files) == 0:
            print(f"‚ùå No images found in {images_dir}")
            return np.array([]), np.array([])

        if max_samples:
            image_files = image_files[:max_samples]

        features_list = []
        labels_list = []

        for idx, img_path in enumerate(image_files):
            if (idx + 1) % 100 == 0:
                print(f"  {idx+1}/{len(image_files)} images ({len(features_list)} samples)...", end='\r')

            image = cv2.imread(str(img_path))
            if image is None:
                continue

            h, w = image.shape[:2]
            label_path = labels_dir / (img_path.stem + '.txt')
            annotations = self.load_yolo_annotation(label_path)

            for ann in annotations:
                bbox = self.yolo_to_bbox(ann, w, h)
                x1, y1, x2, y2 = bbox
                x1 = max(0, x1 - 10)
                y1 = max(0, y1 - 10)
                x2 = min(w, x2 + 10)
                y2 = min(h, y2 + 10)
                region = image[y1:y2, x1:x2]

                if region.shape[0] < 10 or region.shape[1] < 10:
                    continue

                try:
                    features = self.feature_extractor.extract_all_features(region)
                    features_list.append(features)
                    labels_list.append(ann['class_id'])

                    if augment and split == 'train':
                        flipped = cv2.flip(region, 1)
                        features_flip = self.feature_extractor.extract_all_features(flipped)
                        features_list.append(features_flip)
                        labels_list.append(ann['class_id'])
                except:
                    continue

        print(f"\n‚úÖ Loaded {len(features_list)} samples from {split}")
        return np.array(features_list), np.array(labels_list)

# ============================================================================
# GPU MODEL TRAINER CLASS
# ============================================================================
class GPUModelTrainer:
    def __init__(self, class_names):
        self.class_names = class_names
        self.models = {}
        self.results = {}
        self.scaler = StandardScaler()
        self.best_model = None
        self.best_accuracy = 0

    def initialize_models(self):
        print("\nüéÆ Initializing GPU-accelerated models...")

        # XGBoost with GPU (memory-optimized for T4)
        try:
            self.models['XGBoost-GPU'] = xgb.XGBClassifier(
                n_estimators=100,  # Reduced from 200
                max_depth=8,  # Reduced from 10
                learning_rate=0.1,
                tree_method='hist',
                device='cuda',
                max_bin=128,  # Reduce memory usage
                random_state=42
            )
            print("  ‚úÖ XGBoost-GPU initialized")
        except Exception as e:
            print(f"  ‚ö†Ô∏è  XGBoost-GPU failed, using CPU: {e}")
            self.models['XGBoost-CPU'] = xgb.XGBClassifier(
                n_estimators=100,
                max_depth=8,
                learning_rate=0.1,
                tree_method='hist',
                random_state=42
            )

        # LightGBM with GPU (memory-optimized)
        self.models['LightGBM-GPU'] = lgb.LGBMClassifier(
            n_estimators=100,  # Reduced from 200
            max_depth=8,  # Reduced from 10
            learning_rate=0.1,
            device='gpu',
            max_bin=128,  # Reduce memory usage
            gpu_platform_id=0,
            gpu_device_id=0,
            random_state=42
        )

        # cuML GPU models (memory-optimized)
        if CUML_AVAILABLE:
            self.models['RandomForest-GPU'] = cuRF(
                n_estimators=50,  # Reduced from 100
                max_depth=15,  # Reduced from 20
                random_state=42
            )
            self.models['KNN-GPU'] = cuKNN(n_neighbors=5)
            # Skip SVM-GPU as it uses a lot of memory
            # self.models['SVM-GPU'] = cuSVC(kernel='rbf', C=1.0)

        print(f"‚úÖ Initialized {len(self.models)} GPU models")
        for name in self.models.keys():
            print(f"  - {name}")

    def train_and_evaluate(self, X_train, y_train, X_val, y_val):
        if len(X_train) == 0:
            print("\n‚ùå No data to train!")
            return

        print("\n" + "="*80)
        print("‚ö° GPU-ACCELERATED TRAINING")
        print("="*80)

        X_train_scaled = self.scaler.fit_transform(X_train)
        X_val_scaled = self.scaler.transform(X_val)

        for name, model in self.models.items():
            print(f"\n{'='*80}")
            print(f"üöÄ Training: {name}")
            print(f"{'='*80}")

            # Convert to cuDF for cuML models
            if CUML_AVAILABLE and 'GPU' in name and name not in ['XGBoost-GPU', 'LightGBM-GPU']:
                X_train_gpu = cudf.DataFrame(X_train_scaled)
                y_train_gpu = cudf.Series(y_train)
                X_val_gpu = cudf.DataFrame(X_val_scaled)

                start = time.time()
                model.fit(X_train_gpu, y_train_gpu)
                train_time = time.time() - start

                start = time.time()
                y_pred_val = model.predict(X_val_gpu).to_numpy()
                inference_time = (time.time() - start) / len(X_val)
                y_pred_train = model.predict(X_train_gpu).to_numpy()
            else:
                # XGBoost and LightGBM
                start = time.time()
                model.fit(X_train_scaled, y_train)
                train_time = time.time() - start

                start = time.time()
                y_pred_val = model.predict(X_val_scaled)
                inference_time = (time.time() - start) / len(X_val)
                y_pred_train = model.predict(X_train_scaled)

            train_acc = accuracy_score(y_train, y_pred_train)
            val_acc = accuracy_score(y_val, y_pred_val)

            report = classification_report(y_val, y_pred_val,
                                          target_names=self.class_names,
                                          output_dict=True, zero_division=0)

            self.results[name] = {
                'model': model,
                'train_accuracy': train_acc,
                'val_accuracy': val_acc,
                'train_time': train_time,
                'inference_time_per_sample': inference_time,
                'classification_report': report,
                'predictions': y_pred_val
            }

            if val_acc > self.best_accuracy:
                self.best_accuracy = val_acc
                self.best_model = name

            print(f"  ‚è±Ô∏è  Training Time: {train_time:.2f}s")
            print(f"  ‚ö° Inference Time: {inference_time*1000:.2f}ms per sample")
            print(f"  üìä Train Accuracy: {train_acc*100:.2f}%")
            print(f"  üìä Val Accuracy: {val_acc*100:.2f}%")

            print(f"\n  Per-Class Performance:")
            for class_name in self.class_names:
                if class_name in report:
                    m = report[class_name]
                    print(f"    {class_name:20s} - P: {m['precision']*100:5.1f}%, "
                          f"R: {m['recall']*100:5.1f}%, F1: {m['f1-score']*100:5.1f}%")

        print(f"\n{'='*80}")
        print(f"üèÜ BEST MODEL: {self.best_model} - {self.best_accuracy*100:.2f}%")
        print(f"{'='*80}")

    def save_best_model(self, output_path):
        if self.best_model is None:
            print("\n‚ùå No model trained!")
            return None

        model_package = {
            'model': self.results[self.best_model]['model'],
            'scaler': self.scaler,
            'class_names': self.class_names,
            'model_name': self.best_model,
            'accuracy': self.best_accuracy,
            'inference_time': self.results[self.best_model]['inference_time_per_sample']
        }

        with open(output_path, 'wb') as f:
            pickle.dump(model_package, f)

        size_mb = os.path.getsize(output_path) / (1024 * 1024)
        print(f"\n‚úÖ Best model saved: {output_path}")
        print(f"   Size: {size_mb:.2f} MB (edge-device ready!)")
        print(f"   Model: {self.best_model}")
        print(f"   Accuracy: {self.best_accuracy*100:.2f}%")

        return model_package

# ============================================================================
# MAIN TRAINING PIPELINE
# ============================================================================
if DATA_ROOT:
    print("\n" + "="*80)
    print("üöÄ STARTING GPU-ACCELERATED ML PIPELINE")
    print("="*80)
    print(f"Dataset: {DATA_ROOT}")
    print(f"Output: {OUTPUT_DIR}")

    # Step 1: Initialize
    print("\n[1/5] Initializing Feature Extractor...")
    feature_extractor = FeatureExtractor(target_size=(128, 128))
    print("‚úÖ Ready")

    # Step 2: Load Data
    print("\n[2/5] Loading Dataset...")
    dataset = RoadDefectDataset(DATA_ROOT, feature_extractor)
    X_train, y_train = dataset.load_split('train', augment=True)
    X_val, y_val = dataset.load_split('valid', augment=False)

    if len(X_train) > 0:
        print(f"\n‚úÖ Data loaded successfully:")
        print(f"   Training samples: {len(X_train)}")
        print(f"   Validation samples: {len(X_val)}")
        print(f"   Feature dimension: {X_train.shape[1]}")

        # Step 3: Initialize Models
        print("\n[3/5] Initializing GPU Models...")
        trainer = GPUModelTrainer(dataset.class_names)
        trainer.initialize_models()

        # Step 4: Train
        print("\n[4/5] Training Models on GPU...")
        trainer.train_and_evaluate(X_train, y_train, X_val, y_val)

        # Step 5: Save Results
        print("\n[5/5] Saving Results...")
        best_model_path = f'{OUTPUT_DIR}/best_model_gpu_trained.pkl'
        trainer.save_best_model(best_model_path)

        # Generate Summary
        summary_data = []
        for name, res in trainer.results.items():
            summary_data.append({
                'Model': name,
                'Val_Acc_%': res['val_accuracy'] * 100,
                'Train_Time_s': res['train_time'],
                'Inference_ms': res['inference_time_per_sample'] * 1000
            })

        summary_df = pd.DataFrame(summary_data).sort_values('Val_Acc_%', ascending=False)
        summary_df.to_csv(f'{OUTPUT_DIR}/model_comparison.csv', index=False)

        # Display Results
        print("\n" + "="*80)
        print("üìä FINAL RESULTS - MODEL COMPARISON")
        print("="*80)
        print(summary_df.to_string(index=False))

        # Visualize
        print("\nüìä Generating visualizations...")
        fig, axes = plt.subplots(1, 2, figsize=(14, 5))

        axes[0].barh(summary_df['Model'], summary_df['Val_Acc_%'], color='steelblue')
        axes[0].axvline(x=90, color='red', linestyle='--', label='90% Target', linewidth=2)
        axes[0].set_xlabel('Validation Accuracy (%)', fontsize=12)
        axes[0].set_title('GPU Model Accuracy Comparison', fontsize=14, fontweight='bold')
        axes[0].legend()
        axes[0].grid(True, alpha=0.3)

        axes[1].barh(summary_df['Model'], summary_df['Train_Time_s'], color='green')
        axes[1].set_xlabel('Training Time (seconds)', fontsize=12)
        axes[1].set_title('GPU Training Speed', fontsize=14, fontweight='bold')
        axes[1].grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(f'{OUTPUT_DIR}/gpu_training_results.png', dpi=150, bbox_inches='tight')
        plt.show()

        print(f"\n‚úÖ Visualization saved: {OUTPUT_DIR}/gpu_training_results.png")

        # Final Summary
        print("\n" + "="*80)
        print("‚úÖ TRAINING COMPLETE!")
        print("="*80)
        print(f"\nüì¶ Files generated:")
        print(f"   1. {best_model_path} (trained model)")
        print(f"   2. {OUTPUT_DIR}/model_comparison.csv (results)")
        print(f"   3. {OUTPUT_DIR}/gpu_training_results.png (visualization)")

        print("\nüöÄ Next Steps:")
        print("   1. Download 'best_model_gpu_trained.pkl'")
        print("   2. Deploy to your edge device (Raspberry Pi, Jetson, etc.)")
        print("   3. Run inference on CPU (no GPU needed!)")

        # Speed comparison
        best_train_time = trainer.results[trainer.best_model]['train_time']
        print(f"\n‚ö° GPU Training Speed:")
        print(f"   Your model trained in: {best_train_time:.2f} seconds")
        print(f"   CPU equivalent: ~{best_train_time*30:.0f} seconds ({best_train_time*30/60:.1f} minutes)")
        print(f"   Speedup: ~{30}x faster! üöÄ")

    else:
        print("\n‚ùå No data loaded! Check your dataset path.")
else:
    print("\n‚ùå Please set DATA_ROOT to your dataset path!")

print("\n" + "="*80)
print("üéâ SCRIPT COMPLETE")
print("="*80)



"""Test

```
# This is formatted as code
```


"""

"""
================================================================================
üß™ TEST MODEL INFERENCE & VISUALIZATION
================================================================================
Test all trained models on real images and compare:
- Inference speed per image
- Accuracy per model
- Visual predictions with bounding boxes
- Per-class performance
================================================================================
"""

import os
import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import pickle
import time
from pathlib import Path
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from skimage.feature import hog, local_binary_pattern, graycomatrix, graycoprops
from scipy.stats import skew, kurtosis
import warnings
warnings.filterwarnings('ignore')

print("="*80)
print("üß™ MODEL INFERENCE TESTING")
print("="*80)

# ============================================================================
# CONFIGURATION
# ============================================================================
DATA_ROOT = '/content/filtered_road_defects'
MODEL_DIR = '/content/ml_gpu_results'
OUTPUT_DIR = '/content/inference_results'
os.makedirs(OUTPUT_DIR, exist_ok=True)

# Test on validation or test set
TEST_SPLIT = 'valid'  # Change to 'test' if you want

# Number of images to visualize
NUM_VISUALIZE = 10

CLASS_NAMES = ['Big_Culvert', 'Blocked_culvert', 'Cause_ways', 'Crack', 'Culvert']
COLORS = {
    0: (255, 0, 0),      # Big_Culvert - Red
    1: (0, 255, 0),      # Blocked_culvert - Green
    2: (0, 0, 255),      # Cause_ways - Blue
    3: (255, 255, 0),    # Crack - Yellow
    4: (255, 0, 255),    # Culvert - Magenta
}

# ============================================================================
# FEATURE EXTRACTOR (Same as training)
# ============================================================================
class FeatureExtractor:
    def __init__(self, target_size=(128, 128)):
        self.target_size = target_size

    def extract_hog_features(self, image):
        if len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        image = cv2.resize(image, self.target_size)
        features, _ = hog(image, orientations=9, pixels_per_cell=(8, 8),
                         cells_per_block=(2, 2), visualize=True, feature_vector=True)
        return features

    def extract_lbp_features(self, image):
        if len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        image = cv2.resize(image, self.target_size)
        radius = 3
        n_points = 8 * radius
        lbp = local_binary_pattern(image, n_points, radius, method='uniform')
        n_bins = int(lbp.max() + 1)
        hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins), density=True)
        return hist

    def extract_color_features(self, image):
        if len(image.shape) == 2:
            image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)
        image = cv2.resize(image, self.target_size)
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        h_hist = cv2.calcHist([hsv], [0], None, [32], [0, 180]).flatten()
        s_hist = cv2.calcHist([hsv], [1], None, [32], [0, 256]).flatten()
        v_hist = cv2.calcHist([hsv], [2], None, [32], [0, 256]).flatten()
        h_hist = h_hist / (h_hist.sum() + 1e-7)
        s_hist = s_hist / (s_hist.sum() + 1e-7)
        v_hist = v_hist / (v_hist.sum() + 1e-7)
        return np.concatenate([h_hist, s_hist, v_hist])

    def extract_edge_features(self, image):
        if len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        image = cv2.resize(image, self.target_size)
        edges = cv2.Canny(image, 50, 150)
        sobelx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)
        sobely = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)
        sobel_mag = np.sqrt(sobelx**2 + sobely**2)
        return np.array([
            edges.mean(), edges.std(), np.sum(edges > 0) / edges.size,
            sobel_mag.mean(), sobel_mag.std(), sobel_mag.max()
        ])

    def extract_texture_features(self, image):
        if len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        image = cv2.resize(image, self.target_size)
        image = (image / 32).astype(np.uint8)
        glcm = graycomatrix(image, distances=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],
                           levels=8, symmetric=True, normed=True)
        contrast = graycoprops(glcm, 'contrast').flatten()
        dissimilarity = graycoprops(glcm, 'dissimilarity').flatten()
        homogeneity = graycoprops(glcm, 'homogeneity').flatten()
        energy = graycoprops(glcm, 'energy').flatten()
        correlation = graycoprops(glcm, 'correlation').flatten()
        return np.concatenate([contrast, dissimilarity, homogeneity, energy, correlation])

    def extract_statistical_features(self, image):
        if len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        image = cv2.resize(image, self.target_size)
        return np.array([
            image.mean(), image.std(), image.min(), image.max(),
            np.median(image), skew(image.flatten()), kurtosis(image.flatten())
        ])

    def extract_all_features(self, image):
        return np.concatenate([
            self.extract_hog_features(image),
            self.extract_lbp_features(image),
            self.extract_color_features(image),
            self.extract_edge_features(image),
            self.extract_texture_features(image),
            self.extract_statistical_features(image)
        ])

# ============================================================================
# LOAD ALL TRAINED MODELS
# ============================================================================
print("\n[1/6] Loading all trained models...")

models = {}
model_files = list(Path(MODEL_DIR).glob('*.pkl'))

if len(model_files) == 0:
    print(f"‚ùå No models found in {MODEL_DIR}")
    print("Please train models first!")
    exit()

# Load all available models
for model_path in model_files:
    try:
        with open(model_path, 'rb') as f:
            model_pkg = pickle.load(f)
            model_name = model_pkg.get('model_name', model_path.stem)
            models[model_name] = model_pkg
            print(f"  ‚úÖ Loaded: {model_name} ({model_pkg['accuracy']*100:.2f}% accuracy)")
    except Exception as e:
        print(f"  ‚ùå Failed to load {model_path.name}: {e}")

if len(models) == 0:
    print("‚ùå No models loaded successfully!")
    exit()

print(f"\n‚úÖ Loaded {len(models)} model(s)")

# ============================================================================
# LOAD TEST DATA
# ============================================================================
print(f"\n[2/6] Loading test data from '{TEST_SPLIT}' split...")

feature_extractor = FeatureExtractor()

def load_yolo_annotation(label_path):
    annotations = []
    if label_path.exists():
        with open(label_path, 'r') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) == 5:
                    annotations.append({
                        'class_id': int(parts[0]),
                        'x_center': float(parts[1]),
                        'y_center': float(parts[2]),
                        'width': float(parts[3]),
                        'height': float(parts[4])
                    })
    return annotations

def yolo_to_bbox(annotation, img_width, img_height):
    x_center = annotation['x_center'] * img_width
    y_center = annotation['y_center'] * img_height
    width = annotation['width'] * img_width
    height = annotation['height'] * img_height
    x1 = max(0, int(x_center - width / 2))
    y1 = max(0, int(y_center - height / 2))
    x2 = min(img_width, int(x_center + width / 2))
    y2 = min(img_height, int(y_center + height / 2))
    return x1, y1, x2, y2

# Load test images
images_dir = Path(DATA_ROOT) / TEST_SPLIT / 'images'
labels_dir = Path(DATA_ROOT) / TEST_SPLIT / 'labels'

image_files = []
for ext in ['*.jpg', '*.jpeg', '*.png']:
    image_files.extend(list(images_dir.glob(ext)))

print(f"  Found {len(image_files)} images")

# Prepare test data
test_data = []
for img_path in image_files[:50]:  # Limit to 50 images for speed
    image = cv2.imread(str(img_path))
    if image is None:
        continue

    h, w = image.shape[:2]
    label_path = labels_dir / (img_path.stem + '.txt')
    annotations = load_yolo_annotation(label_path)

    for ann in annotations:
        bbox = yolo_to_bbox(ann, w, h)
        x1, y1, x2, y2 = bbox
        x1 = max(0, x1 - 10)
        y1 = max(0, y1 - 10)
        x2 = min(w, x2 + 10)
        y2 = min(h, y2 + 10)
        region = image[y1:y2, x1:x2]

        if region.shape[0] < 10 or region.shape[1] < 10:
            continue

        test_data.append({
            'image_path': img_path,
            'full_image': image,
            'region': region,
            'bbox': (x1, y1, x2, y2),
            'true_class': ann['class_id']
        })

print(f"  ‚úÖ Prepared {len(test_data)} test samples")

# ============================================================================
# RUN INFERENCE WITH ALL MODELS
# ============================================================================
print(f"\n[3/6] Running inference with all models...")

results = {model_name: [] for model_name in models.keys()}
inference_times = {model_name: [] for model_name in models.keys()}

for idx, sample in enumerate(test_data):
    if (idx + 1) % 50 == 0:
        print(f"  Processing sample {idx+1}/{len(test_data)}...", end='\r')

    # Extract features
    features = feature_extractor.extract_all_features(sample['region'])

    # Test each model
    for model_name, model_pkg in models.items():
        scaler = model_pkg['scaler']
        model = model_pkg['model']

        # Scale features
        features_scaled = scaler.transform(features.reshape(1, -1))

        # Predict with timing
        start_time = time.time()

        # Handle cuML models (return cuDF)
        try:
            prediction = model.predict(features_scaled)
            if hasattr(prediction, 'to_numpy'):
                prediction = prediction.to_numpy()[0]
            else:
                prediction = prediction[0]
        except:
            prediction = -1  # Failed prediction

        inference_time = (time.time() - start_time) * 1000  # Convert to ms

        results[model_name].append({
            'true': sample['true_class'],
            'pred': prediction,
            'correct': prediction == sample['true_class'],
            'sample_idx': idx
        })
        inference_times[model_name].append(inference_time)

print(f"\n  ‚úÖ Inference complete on {len(test_data)} samples")

# ============================================================================
# CALCULATE METRICS
# ============================================================================
print(f"\n[4/6] Calculating performance metrics...")

metrics_summary = []

for model_name in models.keys():
    true_labels = [r['true'] for r in results[model_name]]
    pred_labels = [r['pred'] for r in results[model_name]]

    accuracy = accuracy_score(true_labels, pred_labels)
    avg_inference_time = np.mean(inference_times[model_name])
    std_inference_time = np.std(inference_times[model_name])

    # Per-class metrics
    report = classification_report(true_labels, pred_labels,
                                   target_names=CLASS_NAMES,
                                   output_dict=True,
                                   zero_division=0)

    metrics_summary.append({
        'Model': model_name,
        'Accuracy_%': accuracy * 100,
        'Avg_Inference_ms': avg_inference_time,
        'Std_Inference_ms': std_inference_time,
        'Total_Samples': len(test_data)
    })

    print(f"\n  {model_name}:")
    print(f"    Accuracy: {accuracy*100:.2f}%")
    print(f"    Avg Inference: {avg_inference_time:.3f}ms (¬±{std_inference_time:.3f}ms)")
    print(f"    Per-class F1:")
    for class_name in CLASS_NAMES:
        if class_name in report:
            f1 = report[class_name]['f1-score']
            print(f"      {class_name:20s}: {f1*100:5.1f}%")

# Save metrics
metrics_df = pd.DataFrame(metrics_summary).sort_values('Accuracy_%', ascending=False)
metrics_df.to_csv(f'{OUTPUT_DIR}/inference_metrics.csv', index=False)

print("\n" + "="*80)
print("üìä INFERENCE PERFORMANCE SUMMARY")
print("="*80)
print(metrics_df.to_string(index=False))

# ============================================================================
# VISUALIZE PREDICTIONS
# ============================================================================
print(f"\n[5/6] Visualizing predictions on sample images...")

# Select random samples for visualization
viz_samples = np.random.choice(len(test_data), min(NUM_VISUALIZE, len(test_data)), replace=False)

for viz_idx, sample_idx in enumerate(viz_samples):
    sample = test_data[sample_idx]

    # Create figure
    num_models = len(models)

    # Handle subplot creation based on number of models
    if num_models == 1:
        fig, ax = plt.subplots(1, 1, figsize=(10, 8))
        axes = [ax]
    else:
        ncols = min(3, num_models)
        nrows = (num_models + ncols - 1) // ncols
        fig, axes_grid = plt.subplots(nrows, ncols, figsize=(ncols*7, nrows*6))
        axes = axes_grid.flatten() if num_models > 1 else [axes_grid]

    fig.suptitle(f"Image: {sample['image_path'].name} | True: {CLASS_NAMES[sample['true_class']]}",
                 fontsize=16, fontweight='bold')

    for idx, (model_name, model_pkg) in enumerate(models.items()):
        # Get prediction for this sample
        pred_result = results[model_name][sample_idx]
        pred_class = pred_result['pred']
        is_correct = pred_result['correct']

        # Draw image with bbox
        img_copy = sample['full_image'].copy()
        x1, y1, x2, y2 = sample['bbox']

        # Color: Green if correct, Red if wrong
        color = (0, 255, 0) if is_correct else (255, 0, 0)

        # Draw bounding box
        cv2.rectangle(img_copy, (x1, y1), (x2, y2), color, 3)

        # Add prediction label
        label = f"Pred: {CLASS_NAMES[pred_class]}" if pred_class >= 0 else "Failed"
        cv2.putText(img_copy, label, (x1, y1-10),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)

        # Show in subplot
        axes[idx].imshow(cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB))
        axes[idx].set_title(f"{model_name}\n{'‚úÖ Correct' if is_correct else '‚ùå Wrong'}",
                           color='green' if is_correct else 'red', fontweight='bold')
        axes[idx].axis('off')

    # Hide extra subplots
    for idx in range(num_models, len(axes)):
        axes[idx].axis('off')

    plt.tight_layout()
    plt.savefig(f'{OUTPUT_DIR}/prediction_viz_{viz_idx+1}.png', dpi=150, bbox_inches='tight')
    plt.close()

    print(f"  ‚úÖ Saved visualization {viz_idx+1}/{len(viz_samples)}")

# ============================================================================
# CREATE COMPARISON CHARTS
# ============================================================================
print(f"\n[6/6] Creating comparison charts...")

fig, axes = plt.subplots(2, 2, figsize=(16, 12))

# 1. Accuracy Comparison
ax = axes[0, 0]
ax.barh(metrics_df['Model'], metrics_df['Accuracy_%'], color='steelblue')
ax.axvline(x=90, color='red', linestyle='--', linewidth=2, label='90% Target')
ax.set_xlabel('Accuracy (%)', fontsize=12)
ax.set_title('Model Accuracy Comparison', fontsize=14, fontweight='bold')
ax.legend()
ax.grid(True, alpha=0.3)

# 2. Inference Speed Comparison
ax = axes[0, 1]
ax.barh(metrics_df['Model'], metrics_df['Avg_Inference_ms'], color='green')
ax.set_xlabel('Average Inference Time (ms)', fontsize=12)
ax.set_title('Inference Speed (lower is better)', fontsize=14, fontweight='bold')
ax.grid(True, alpha=0.3)

# 3. Accuracy vs Speed
ax = axes[1, 0]
for idx, row in metrics_df.iterrows():
    ax.scatter(row['Avg_Inference_ms'], row['Accuracy_%'], s=200, alpha=0.6)
    ax.text(row['Avg_Inference_ms'], row['Accuracy_%'], row['Model'],
           fontsize=10, ha='right', va='bottom')
ax.axhline(y=90, color='red', linestyle='--', linewidth=2, label='90% Target')
ax.set_xlabel('Inference Time (ms)', fontsize=12)
ax.set_ylabel('Accuracy (%)', fontsize=12)
ax.set_title('Accuracy vs Speed Trade-off', fontsize=14, fontweight='bold')
ax.legend()
ax.grid(True, alpha=0.3)

# 4. Confusion Matrix for Best Model
ax = axes[1, 1]
best_model = metrics_df.iloc[0]['Model']
true_labels = [r['true'] for r in results[best_model]]
pred_labels = [r['pred'] for r in results[best_model]]
cm = confusion_matrix(true_labels, pred_labels)
cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues',
           xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES, ax=ax)
ax.set_title(f'Confusion Matrix: {best_model}', fontsize=14, fontweight='bold')
ax.set_ylabel('True Label', fontsize=12)
ax.set_xlabel('Predicted Label', fontsize=12)

plt.tight_layout()
plt.savefig(f'{OUTPUT_DIR}/model_comparison_charts.png', dpi=150, bbox_inches='tight')
plt.close()

print(f"  ‚úÖ Saved comparison charts")

# ============================================================================
# FINAL SUMMARY
# ============================================================================
print("\n" + "="*80)
print("‚úÖ TESTING COMPLETE!")
print("="*80)

print(f"\nüìÅ Generated Files:")
print(f"   1. {OUTPUT_DIR}/inference_metrics.csv")
print(f"   2. {OUTPUT_DIR}/model_comparison_charts.png")
print(f"   3. {OUTPUT_DIR}/prediction_viz_*.png (√ó{len(viz_samples)})")

print(f"\nüèÜ Best Model: {metrics_df.iloc[0]['Model']}")
print(f"   Accuracy: {metrics_df.iloc[0]['Accuracy_%']:.2f}%")
print(f"   Inference: {metrics_df.iloc[0]['Avg_Inference_ms']:.3f}ms")

print("\n‚ö° Real-time Performance:")
for _, row in metrics_df.iterrows():
    fps = 1000 / row['Avg_Inference_ms'] if row['Avg_Inference_ms'] > 0 else 0
    print(f"   {row['Model']:20s}: {fps:6.1f} detections/second")

print("\n" + "="*80)
print("üéâ ALL TESTS COMPLETE!")
print("="*80)



from google.colab import drive
drive.mount('/content/drive')

"""10-02-26

"""

#DATA SEGEREGATING

"""
================================================================================
STEP 1: EXPLORE PARENT DATASET - Road_defects.v3i.yolov11.zip
================================================================================
Carefully examine everything before touching or splitting anything
Output saved to Google Drive automatically
================================================================================
"""

import os
import cv2
import zipfile
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import shutil
from pathlib import Path
from collections import defaultdict
from google.colab import drive

# ============================================================================
# MOUNT GOOGLE DRIVE - ALL OUTPUTS SAVED HERE
# ============================================================================
print("üìÇ Mounting Google Drive...")
drive.mount('/content/drive')

OUTPUT_DIR = '/content/drive/MyDrive/Road_Defect_Project/01_Dataset_Exploration'
os.makedirs(OUTPUT_DIR, exist_ok=True)
print(f"‚úÖ Outputs will be saved to: {OUTPUT_DIR}\n")

# ============================================================================
# STEP 1: EXTRACT ZIP
# ============================================================================
ZIP_PATH = '/content/Road_defects.v3i.yolov11.zip'
EXTRACT_PATH = '/content/Road_defects_parent'

print("="*80)
print("STEP 1: EXTRACTING DATASET")
print("="*80)

if not os.path.exists(ZIP_PATH):
    print(f"‚ùå ZIP not found at: {ZIP_PATH}")
    print("Please upload the zip file first!")
    exit()

print(f"‚úÖ Found zip: {ZIP_PATH}")
print(f"   Size: {os.path.getsize(ZIP_PATH) / (1024*1024):.2f} MB")

print(f"\n‚è≥ Extracting to {EXTRACT_PATH}...")
os.makedirs(EXTRACT_PATH, exist_ok=True)

with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:
    all_files = zip_ref.namelist()
    zip_ref.extractall(EXTRACT_PATH)

print(f"‚úÖ Extracted {len(all_files)} files total")

# ============================================================================
# STEP 2: EXPLORE FULL DIRECTORY STRUCTURE
# ============================================================================
print("\n" + "="*80)
print("STEP 2: FULL DIRECTORY STRUCTURE")
print("="*80)

structure_lines = []
for root, dirs, files in os.walk(EXTRACT_PATH):
    # Skip hidden dirs
    dirs[:] = [d for d in dirs if not d.startswith('.')]

    level = root.replace(EXTRACT_PATH, '').count(os.sep)
    indent = '  ' * level
    folder_name = os.path.basename(root)

    n_files = len(files)
    line = f"{indent}üìÅ {folder_name}/ ({n_files} files)"
    print(line)
    structure_lines.append(line)

    # Show file types summary
    if files:
        ext_count = defaultdict(int)
        for f in files:
            ext = Path(f).suffix.lower()
            ext_count[ext] += 1

        sub_indent = '  ' * (level + 1)
        for ext, count in sorted(ext_count.items()):
            line = f"{sub_indent}üìÑ {ext if ext else 'no ext'}: {count} files"
            print(line)
            structure_lines.append(line)

# Save structure to file
with open(f'{OUTPUT_DIR}/directory_structure.txt', 'w') as f:
    f.write('\n'.join(structure_lines))
print(f"\n‚úÖ Structure saved to Drive")

# ============================================================================
# STEP 3: FIND AND READ CONFIG FILES
# ============================================================================
print("\n" + "="*80)
print("STEP 3: CONFIG & METADATA FILES")
print("="*80)

# Find all yaml, txt config files
config_files = []
for ext in ['*.yaml', '*.yml', '*.txt', '*.json', '*.md']:
    config_files.extend(list(Path(EXTRACT_PATH).rglob(ext)))

# Filter out label txt files
config_files = [f for f in config_files if 'labels' not in str(f).lower()
                or f.name in ['README.md', 'data.yaml', 'dataset.yaml']]

print(f"\nFound {len(config_files)} config/meta files:")

config_content = {}
for cfg_path in config_files:
    print(f"\n{'='*60}")
    print(f"üìÑ {cfg_path.name} ‚Äî {cfg_path}")
    print(f"{'='*60}")

    try:
        with open(cfg_path, 'r') as f:
            content = f.read()
            print(content)
            config_content[cfg_path.name] = content
    except:
        print("  (Could not read file)")

# Save configs
with open(f'{OUTPUT_DIR}/config_files_content.txt', 'w') as f:
    for name, content in config_content.items():
        f.write(f"\n{'='*60}\n{name}\n{'='*60}\n{content}\n")
print(f"\n‚úÖ Config content saved to Drive")

# ============================================================================
# STEP 4: ANALYZE ALL LABEL FILES
# ============================================================================
print("\n" + "="*80)
print("STEP 4: ANALYZING ALL LABEL FILES")
print("="*80)

label_files = list(Path(EXTRACT_PATH).rglob('*.txt'))
label_files = [f for f in label_files if 'labels' in str(f).lower()]

print(f"Found {len(label_files)} label files")

all_annotations = []
class_counts_per_split = defaultdict(lambda: defaultdict(int))

for label_path in label_files:
    # Determine split from path
    parts = label_path.parts
    split = 'unknown'
    for part in parts:
        if part.lower() in ['train', 'valid', 'test', 'validation']:
            split = part.lower()
            break

    # Read annotations
    try:
        with open(label_path, 'r') as f:
            for line in f:
                parts_line = line.strip().split()
                if len(parts_line) >= 5:
                    class_id = int(parts_line[0])
                    x_center = float(parts_line[1])
                    y_center = float(parts_line[2])
                    width = float(parts_line[3])
                    height = float(parts_line[4])

                    all_annotations.append({
                        'split': split,
                        'label_file': label_path.name,
                        'class_id': class_id,
                        'x_center': x_center,
                        'y_center': y_center,
                        'width': width,
                        'height': height,
                        'area': width * height
                    })
                    class_counts_per_split[split][class_id] += 1
    except:
        continue

df_annotations = pd.DataFrame(all_annotations)

print(f"\n‚úÖ Total annotations found: {len(df_annotations)}")
print(f"   Unique class IDs: {sorted(df_annotations['class_id'].unique())}")
print(f"   Splits found: {df_annotations['split'].unique()}")

# ============================================================================
# STEP 5: CLASS DISTRIBUTION ANALYSIS
# ============================================================================
print("\n" + "="*80)
print("STEP 5: CLASS DISTRIBUTION")
print("="*80)

# Try to get class names from yaml
class_names = {}
yaml_files = list(Path(EXTRACT_PATH).rglob('*.yaml'))

for yaml_path in yaml_files:
    try:
        with open(yaml_path, 'r') as f:
            content = f.read()
            # Parse class names
            if 'names' in content:
                lines = content.split('\n')
                reading_names = False
                for line in lines:
                    if 'names:' in line:
                        reading_names = True
                        # Check if inline: names: ['class1', 'class2']
                        if '[' in line:
                            names_str = line.split('names:')[1].strip()
                            names_str = names_str.strip("[]'\" ")
                            names = [n.strip().strip("'\"") for n in names_str.split(',')]
                            for i, name in enumerate(names):
                                if name:
                                    class_names[i] = name
                            reading_names = False
                        continue
                    if reading_names and line.strip().startswith('-'):
                        name = line.strip().lstrip('- ').strip().strip("'\"")
                        if name:
                            idx = len(class_names)
                            class_names[idx] = name
                    elif reading_names and line.strip() and not line.strip().startswith('-') and ':' not in line:
                        reading_names = False
        if class_names:
            print(f"‚úÖ Class names from: {yaml_path.name}")
            break
    except:
        continue

if not class_names:
    # Default names based on known dataset
    class_names = {
        0: 'Big_Culvert',
        1: 'Blocked_culvert',
        2: 'Cause_ways',
        3: 'Crack',
        4: 'Culvert'
    }
    print("‚ö†Ô∏è  Using default class names")

print(f"\nüìã Classes detected:")
for idx, name in class_names.items():
    print(f"   Class {idx}: {name}")

# Per split distribution
print(f"\nüìä Distribution per split:")
split_summary = []
for split in sorted(df_annotations['split'].unique()):
    split_df = df_annotations[df_annotations['split'] == split]
    print(f"\n  {split.upper()}:")

    n_images = split_df['label_file'].nunique()
    print(f"    Total images with labels: {n_images}")
    print(f"    Total annotations: {len(split_df)}")
    print(f"    Avg annotations per image: {len(split_df)/n_images:.2f}")

    for class_id in sorted(split_df['class_id'].unique()):
        class_df = split_df[split_df['class_id'] == class_id]
        class_name = class_names.get(class_id, f'Class_{class_id}')
        pct = len(class_df) / len(split_df) * 100
        print(f"    {class_name:20s}: {len(class_df):5d} ({pct:.1f}%)")
        split_summary.append({
            'split': split,
            'class_id': class_id,
            'class_name': class_name,
            'count': len(class_df),
            'percentage': pct
        })

# Save distribution
split_df_summary = pd.DataFrame(split_summary)
split_df_summary.to_csv(f'{OUTPUT_DIR}/class_distribution.csv', index=False)
print(f"\n‚úÖ Distribution saved to Drive")

# ============================================================================
# STEP 6: SAMPLE IMAGE ANALYSIS
# ============================================================================
print("\n" + "="*80)
print("STEP 6: IMAGE PROPERTIES ANALYSIS")
print("="*80)

image_files = list(Path(EXTRACT_PATH).rglob('*.jpg'))
image_files += list(Path(EXTRACT_PATH).rglob('*.png'))
image_files += list(Path(EXTRACT_PATH).rglob('*.jpeg'))

print(f"Total images found: {len(image_files)}")

# Sample 50 images for analysis
sample_images = image_files[:50]
widths, heights, channels_list = [], [], []

for img_path in sample_images:
    img = cv2.imread(str(img_path))
    if img is not None:
        h, w, c = img.shape
        widths.append(w)
        heights.append(h)
        channels_list.append(c)

if widths:
    print(f"\nüìê Image Dimensions (from {len(widths)} samples):")
    print(f"   Width:  min={min(widths)}, max={max(widths)}, avg={np.mean(widths):.0f}")
    print(f"   Height: min={min(heights)}, max={max(heights)}, avg={np.mean(heights):.0f}")
    print(f"   Channels: {set(channels_list)}")

# ============================================================================
# STEP 7: VISUALIZATION
# ============================================================================
print("\n" + "="*80)
print("STEP 7: GENERATING VISUALIZATIONS")
print("="*80)

# Plot 1: Class distribution
fig, axes = plt.subplots(1, 2, figsize=(16, 6))
fig.suptitle('Road Defects Dataset ‚Äî Class Distribution', fontsize=16, fontweight='bold')

colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7']

# Overall distribution
class_totals = df_annotations.groupby('class_id').size()
class_labels = [class_names.get(i, f'Class_{i}') for i in class_totals.index]

axes[0].bar(class_labels, class_totals.values, color=colors[:len(class_totals)])
axes[0].set_title('Total Annotations per Class', fontweight='bold')
axes[0].set_xlabel('Class')
axes[0].set_ylabel('Count')
axes[0].tick_params(axis='x', rotation=30)
for i, v in enumerate(class_totals.values):
    axes[0].text(i, v + 10, str(v), ha='center', fontweight='bold')
axes[0].grid(True, alpha=0.3)

# Per split distribution
splits = sorted(df_annotations['split'].unique())
x = np.arange(len(class_names))
width = 0.8 / len(splits)

for i, split in enumerate(splits):
    split_data = df_annotations[df_annotations['split'] == split]
    counts = [len(split_data[split_data['class_id'] == cid]) for cid in sorted(class_names.keys())]
    axes[1].bar(x + i * width, counts, width, label=split, alpha=0.8)

axes[1].set_title('Distribution per Split', fontweight='bold')
axes[1].set_xlabel('Class')
axes[1].set_ylabel('Count')
axes[1].set_xticks(x + width * (len(splits)-1) / 2)
axes[1].set_xticklabels([class_names[i] for i in sorted(class_names.keys())], rotation=30)
axes[1].legend()
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig(f'{OUTPUT_DIR}/class_distribution.png', dpi=150, bbox_inches='tight')
plt.close()
print("‚úÖ Distribution chart saved")

# Plot 2: Sample images with annotations
print("\n‚è≥ Generating sample image visualizations...")

fig, axes = plt.subplots(3, 4, figsize=(20, 15))
fig.suptitle('Sample Images with Annotations', fontsize=16, fontweight='bold')
axes = axes.flatten()

sample_count = 0
for img_path in image_files:
    if sample_count >= 12:
        break

    # Find corresponding label
    label_path = None
    for possible in [
        img_path.parent.parent / 'labels' / (img_path.stem + '.txt'),
        img_path.parent / (img_path.stem + '.txt')
    ]:
        if possible.exists():
            label_path = possible
            break

    if label_path is None:
        continue

    img = cv2.imread(str(img_path))
    if img is None:
        continue

    h, w = img.shape[:2]
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # Draw annotations
    with open(label_path, 'r') as f:
        for line in f:
            parts = line.strip().split()
            if len(parts) >= 5:
                cid = int(parts[0])
                xc, yc = float(parts[1]) * w, float(parts[2]) * h
                bw, bh = float(parts[3]) * w, float(parts[4]) * h
                x1 = int(xc - bw/2)
                y1 = int(yc - bh/2)
                x2 = int(xc + bw/2)
                y2 = int(yc + bh/2)

                color_map = [(255,0,0), (0,255,0), (0,0,255), (255,255,0), (255,0,255)]
                color = color_map[cid % len(color_map)]

                cv2.rectangle(img_rgb, (x1, y1), (x2, y2), color, 2)
                label_text = class_names.get(cid, str(cid))
                cv2.putText(img_rgb, label_text, (x1, max(0, y1-5)),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)

    axes[sample_count].imshow(img_rgb)
    axes[sample_count].set_title(img_path.name[:30], fontsize=8)
    axes[sample_count].axis('off')
    sample_count += 1

for idx in range(sample_count, len(axes)):
    axes[idx].axis('off')

plt.tight_layout()
plt.savefig(f'{OUTPUT_DIR}/sample_images_with_annotations.png', dpi=150, bbox_inches='tight')
plt.close()
print("‚úÖ Sample visualization saved")

# ============================================================================
# STEP 8: FINAL SUMMARY
# ============================================================================
print("\n" + "="*80)
print("DATASET EXPLORATION COMPLETE ‚Äî FULL SUMMARY")
print("="*80)

print(f"\nüìÅ Dataset Location: {EXTRACT_PATH}")
print(f"\nüìä Overview:")
print(f"   Total images:      {len(image_files)}")
print(f"   Total annotations: {len(df_annotations)}")
print(f"   Total classes:     {len(class_names)}")
print(f"   Splits:            {list(df_annotations['split'].unique())}")

print(f"\nüìã Classes:")
for idx, name in class_names.items():
    total = len(df_annotations[df_annotations['class_id'] == idx])
    print(f"   Class {idx}: {name:20s} ‚Äî {total} annotations")

print(f"\nüíæ All outputs saved to Google Drive:")
print(f"   üìÑ directory_structure.txt")
print(f"   üìÑ config_files_content.txt")
print(f"   üìÑ class_distribution.csv")
print(f"   üìä class_distribution.png")
print(f"   üìä sample_images_with_annotations.png")

print(f"\n‚úÖ Ready for next step: Split dataset by class!")
print("="*80)

"""DATA SPLITTER"""

"""
================================================================================
STEP 2: SPLIT DATASET BY CLASS ‚Äî One Dataset Per Class (Binary: Yes/No)
================================================================================
Parent Dataset: /content/Road_defects_parent
Strategy:
  - For each class: create POSITIVE samples (has this class) + NEGATIVE samples
  - Maintain train/valid/test splits
  - Handle class imbalance intelligently
  - Save everything to Google Drive
================================================================================
"""

import os
import cv2
import shutil
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from pathlib import Path
from collections import defaultdict
from google.colab import drive

# ============================================================================
# MOUNT DRIVE
# ============================================================================
print("üìÇ Mounting Google Drive...")
drive.mount('/content/drive')

PARENT_DATA  = '/content/Road_defects_parent'
OUTPUT_BASE  = '/content/drive/MyDrive/Road_Defect_Project/02_Per_Class_Datasets'
WORKING_DIR  = '/content/per_class_datasets'  # local working copy

os.makedirs(OUTPUT_BASE, exist_ok=True)
os.makedirs(WORKING_DIR, exist_ok=True)

print(f"‚úÖ Parent data: {PARENT_DATA}")
print(f"‚úÖ Drive output: {OUTPUT_BASE}")

# ============================================================================
# CONFIGURATION
# ============================================================================
CLASS_NAMES = {
    0:  'Big_Culvert',
    1:  'Blocked_culvert',
    2:  'Cause_ways',
    3:  'Crack',
    4:  'Culvert',
    5:  'Damaged_surface_layer',
    6:  'Drainage_cover',
    7:  'Edge_breaking',
    8:  'Guard_stone',
    9:  'Not_painted_gs',
    10: 'Not_whitewashed',
    11: 'Patching',
    12: 'Ravelling',
    13: 'km_stone',
    14: 'pothole'
}

SPLITS = ['train', 'valid', 'test']

# Minimum samples needed to create a usable binary dataset
MIN_POSITIVE_SAMPLES = 30

# ============================================================================
# HELPER FUNCTIONS
# ============================================================================
def load_annotations(label_path):
    """Load YOLO annotations from a label file"""
    annotations = []
    if Path(label_path).exists():
        with open(label_path, 'r') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) >= 5:
                    annotations.append({
                        'class_id': int(parts[0]),
                        'x_center': float(parts[1]),
                        'y_center': float(parts[2]),
                        'width':    float(parts[3]),
                        'height':   float(parts[4]),
                        'raw':      line.strip()
                    })
    return annotations


def write_annotations(annotations, output_path):
    """Write YOLO annotations to file"""
    with open(output_path, 'w') as f:
        for ann in annotations:
            f.write(ann['raw'] + '\n')


def write_binary_annotations(annotations, target_class_id, output_path):
    """
    Write annotations for binary classification:
    - Keep only target class, remap to class 0 (POSITIVE)
    - All other classes removed (we only care about target class bbox)
    """
    target_anns = [a for a in annotations if a['class_id'] == target_class_id]
    with open(output_path, 'w') as f:
        for ann in target_anns:
            # Remap class_id to 0 for binary: 0 = this defect exists
            f.write(f"0 {ann['x_center']} {ann['y_center']} {ann['width']} {ann['height']}\n")


def create_data_yaml(class_name, dataset_path, output_path):
    """Create data.yaml for binary dataset"""
    yaml_content = f"""train: {dataset_path}/train/images
val: {dataset_path}/valid/images
test: {dataset_path}/test/images

nc: 1
names: ['{class_name}']

# Binary detector: detects only '{class_name}'
# 0 = {class_name} present
"""
    with open(output_path, 'w') as f:
        f.write(yaml_content)

# ============================================================================
# STEP 1: SCAN ALL IMAGES AND BUILD INDEX
# ============================================================================
print("\n" + "="*80)
print("STEP 1: SCANNING ALL IMAGES")
print("="*80)

# Build a complete index of all images and their annotations
image_index = defaultdict(dict)

for split in SPLITS:
    images_dir = Path(PARENT_DATA) / split / 'images'
    labels_dir = Path(PARENT_DATA) / split / 'labels'

    if not images_dir.exists():
        print(f"  ‚ö†Ô∏è  Split '{split}' not found, skipping")
        continue

    img_files = list(images_dir.glob('*.jpg')) + \
                list(images_dir.glob('*.jpeg')) + \
                list(images_dir.glob('*.png'))

    for img_path in img_files:
        label_path = labels_dir / (img_path.stem + '.txt')
        annotations = load_annotations(label_path)
        classes_in_image = set(a['class_id'] for a in annotations)

        image_index[split][img_path.stem] = {
            'img_path':    img_path,
            'label_path':  label_path,
            'annotations': annotations,
            'classes':     classes_in_image
        }

    print(f"  ‚úÖ {split:6s}: {len(image_index[split])} images indexed")

# ============================================================================
# STEP 2: ANALYZE WHAT WE HAVE PER CLASS
# ============================================================================
print("\n" + "="*80)
print("STEP 2: PER-CLASS AVAILABILITY ANALYSIS")
print("="*80)

class_analysis = {}

for class_id, class_name in CLASS_NAMES.items():
    analysis = {}
    for split in SPLITS:
        positive_imgs = [
            stem for stem, info in image_index[split].items()
            if class_id in info['classes']
        ]
        negative_imgs = [
            stem for stem, info in image_index[split].items()
            if class_id not in info['classes']
        ]
        analysis[split] = {
            'positive': positive_imgs,
            'negative': negative_imgs,
            'n_positive': len(positive_imgs),
            'n_negative': len(negative_imgs)
        }

    total_positive = sum(analysis[s]['n_positive'] for s in SPLITS)
    feasible = total_positive >= MIN_POSITIVE_SAMPLES

    class_analysis[class_id] = {
        'name': class_name,
        'splits': analysis,
        'total_positive': total_positive,
        'feasible': feasible
    }

    status = "‚úÖ" if feasible else "‚ö†Ô∏è "
    print(f"  {status} Class {class_id:2d}: {class_name:25s} | "
          f"Train: {analysis['train']['n_positive']:4d}+ "
          f"{analysis['train']['n_negative']:4d}- | "
          f"Valid: {analysis['valid']['n_positive']:3d}+ "
          f"{analysis['valid']['n_negative']:3d}- | "
          f"Total+: {total_positive}")

feasible_classes  = [cid for cid, info in class_analysis.items() if info['feasible']]
skipped_classes   = [cid for cid, info in class_analysis.items() if not info['feasible']]

print(f"\n  ‚úÖ Will create datasets for {len(feasible_classes)} classes")
if skipped_classes:
    print(f"  ‚ö†Ô∏è  Skipping {len(skipped_classes)} classes with <{MIN_POSITIVE_SAMPLES} samples:")
    for cid in skipped_classes:
        print(f"       Class {cid}: {CLASS_NAMES[cid]} ({class_analysis[cid]['total_positive']} samples)")

# ============================================================================
# STEP 3: CREATE BINARY DATASETS
# ============================================================================
print("\n" + "="*80)
print("STEP 3: CREATING PER-CLASS BINARY DATASETS")
print("="*80)

dataset_summary = []

for class_id in feasible_classes:
    class_name = CLASS_NAMES[class_id]
    class_info = class_analysis[class_id]

    print(f"\n  üìÅ Creating dataset for: {class_name}")

    # Create directory structure
    class_dir = Path(WORKING_DIR) / f"class_{class_id:02d}_{class_name}"

    for split in SPLITS:
        (class_dir / split / 'images').mkdir(parents=True, exist_ok=True)
        (class_dir / split / 'labels').mkdir(parents=True, exist_ok=True)

    split_counts = {}

    for split in SPLITS:
        split_info   = class_info['splits'][split]
        positive_stems = split_info['positive']
        negative_stems = split_info['negative']

        # For negative sampling: balance with positive count
        # Use at most 2x positive samples as negatives to avoid extreme imbalance
        n_positives = len(positive_stems)
        n_neg_to_use = min(len(negative_stems), max(n_positives * 2, 50))

        # Randomly sample negatives
        np.random.seed(42)
        if len(negative_stems) > n_neg_to_use:
            selected_negatives = list(np.random.choice(
                negative_stems, n_neg_to_use, replace=False
            ))
        else:
            selected_negatives = negative_stems

        copied_pos = 0
        copied_neg = 0
        errors     = 0

        # Copy POSITIVE samples
        for stem in positive_stems:
            info        = image_index[split][stem]
            img_src     = info['img_path']
            img_dst     = class_dir / split / 'images' / img_src.name
            label_dst   = class_dir / split / 'labels' / (stem + '.txt')

            try:
                shutil.copy2(img_src, img_dst)
                # Write binary label (only target class, remapped to 0)
                write_binary_annotations(info['annotations'], class_id, label_dst)
                copied_pos += 1
            except Exception as e:
                errors += 1

        # Copy NEGATIVE samples (images with no target class)
        for stem in selected_negatives:
            info      = image_index[split][stem]
            img_src   = info['img_path']
            img_dst   = class_dir / split / 'images' / img_src.name
            label_dst = class_dir / split / 'labels' / (stem + '.txt')

            try:
                shutil.copy2(img_src, img_dst)
                # Write empty label file (no target class = no annotations)
                open(label_dst, 'w').close()
                copied_neg += 1
            except Exception as e:
                errors += 1

        split_counts[split] = {
            'positive': copied_pos,
            'negative': copied_neg,
            'total':    copied_pos + copied_neg
        }

        print(f"    {split:6s}: {copied_pos:4d} positive + {copied_neg:4d} negative = "
              f"{copied_pos + copied_neg:4d} total  (errors: {errors})")

    # Create data.yaml
    create_data_yaml(
        class_name,
        str(class_dir),
        str(class_dir / 'data.yaml')
    )

    dataset_summary.append({
        'class_id':        class_id,
        'class_name':      class_name,
        'train_positive':  split_counts['train']['positive'],
        'train_negative':  split_counts['train']['negative'],
        'train_total':     split_counts['train']['total'],
        'valid_positive':  split_counts['valid']['positive'],
        'valid_negative':  split_counts['valid']['negative'],
        'valid_total':     split_counts['valid']['total'],
        'dataset_path':    str(class_dir)
    })

# ============================================================================
# STEP 4: COPY TO GOOGLE DRIVE
# ============================================================================
print("\n" + "="*80)
print("STEP 4: SAVING TO GOOGLE DRIVE")
print("="*80)

print("‚è≥ Copying datasets to Drive (this may take a few minutes)...")

for class_id in feasible_classes:
    class_name = CLASS_NAMES[class_id]
    src_dir    = Path(WORKING_DIR) / f"class_{class_id:02d}_{class_name}"
    dst_dir    = Path(OUTPUT_BASE) / f"class_{class_id:02d}_{class_name}"

    if dst_dir.exists():
        shutil.rmtree(dst_dir)

    shutil.copytree(src_dir, dst_dir)
    print(f"  ‚úÖ Saved: {class_name}")

# ============================================================================
# STEP 5: SUMMARY REPORT
# ============================================================================
print("\n" + "="*80)
print("STEP 5: FINAL SUMMARY")
print("="*80)

df_summary = pd.DataFrame(dataset_summary)
df_summary.to_csv(f'{OUTPUT_BASE}/dataset_split_summary.csv', index=False)

print(f"\n{'Class':<25} {'Train+':>7} {'Train-':>7} {'Valid+':>7} {'Valid-':>7} {'Total':>7}")
print("-" * 65)
for _, row in df_summary.iterrows():
    print(f"  {row['class_name']:<23} {row['train_positive']:>7} {row['train_negative']:>7} "
          f"{row['valid_positive']:>7} {row['valid_negative']:>7} "
          f"{row['train_total'] + row['valid_total']:>7}")

# ============================================================================
# STEP 6: VISUALIZE DATASET SIZES
# ============================================================================
fig, axes = plt.subplots(1, 2, figsize=(16, 6))
fig.suptitle('Per-Class Binary Datasets ‚Äî Overview', fontsize=16, fontweight='bold')

# Train distribution
ax = axes[0]
x = np.arange(len(df_summary))
w = 0.35
ax.bar(x - w/2, df_summary['train_positive'], w, label='Positive', color='#2ECC71', alpha=0.8)
ax.bar(x + w/2, df_summary['train_negative'], w, label='Negative', color='#E74C3C', alpha=0.8)
ax.set_title('Training Set: Positive vs Negative', fontweight='bold')
ax.set_xlabel('Class')
ax.set_ylabel('Sample Count')
ax.set_xticks(x)
ax.set_xticklabels(df_summary['class_name'], rotation=45, ha='right', fontsize=9)
ax.legend()
ax.grid(True, alpha=0.3)

# Valid distribution
ax = axes[1]
ax.bar(x - w/2, df_summary['valid_positive'], w, label='Positive', color='#3498DB', alpha=0.8)
ax.bar(x + w/2, df_summary['valid_negative'], w, label='Negative', color='#E67E22', alpha=0.8)
ax.set_title('Validation Set: Positive vs Negative', fontweight='bold')
ax.set_xlabel('Class')
ax.set_ylabel('Sample Count')
ax.set_xticks(x)
ax.set_xticklabels(df_summary['class_name'], rotation=45, ha='right', fontsize=9)
ax.legend()
ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig(f'{OUTPUT_BASE}/per_class_dataset_sizes.png', dpi=150, bbox_inches='tight')
plt.close()

print(f"\nüíæ All outputs saved to Google Drive:")
print(f"   üìÅ {OUTPUT_BASE}/")
print(f"   ‚îú‚îÄ‚îÄ dataset_split_summary.csv")
print(f"   ‚îú‚îÄ‚îÄ per_class_dataset_sizes.png")
for class_id in feasible_classes:
    class_name = CLASS_NAMES[class_id]
    print(f"   ‚îú‚îÄ‚îÄ class_{class_id:02d}_{class_name}/")
    print(f"   ‚îÇ     ‚îú‚îÄ‚îÄ train/images/ & labels/")
    print(f"   ‚îÇ     ‚îú‚îÄ‚îÄ valid/images/ & labels/")
    print(f"   ‚îÇ     ‚îú‚îÄ‚îÄ test/images/  & labels/")
    print(f"   ‚îÇ     ‚îî‚îÄ‚îÄ data.yaml")

print(f"\n‚úÖ DATASET SPLITTING COMPLETE!")
print(f"   {len(feasible_classes)} binary datasets ready for One-vs-Rest training!")
print("="*80)



"""Training script"""

"""
================================================================================
STEP 3: TRAIN ML MODELS FOR ALL 15 ROAD DEFECT CLASSES
================================================================================
- Extracts features from bounding box regions
- Trains multiple ML models per class (LightGBM, XGBoost, CatBoost, RF)
- Saves best model per class
- Visualizes predictions on test data
- All outputs saved to Google Drive
- Optimized for T4 GPU training + Edge device inference
================================================================================
"""

# ============================================================================
# INSTALL REQUIRED PACKAGES (Run this first!)
# ============================================================================
print("üì¶ Installing required packages...")
import subprocess
import sys

packages = [
    'lightgbm',
    'xgboost',
    'catboost',
    'scikit-image',
    'imbalanced-learn'
]

for package in packages:
    print(f"   Installing {package}...")
    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', package])

print("‚úÖ All packages installed!\n")

# ============================================================================
# IMPORTS
# ============================================================================
import os
import cv2
import pickle
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from collections import defaultdict
from tqdm.auto import tqdm
import json
import time
import warnings
warnings.filterwarnings('ignore')

# ML Libraries
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (accuracy_score, precision_score, recall_score,
                             f1_score, confusion_matrix, classification_report)
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE

# Gradient Boosting Models
import lightgbm as lgb
import xgboost as xgb
from catboost import CatBoostClassifier

# Feature Extraction
from skimage.feature import hog, local_binary_pattern
from skimage.filters import gabor
from scipy.stats import skew, kurtosis

# Google Drive
from google.colab import drive

# ============================================================================
# MOUNT GOOGLE DRIVE
# ============================================================================
print("üìÇ Mounting Google Drive...")
drive.mount('/content/drive')

DATASETS_DIR = '/content/drive/MyDrive/Road_Defect_Project/02_Per_Class_Datasets'
OUTPUT_DIR   = '/content/drive/MyDrive/Road_Defect_Project/03_Trained_Models'
os.makedirs(OUTPUT_DIR, exist_ok=True)

print(f"‚úÖ Datasets: {DATASETS_DIR}")
print(f"‚úÖ Output: {OUTPUT_DIR}\n")

# ============================================================================
# CONFIGURATION
# ============================================================================
CLASS_NAMES = {
    0:  'Big_Culvert',
    1:  'Blocked_culvert',
    2:  'Cause_ways',
    3:  'Crack',
    4:  'Culvert',
    5:  'Damaged_surface_layer',
    6:  'Drainage_cover',
    7:  'Edge_breaking',
    8:  'Guard_stone',
    9:  'Not_painted_gs',
    10: 'Not_whitewashed',
    11: 'Patching',
    12: 'Ravelling',
    13: 'km_stone',
    14: 'pothole'
}

# Feature extraction settings
TARGET_SIZE = (128, 128)  # Resize all ROIs to this size for consistency
USE_SMOTE = True  # Handle class imbalance
RANDOM_SEED = 42

# ============================================================================
# FEATURE EXTRACTION FUNCTIONS
# ============================================================================
def extract_roi_from_image(img_path, label_path):
    """
    Extract all ROIs (bounding boxes) from an image
    Returns list of (roi_image, class_label) tuples
    """
    img = cv2.imread(str(img_path))
    if img is None:
        return []

    h, w = img.shape[:2]
    rois = []

    if Path(label_path).exists() and Path(label_path).stat().st_size > 0:
        with open(label_path, 'r') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) >= 5:
                    class_id = int(parts[0])
                    x_center = float(parts[1]) * w
                    y_center = float(parts[2]) * h
                    box_w = float(parts[3]) * w
                    box_h = float(parts[4]) * h

                    x1 = int(max(0, x_center - box_w/2))
                    y1 = int(max(0, y_center - box_h/2))
                    x2 = int(min(w, x_center + box_w/2))
                    y2 = int(min(h, y_center + box_h/2))

                    if x2 > x1 and y2 > y1:
                        roi = img[y1:y2, x1:x2]
                        if roi.size > 0:
                            rois.append((roi, class_id, (x1, y1, x2, y2)))

        return rois
    else:
        # No annotations = negative sample (entire image or random crop)
        # For simplicity, use center crop
        crop_size = min(h, w) // 2
        y_start = h // 4
        x_start = w // 4
        roi = img[y_start:y_start+crop_size, x_start:x_start+crop_size]
        return [(roi, -1, (x_start, y_start, x_start+crop_size, y_start+crop_size))]  # -1 = negative


def extract_features(roi):
    """
    Extract comprehensive features from ROI
    Returns feature vector (~8000+ dimensions)
    """
    # Resize to standard size
    roi_resized = cv2.resize(roi, TARGET_SIZE)
    gray = cv2.cvtColor(roi_resized, cv2.COLOR_BGR2GRAY)

    features = []

    # 1. HOG Features (Histogram of Oriented Gradients) - for edges/shapes
    hog_features = hog(
        gray,
        orientations=9,
        pixels_per_cell=(8, 8),
        cells_per_block=(2, 2),
        block_norm='L2-Hys',
        visualize=False
    )
    features.extend(hog_features)

    # 2. LBP Features (Local Binary Patterns) - for texture
    radius = 3
    n_points = 8 * radius
    lbp = local_binary_pattern(gray, n_points, radius, method='uniform')
    lbp_hist, _ = np.histogram(lbp.ravel(), bins=n_points + 2,
                                range=(0, n_points + 2), density=True)
    features.extend(lbp_hist)

    # 3. Color Histograms (RGB) - for color patterns
    for channel in range(3):
        hist = cv2.calcHist([roi_resized], [channel], None, [256], [0, 256])
        hist = hist.flatten() / hist.sum()  # Normalize
        features.extend(hist)

    # 4. Gabor Filters - for oriented patterns
    gabor_features = []
    for theta in [0, np.pi/4, np.pi/2, 3*np.pi/4]:
        filt_real, filt_imag = gabor(gray, frequency=0.1, theta=theta)
        gabor_features.extend([
            filt_real.mean(),
            filt_real.std(),
            filt_imag.mean(),
            filt_imag.std()
        ])
    features.extend(gabor_features)

    # 5. Statistical Features
    stats_features = [
        gray.mean(),
        gray.std(),
        gray.min(),
        gray.max(),
        skew(gray.ravel()),
        kurtosis(gray.ravel()),
        np.median(gray),
        np.percentile(gray, 25),
        np.percentile(gray, 75)
    ]
    features.extend(stats_features)

    # 6. Edge Features
    edges = cv2.Canny(gray, 50, 150)
    edge_features = [
        edges.mean(),
        edges.std(),
        (edges > 0).sum() / edges.size  # Edge density
    ]
    features.extend(edge_features)

    return np.array(features, dtype=np.float32)


def load_dataset(class_id, class_name):
    """
    Load all images for a specific binary class dataset
    Returns X (features), y (labels), metadata
    """
    class_dir = Path(DATASETS_DIR) / f"class_{class_id:02d}_{class_name}"

    if not class_dir.exists():
        print(f"  ‚ö†Ô∏è  Dataset not found: {class_dir}")
        return None, None, None

    X_train, y_train = [], []
    X_valid, y_valid = [], []
    X_test, y_test = [], []
    test_metadata = []  # For visualization later

    print(f"\n  üì¶ Loading: {class_name}")

    # Load training data
    train_img_dir = class_dir / 'train' / 'images'
    train_lbl_dir = class_dir / 'train' / 'labels'

    for img_path in tqdm(list(train_img_dir.glob('*.jpg')),
                          desc=f"  Train", leave=False):
        label_path = train_lbl_dir / (img_path.stem + '.txt')
        rois = extract_roi_from_image(img_path, label_path)

        for roi, label, bbox in rois:
            features = extract_features(roi)
            X_train.append(features)
            y_train.append(1 if label == 0 else 0)  # 0 in label = positive class

    # Load validation data
    valid_img_dir = class_dir / 'valid' / 'images'
    valid_lbl_dir = class_dir / 'valid' / 'labels'

    for img_path in tqdm(list(valid_img_dir.glob('*.jpg')),
                          desc=f"  Valid", leave=False):
        label_path = valid_lbl_dir / (img_path.stem + '.txt')
        rois = extract_roi_from_image(img_path, label_path)

        for roi, label, bbox in rois:
            features = extract_features(roi)
            X_valid.append(features)
            y_valid.append(1 if label == 0 else 0)

    # Load test data (WITH metadata for visualization)
    test_img_dir = class_dir / 'test' / 'images'
    test_lbl_dir = class_dir / 'test' / 'labels'

    for img_path in tqdm(list(test_img_dir.glob('*.jpg')),
                          desc=f"  Test ", leave=False):
        label_path = test_lbl_dir / (img_path.stem + '.txt')
        rois = extract_roi_from_image(img_path, label_path)

        for roi, label, bbox in rois:
            features = extract_features(roi)
            X_test.append(features)
            y_test.append(1 if label == 0 else 0)

            # Save metadata for visualization
            test_metadata.append({
                'img_path': str(img_path),
                'bbox': bbox,
                'true_label': 1 if label == 0 else 0,
                'roi': roi.copy()
            })

    X_train = np.array(X_train)
    y_train = np.array(y_train)
    X_valid = np.array(X_valid)
    y_valid = np.array(y_valid)
    X_test = np.array(X_test)
    y_test = np.array(y_test)

    print(f"    Train: {X_train.shape[0]} samples ({y_train.sum()} positive)")
    print(f"    Valid: {X_valid.shape[0]} samples ({y_valid.sum()} positive)")
    print(f"    Test:  {X_test.shape[0]} samples ({y_test.sum()} positive)")
    print(f"    Features: {X_train.shape[1]} dimensions")

    return (X_train, y_train, X_valid, y_valid, X_test, y_test), test_metadata


# ============================================================================
# MODEL TRAINING FUNCTIONS
# ============================================================================
def train_lightgbm(X_train, y_train, X_valid, y_valid):
    """Train LightGBM model"""
    start_time = time.time()

    model = lgb.LGBMClassifier(
        n_estimators=200,
        learning_rate=0.05,
        max_depth=7,
        num_leaves=31,
        min_child_samples=20,
        subsample=0.8,
        colsample_bytree=0.8,
        random_state=RANDOM_SEED,
        n_jobs=-1,
        verbose=-1
    )

    model.fit(
        X_train, y_train,
        eval_set=[(X_valid, y_valid)],
        callbacks=[lgb.early_stopping(stopping_rounds=20, verbose=False)]
    )

    train_time = time.time() - start_time

    # Inference speed test
    start = time.time()
    _ = model.predict(X_valid[:100])
    inference_time = (time.time() - start) / 100 * 1000  # ms per sample

    return model, train_time, inference_time


def train_xgboost(X_train, y_train, X_valid, y_valid):
    """Train XGBoost model"""
    start_time = time.time()

    model = xgb.XGBClassifier(
        n_estimators=200,
        learning_rate=0.05,
        max_depth=7,
        min_child_weight=3,
        subsample=0.8,
        colsample_bytree=0.8,
        random_state=RANDOM_SEED,
        n_jobs=-1,
        tree_method='hist',
        device='cuda',  # Use GPU for training
        verbosity=0
    )

    model.fit(
        X_train, y_train,
        eval_set=[(X_valid, y_valid)],
        verbose=False
    )

    train_time = time.time() - start_time

    # Inference speed test (on CPU for edge device simulation)
    model.set_params(device='cpu')
    start = time.time()
    _ = model.predict(X_valid[:100])
    inference_time = (time.time() - start) / 100 * 1000

    return model, train_time, inference_time


def train_catboost(X_train, y_train, X_valid, y_valid):
    """Train CatBoost model"""
    start_time = time.time()

    model = CatBoostClassifier(
        iterations=200,
        learning_rate=0.05,
        depth=7,
        l2_leaf_reg=3,
        random_seed=RANDOM_SEED,
        task_type='GPU',
        devices='0',
        verbose=False
    )

    model.fit(
        X_train, y_train,
        eval_set=(X_valid, y_valid),
        early_stopping_rounds=20,
        verbose=False
    )

    train_time = time.time() - start_time

    # Inference speed test
    start = time.time()
    _ = model.predict(X_valid[:100])
    inference_time = (time.time() - start) / 100 * 1000

    return model, train_time, inference_time


def train_random_forest(X_train, y_train, X_valid, y_valid):
    """Train Random Forest model"""
    start_time = time.time()

    model = RandomForestClassifier(
        n_estimators=100,
        max_depth=15,
        min_samples_split=10,
        min_samples_leaf=4,
        max_features='sqrt',
        random_state=RANDOM_SEED,
        n_jobs=-1
    )

    model.fit(X_train, y_train)

    train_time = time.time() - start_time

    # Inference speed test
    start = time.time()
    _ = model.predict(X_valid[:100])
    inference_time = (time.time() - start) / 100 * 1000

    return model, train_time, inference_time


def evaluate_model(model, X_test, y_test):
    """Evaluate model and return metrics"""
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else y_pred

    metrics = {
        'accuracy': accuracy_score(y_test, y_pred),
        'precision': precision_score(y_test, y_pred, zero_division=0),
        'recall': recall_score(y_test, y_pred, zero_division=0),
        'f1_score': f1_score(y_test, y_pred, zero_division=0),
        'confusion_matrix': confusion_matrix(y_test, y_pred).tolist(),
        'predictions': y_pred.tolist(),
        'probabilities': y_proba.tolist()
    }

    return metrics


# ============================================================================
# VISUALIZATION FUNCTIONS
# ============================================================================
def plot_confusion_matrix(cm, class_name, output_path):
    """Plot confusion matrix"""
    fig, ax = plt.subplots(figsize=(8, 6))

    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=['Negative', 'Positive'],
                yticklabels=['Negative', 'Positive'],
                cbar_kws={'label': 'Count'})

    ax.set_xlabel('Predicted Label', fontsize=12, fontweight='bold')
    ax.set_ylabel('True Label', fontsize=12, fontweight='bold')
    ax.set_title(f'Confusion Matrix: {class_name}', fontsize=14, fontweight='bold')

    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close()


def plot_feature_importance(model, model_name, class_name, output_path, top_n=20):
    """Plot feature importance for tree-based models"""
    if not hasattr(model, 'feature_importances_'):
        return

    importances = model.feature_importances_
    indices = np.argsort(importances)[::-1][:top_n]

    fig, ax = plt.subplots(figsize=(10, 8))

    ax.barh(range(top_n), importances[indices], color='steelblue')
    ax.set_yticks(range(top_n))
    ax.set_yticklabels([f'Feature {i}' for i in indices])
    ax.set_xlabel('Importance', fontsize=12, fontweight='bold')
    ax.set_title(f'Top {top_n} Feature Importance: {class_name}\n{model_name}',
                 fontsize=14, fontweight='bold')
    ax.invert_yaxis()

    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close()


def visualize_test_predictions(model, test_metadata, class_name, output_path, max_images=12):
    """
    ‚≠ê VISUALIZE HOW MODEL DETECTS ON TEST DATA ‚≠ê
    Shows original images with bounding boxes colored by prediction correctness
    """
    if len(test_metadata) == 0:
        print(f"    ‚ö†Ô∏è  No test samples to visualize")
        return

    # Group by image
    images_dict = defaultdict(list)
    for meta in test_metadata:
        images_dict[meta['img_path']].append(meta)

    unique_images = list(images_dict.keys())[:max_images]

    # Calculate grid size
    n_images = len(unique_images)
    n_cols = 4
    n_rows = (n_images + n_cols - 1) // n_cols

    fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 5*n_rows))
    if n_rows == 1:
        axes = axes.reshape(1, -1)
    axes = axes.flatten()

    fig.suptitle(f'Test Predictions: {class_name}\nüü¢ Correct | üî¥ Wrong',
                 fontsize=16, fontweight='bold')

    for idx, img_path in enumerate(unique_images):
        img = cv2.imread(img_path)
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        # Draw all detections for this image
        for meta in images_dict[img_path]:
            x1, y1, x2, y2 = meta['bbox']
            true_label = meta['true_label']
            pred_label = meta.get('pred_label', -1)
            confidence = meta.get('confidence', 0)

            # Color: Green if correct, Red if wrong
            correct = (true_label == pred_label)
            color = (0, 255, 0) if correct else (255, 0, 0)
            thickness = 3 if correct else 2

            cv2.rectangle(img_rgb, (x1, y1), (x2, y2), color, thickness)

            # Label
            label_text = f"{'‚úì' if correct else '‚úó'} "
            label_text += f"Pred: {'POS' if pred_label == 1 else 'NEG'} "
            label_text += f"({confidence:.2f})"

            # Background for text
            (text_w, text_h), _ = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
            cv2.rectangle(img_rgb, (x1, y1-text_h-8), (x1+text_w+5, y1), color, -1)
            cv2.putText(img_rgb, label_text, (x1+2, y1-5),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

        axes[idx].imshow(img_rgb)
        axes[idx].set_title(Path(img_path).name[:30], fontsize=9)
        axes[idx].axis('off')

    # Hide empty subplots
    for idx in range(len(unique_images), len(axes)):
        axes[idx].axis('off')

    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close()

    print(f"    ‚úÖ Test visualization saved: {Path(output_path).name}")


# ============================================================================
# MAIN TRAINING PIPELINE
# ============================================================================
def train_class_models(class_id, class_name):
    """
    Train all models for a single class
    """
    print("\n" + "="*80)
    print(f"üéØ TRAINING CLASS {class_id}: {class_name}")
    print("="*80)

    # Create output directory
    class_output_dir = Path(OUTPUT_DIR) / f"class_{class_id:02d}_{class_name}"
    class_output_dir.mkdir(parents=True, exist_ok=True)

    # Load dataset
    dataset, test_metadata = load_dataset(class_id, class_name)
    if dataset is None:
        print(f"  ‚ùå Skipping {class_name} - dataset not found")
        return None

    X_train, y_train, X_valid, y_valid, X_test, y_test = dataset

    # Feature scaling
    print("\n  ‚öôÔ∏è  Scaling features...")
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_valid_scaled = scaler.transform(X_valid)
    X_test_scaled = scaler.transform(X_test)

    # Handle class imbalance with SMOTE
    if USE_SMOTE and y_train.sum() > 5:  # Need at least 5 positive samples
        print(f"  ‚öôÔ∏è  Applying SMOTE (pos: {y_train.sum()}, neg: {len(y_train) - y_train.sum()})...")
        smote = SMOTE(random_state=RANDOM_SEED)
        X_train_scaled, y_train = smote.fit_resample(X_train_scaled, y_train)
        print(f"      After SMOTE: {len(y_train)} samples ({y_train.sum()} positive)")

    # Train all models
    models_results = {}

    print("\n  üöÄ Training models...")

    # 1. LightGBM
    print("\n    üìä LightGBM...")
    try:
        model_lgb, train_time, inf_time = train_lightgbm(
            X_train_scaled, y_train, X_valid_scaled, y_valid
        )
        metrics_lgb = evaluate_model(model_lgb, X_test_scaled, y_test)
        models_results['lightgbm'] = {
            'model': model_lgb,
            'metrics': metrics_lgb,
            'train_time': train_time,
            'inference_time': inf_time
        }
        print(f"       Accuracy: {metrics_lgb['accuracy']:.4f} | "
              f"F1: {metrics_lgb['f1_score']:.4f} | "
              f"Inference: {inf_time:.3f}ms")
    except Exception as e:
        print(f"       ‚ùå Failed: {e}")

    # 2. XGBoost
    print("\n    üìä XGBoost...")
    try:
        model_xgb, train_time, inf_time = train_xgboost(
            X_train_scaled, y_train, X_valid_scaled, y_valid
        )
        metrics_xgb = evaluate_model(model_xgb, X_test_scaled, y_test)
        models_results['xgboost'] = {
            'model': model_xgb,
            'metrics': metrics_xgb,
            'train_time': train_time,
            'inference_time': inf_time
        }
        print(f"       Accuracy: {metrics_xgb['accuracy']:.4f} | "
              f"F1: {metrics_xgb['f1_score']:.4f} | "
              f"Inference: {inf_time:.3f}ms")
    except Exception as e:
        print(f"       ‚ùå Failed: {e}")

    # 3. CatBoost
    print("\n    üìä CatBoost...")
    try:
        model_cat, train_time, inf_time = train_catboost(
            X_train_scaled, y_train, X_valid_scaled, y_valid
        )
        metrics_cat = evaluate_model(model_cat, X_test_scaled, y_test)
        models_results['catboost'] = {
            'model': model_cat,
            'metrics': metrics_cat,
            'train_time': train_time,
            'inference_time': inf_time
        }
        print(f"       Accuracy: {metrics_cat['accuracy']:.4f} | "
              f"F1: {metrics_cat['f1_score']:.4f} | "
              f"Inference: {inf_time:.3f}ms")
    except Exception as e:
        print(f"       ‚ùå Failed: {e}")

    # 4. Random Forest
    print("\n    üìä Random Forest...")
    try:
        model_rf, train_time, inf_time = train_random_forest(
            X_train_scaled, y_train, X_valid_scaled, y_valid
        )
        metrics_rf = evaluate_model(model_rf, X_test_scaled, y_test)
        models_results['random_forest'] = {
            'model': model_rf,
            'metrics': metrics_rf,
            'train_time': train_time,
            'inference_time': inf_time
        }
        print(f"       Accuracy: {metrics_rf['accuracy']:.4f} | "
              f"F1: {metrics_rf['f1_score']:.4f} | "
              f"Inference: {inf_time:.3f}ms")
    except Exception as e:
        print(f"       ‚ùå Failed: {e}")

    # Select best model
    print("\n  üèÜ Selecting best model...")
    best_model_name = None
    best_score = -1

    for model_name, result in models_results.items():
        # Composite score: 50% accuracy + 30% F1 + 10% speed + 10% size
        acc = result['metrics']['accuracy']
        f1 = result['metrics']['f1_score']
        speed_score = 1 / (1 + result['inference_time'])  # Lower time = higher score

        composite_score = 0.5 * acc + 0.3 * f1 + 0.2 * speed_score

        if composite_score > best_score:
            best_score = composite_score
            best_model_name = model_name

    if best_model_name is None:
        print("    ‚ùå No models trained successfully")
        return None

    best_result = models_results[best_model_name]
    best_model = best_result['model']
    best_metrics = best_result['metrics']

    print(f"    ‚≠ê Best: {best_model_name.upper()}")
    print(f"       Accuracy:  {best_metrics['accuracy']:.4f}")
    print(f"       Precision: {best_metrics['precision']:.4f}")
    print(f"       Recall:    {best_metrics['recall']:.4f}")
    print(f"       F1 Score:  {best_metrics['f1_score']:.4f}")
    print(f"       Inference: {best_result['inference_time']:.3f}ms")

    # Save all models
    print("\n  üíæ Saving models...")
    for model_name, result in models_results.items():
        model_path = class_output_dir / f"model_{model_name}.pkl"
        with open(model_path, 'wb') as f:
            pickle.dump({
                'model': result['model'],
                'scaler': scaler,
                'metadata': {
                    'class_id': class_id,
                    'class_name': class_name,
                    'model_type': model_name,
                    'feature_dim': X_train.shape[1]
                }
            }, f)
        print(f"    ‚úÖ {model_name}: {model_path.name}")

    # Save best model separately
    best_model_path = class_output_dir / "best_model.pkl"
    with open(best_model_path, 'wb') as f:
        pickle.dump({
            'model': best_model,
            'scaler': scaler,
            'metadata': {
                'class_id': class_id,
                'class_name': class_name,
                'model_type': best_model_name,
                'feature_dim': X_train.shape[1],
                'metrics': best_metrics
            }
        }, f)
    print(f"    ‚≠ê best_model.pkl (Use this for deployment!)")

    # Save metrics
    metrics_path = class_output_dir / "metrics.json"
    with open(metrics_path, 'w') as f:
        json.dump({
            'best_model': best_model_name,
            'models': {
                name: {
                    'accuracy': res['metrics']['accuracy'],
                    'precision': res['metrics']['precision'],
                    'recall': res['metrics']['recall'],
                    'f1_score': res['metrics']['f1_score'],
                    'train_time': res['train_time'],
                    'inference_time': res['inference_time']
                }
                for name, res in models_results.items()
            }
        }, f, indent=2)
    print(f"    ‚úÖ metrics.json")

    # Generate visualizations
    print("\n  üìä Generating visualizations...")

    # Confusion matrix
    cm = np.array(best_metrics['confusion_matrix'])
    cm_path = class_output_dir / "confusion_matrix.png"
    plot_confusion_matrix(cm, class_name, cm_path)
    print(f"    ‚úÖ confusion_matrix.png")

    # Feature importance
    fi_path = class_output_dir / "feature_importance.png"
    plot_feature_importance(best_model, best_model_name, class_name, fi_path)
    print(f"    ‚úÖ feature_importance.png")

    # ‚≠ê TEST PREDICTIONS VISUALIZATION ‚≠ê
    print("\n  üé® Visualizing test predictions...")

    # Add predictions to metadata
    for i, meta in enumerate(test_metadata):
        meta['pred_label'] = best_metrics['predictions'][i]
        meta['confidence'] = best_metrics['probabilities'][i]

    viz_path = class_output_dir / "test_predictions_visualization.png"
    visualize_test_predictions(best_model, test_metadata, class_name, viz_path)

    # Training log
    log_path = class_output_dir / "training_log.txt"
    with open(log_path, 'w') as f:
        f.write(f"Training Log: {class_name}\n")
        f.write("="*60 + "\n\n")
        f.write(f"Dataset:\n")
        f.write(f"  Train: {X_train.shape[0]} samples\n")
        f.write(f"  Valid: {X_valid.shape[0]} samples\n")
        f.write(f"  Test:  {X_test.shape[0]} samples\n")
        f.write(f"  Features: {X_train.shape[1]} dimensions\n\n")
        f.write(f"Best Model: {best_model_name}\n")
        f.write(f"  Accuracy:  {best_metrics['accuracy']:.4f}\n")
        f.write(f"  Precision: {best_metrics['precision']:.4f}\n")
        f.write(f"  Recall:    {best_metrics['recall']:.4f}\n")
        f.write(f"  F1 Score:  {best_metrics['f1_score']:.4f}\n")
        f.write(f"  Inference: {best_result['inference_time']:.3f}ms\n")
    print(f"    ‚úÖ training_log.txt")

    print(f"\n‚úÖ Class {class_id}: {class_name} COMPLETE!")
    print(f"   üìÅ Saved to: {class_output_dir.name}/")

    return {
        'class_id': class_id,
        'class_name': class_name,
        'best_model': best_model_name,
        'accuracy': best_metrics['accuracy'],
        'precision': best_metrics['precision'],
        'recall': best_metrics['recall'],
        'f1_score': best_metrics['f1_score'],
        'inference_time': best_result['inference_time'],
        'train_samples': X_train.shape[0],
        'test_samples': X_test.shape[0]
    }


# ============================================================================
# RUN TRAINING FOR ALL CLASSES
# ============================================================================
print("\n" + "="*80)
print("üöÄ STARTING TRAINING FOR ALL 15 CLASSES")
print("="*80)
print(f"Using GPU: {os.system('nvidia-smi -L')}")

all_results = []

for class_id, class_name in CLASS_NAMES.items():
    try:
        result = train_class_models(class_id, class_name)
        if result:
            all_results.append(result)
    except Exception as e:
        print(f"\n‚ùå ERROR training {class_name}: {e}")
        import traceback
        traceback.print_exc()
        continue

# ============================================================================
# GENERATE MASTER SUMMARY
# ============================================================================
print("\n" + "="*80)
print("üìä GENERATING MASTER SUMMARY")
print("="*80)

if len(all_results) > 0:
    df_summary = pd.DataFrame(all_results)
    summary_path = Path(OUTPUT_DIR) / "MASTER_TRAINING_SUMMARY.csv"
    df_summary.to_csv(summary_path, index=False)
    print(f"\n‚úÖ Master summary saved: {summary_path}")

    # Display summary table
    print("\n" + "="*80)
    print("FINAL RESULTS SUMMARY")
    print("="*80)
    print(df_summary.to_string(index=False))

    # Summary visualizations
    fig, axes = plt.subplots(2, 2, figsize=(18, 12))
    fig.suptitle('Training Results Summary ‚Äî All 15 Classes',
                 fontsize=18, fontweight='bold')

    # 1. Accuracy comparison
    ax = axes[0, 0]
    bars = ax.barh(df_summary['class_name'], df_summary['accuracy'], color='steelblue')
    for i, bar in enumerate(bars):
        width = bar.get_width()
        ax.text(width + 0.01, bar.get_y() + bar.get_height()/2,
                f'{width:.3f}', va='center', fontsize=9, fontweight='bold')
    ax.axvline(x=0.90, color='red', linestyle='--', label='90% Target')
    ax.set_xlabel('Accuracy', fontweight='bold')
    ax.set_title('Test Accuracy by Class', fontweight='bold')
    ax.legend()
    ax.grid(axis='x', alpha=0.3)

    # 2. F1 Score comparison
    ax = axes[0, 1]
    bars = ax.barh(df_summary['class_name'], df_summary['f1_score'], color='green', alpha=0.7)
    for i, bar in enumerate(bars):
        width = bar.get_width()
        ax.text(width + 0.01, bar.get_y() + bar.get_height()/2,
                f'{width:.3f}', va='center', fontsize=9, fontweight='bold')
    ax.set_xlabel('F1 Score', fontweight='bold')
    ax.set_title('F1 Score by Class', fontweight='bold')
    ax.grid(axis='x', alpha=0.3)

    # 3. Inference time comparison
    ax = axes[1, 0]
    bars = ax.barh(df_summary['class_name'], df_summary['inference_time'], color='orange')
    for i, bar in enumerate(bars):
        width = bar.get_width()
        ax.text(width + 0.01, bar.get_y() + bar.get_height()/2,
                f'{width:.2f}ms', va='center', fontsize=9, fontweight='bold')
    ax.axvline(x=10, color='red', linestyle='--', label='10ms Target')
    ax.set_xlabel('Inference Time (ms)', fontweight='bold')
    ax.set_title('Inference Speed by Class', fontweight='bold')
    ax.legend()
    ax.grid(axis='x', alpha=0.3)

    # 4. Model distribution
    ax = axes[1, 1]
    model_counts = df_summary['best_model'].value_counts()
    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']
    wedges, texts, autotexts = ax.pie(model_counts.values, labels=model_counts.index,
                                        autopct='%1.0f%%', startangle=90, colors=colors)
    for autotext in autotexts:
        autotext.set_color('white')
        autotext.set_fontweight('bold')
    ax.set_title('Best Model Distribution', fontweight='bold')

    plt.tight_layout()
    viz_path = Path(OUTPUT_DIR) / "training_summary_visualization.png"
    plt.savefig(viz_path, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"‚úÖ Summary visualization saved: {viz_path}")

    # Stats
    print(f"\nüìà OVERALL STATISTICS:")
    print(f"   Average Accuracy:    {df_summary['accuracy'].mean():.4f}")
    print(f"   Average F1 Score:    {df_summary['f1_score'].mean():.4f}")
    print(f"   Average Inference:   {df_summary['inference_time'].mean():.3f}ms")
    print(f"   Classes ‚â•90% Acc:    {(df_summary['accuracy'] >= 0.90).sum()}/{len(df_summary)}")
    print(f"   Classes <10ms Inf:   {(df_summary['inference_time'] < 10).sum()}/{len(df_summary)}")

else:
    print("‚ö†Ô∏è  No models trained successfully")

print("\n" + "="*80)
print("üéâ TRAINING COMPLETE!")
print("="*80)
print(f"\nüìÅ All outputs saved to:")
print(f"   {OUTPUT_DIR}")
print(f"\n‚úÖ Ready for deployment!")
print("="*80)

#upadeted script for diagnose

"""
================================================================================
ROAD DEFECT DETECTION ‚Äî COMPLETE TRAINING SCRIPT (NEW ACCOUNT)
================================================================================
- Mounts Google Drive (same Drive where datasets are saved)
- Auto-detects already trained classes vs remaining
- Fixes F1=0 bug (evaluates on validation, not broken test set)
- Trains: LightGBM + XGBoost + CatBoost + Random Forest per class
- Saves best model per class to Drive
- Generates visualizations + master summary
- Works on GPU (fast) or CPU (fallback)
================================================================================
BEFORE RUNNING:
  1. Runtime ‚Üí Change runtime type ‚Üí GPU (T4)
  2. Make sure this is logged into the SAME Google account as before
     (so it can access Drive datasets from Step 2)
================================================================================
"""

# ============================================================================
# 0. INSTALL PACKAGES
# ============================================================================
import subprocess, sys
print("üì¶ Installing packages...")
for pkg in ['lightgbm', 'xgboost', 'catboost', 'scikit-image', 'imbalanced-learn', 'tqdm']:
    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', pkg])
print("‚úÖ All packages ready\n")

# ============================================================================
# 1. IMPORTS
# ============================================================================
import os, cv2, pickle, json, time, warnings
import numpy as np
import pandas as pd
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from collections import defaultdict
from tqdm.auto import tqdm
warnings.filterwarnings('ignore')

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (accuracy_score, precision_score,
                             recall_score, f1_score, confusion_matrix)
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
import lightgbm as lgb
import xgboost as xgb
from catboost import CatBoostClassifier
from skimage.feature import hog, local_binary_pattern
from skimage.filters import gabor
from scipy.stats import skew, kurtosis
from google.colab import drive

# ============================================================================
# 2. MOUNT DRIVE
# ============================================================================
print("üìÇ Mounting Google Drive...")
drive.mount('/content/drive')

DATASETS_DIR = '/content/drive/MyDrive/Road_Defect_Project/02_Per_Class_Datasets'
OUTPUT_DIR   = '/content/drive/MyDrive/Road_Defect_Project/03_Trained_Models'
os.makedirs(OUTPUT_DIR, exist_ok=True)

print(f"‚úÖ Datasets : {DATASETS_DIR}")
print(f"‚úÖ Output   : {OUTPUT_DIR}")

# Verify datasets exist
if not os.path.exists(DATASETS_DIR):
    print(f"\n‚ùå DATASETS NOT FOUND: {DATASETS_DIR}")
    print("   Make sure you are logged into the SAME Google account!")
    raise SystemExit()
else:
    class_folders = [f for f in os.listdir(DATASETS_DIR) if os.path.isdir(f'{DATASETS_DIR}/{f}')]
    print(f"‚úÖ Found {len(class_folders)} class datasets in Drive\n")

# ============================================================================
# 3. GPU CHECK
# ============================================================================
try:
    gpu_info = subprocess.check_output(
        ['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader']
    ).decode().strip()
    print(f"üéÆ GPU: {gpu_info}")
    GPU_AVAILABLE    = True
    XGBOOST_DEVICE   = 'cuda'
    CATBOOST_TASK    = 'GPU'
except:
    print("üíª No GPU detected ‚Äî using CPU")
    GPU_AVAILABLE    = False
    XGBOOST_DEVICE   = 'cpu'
    CATBOOST_TASK    = 'CPU'

# ============================================================================
# 4. CONFIG
# ============================================================================
CLASS_NAMES = {
    0:  'Big_Culvert',
    1:  'Blocked_culvert',
    2:  'Cause_ways',
    3:  'Crack',
    4:  'Culvert',
    5:  'Damaged_surface_layer',
    6:  'Drainage_cover',
    7:  'Edge_breaking',
    8:  'Guard_stone',
    9:  'Not_painted_gs',
    10: 'Not_whitewashed',
    11: 'Patching',
    12: 'Ravelling',
    13: 'km_stone',
    14: 'pothole'
}
TARGET_SIZE = (128, 128)
RANDOM_SEED = 42

# ============================================================================
# 5. CHECK WHICH CLASSES NEED TRAINING
# ============================================================================
print("\n" + "="*70)
print("CHECKING TRAINING STATUS")
print("="*70)

already_done   = []
needs_training = []

for class_id, class_name in CLASS_NAMES.items():
    out_dir      = Path(OUTPUT_DIR) / f"class_{class_id:02d}_{class_name}"
    model_path   = out_dir / "best_model.pkl"
    metrics_path = out_dir / "metrics.json"

    if model_path.exists() and metrics_path.exists():
        try:
            with open(metrics_path) as f:
                m = json.load(f)
            best   = m['best_model']
            f1_val = m['models'][best]['f1_score']
            acc    = m['models'][best]['accuracy']
            # If evaluated on broken test set (F1=0 but acc looks suspicious)
            if f1_val == 0.0:
                print(f"  ‚ö†Ô∏è  Class {class_id:2d}: {class_name:<25} ‚Üí F1=0 BUG ‚Üí RETRAIN")
                needs_training.append((class_id, class_name, 'retrain'))
            else:
                print(f"  ‚úÖ  Class {class_id:2d}: {class_name:<25} ‚Üí Acc={acc:.3f} F1={f1_val:.3f} DONE")
                already_done.append((class_id, class_name))
        except Exception as e:
            print(f"  ‚ö†Ô∏è  Class {class_id:2d}: {class_name:<25} ‚Üí Corrupt metrics ‚Üí RETRAIN")
            needs_training.append((class_id, class_name, 'retrain'))
    else:
        print(f"  ‚ùå  Class {class_id:2d}: {class_name:<25} ‚Üí NOT TRAINED")
        needs_training.append((class_id, class_name, 'new'))

print(f"\n  ‚úÖ Already done     : {len(already_done)} classes")
print(f"  üîÑ Needs training   : {len(needs_training)} classes")

if len(needs_training) == 0:
    print("\nüéâ ALL CLASSES TRAINED! Nothing to do.")
    raise SystemExit()

print(f"\n  Will train:")
for cid, cname, reason in needs_training:
    print(f"    Class {cid:2d}: {cname} ({'NEW' if reason=='new' else 'FIX F1 BUG'})")

# ============================================================================
# 6. FEATURE EXTRACTION
# ============================================================================
def extract_roi_from_image(img_path, label_path):
    img = cv2.imread(str(img_path))
    if img is None:
        return []

    h, w = img.shape[:2]
    rois = []
    lp   = Path(label_path)

    if lp.exists() and lp.stat().st_size > 0:
        with open(lp, 'r') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) >= 5:
                    cid = int(parts[0])
                    xc  = float(parts[1]) * w
                    yc  = float(parts[2]) * h
                    bw  = float(parts[3]) * w
                    bh  = float(parts[4]) * h
                    x1  = int(max(0, xc - bw/2))
                    y1  = int(max(0, yc - bh/2))
                    x2  = int(min(w, xc + bw/2))
                    y2  = int(min(h, yc + bh/2))
                    if x2 > x1 and y2 > y1:
                        roi = img[y1:y2, x1:x2]
                        if roi.size > 0:
                            rois.append((roi, cid, (x1, y1, x2, y2)))
    else:
        # Negative sample ‚Äî use center crop
        cs = min(h, w) // 2
        ys, xs = h // 4, w // 4
        roi = img[ys:ys+cs, xs:xs+cs]
        if roi.size > 0:
            rois.append((roi, -1, (xs, ys, xs+cs, ys+cs)))

    return rois


def extract_features(roi):
    roi_r = cv2.resize(roi, TARGET_SIZE)
    gray  = cv2.cvtColor(roi_r, cv2.COLOR_BGR2GRAY)
    feats = []

    # HOG ‚Äî shape/edge structure
    hog_f = hog(gray, orientations=9, pixels_per_cell=(8, 8),
                cells_per_block=(2, 2), block_norm='L2-Hys', visualize=False)
    feats.extend(hog_f)

    # LBP ‚Äî texture
    lbp = local_binary_pattern(gray, 24, 3, method='uniform')
    lbp_h, _ = np.histogram(lbp.ravel(), bins=26, range=(0, 26), density=True)
    feats.extend(lbp_h)

    # Color histograms (RGB)
    for ch in range(3):
        h = cv2.calcHist([roi_r], [ch], None, [256], [0, 256]).flatten()
        feats.extend(h / (h.sum() + 1e-7))

    # Gabor filters ‚Äî oriented patterns
    for theta in [0, np.pi/4, np.pi/2, 3*np.pi/4]:
        fr, fi = gabor(gray, frequency=0.1, theta=theta)
        feats.extend([fr.mean(), fr.std(), fi.mean(), fi.std()])

    # Statistical moments
    g = gray.ravel()
    feats.extend([
        gray.mean(), gray.std(), gray.min(), gray.max(),
        float(skew(g)), float(kurtosis(g)),
        np.median(gray), np.percentile(gray, 25), np.percentile(gray, 75)
    ])

    # Edge features
    edges = cv2.Canny(gray, 50, 150)
    feats.extend([edges.mean(), edges.std(), (edges > 0).sum() / edges.size])

    return np.array(feats, dtype=np.float32)


def load_split(class_dir, split):
    """Load features + labels for one split"""
    img_dir = class_dir / split / 'images'
    lbl_dir = class_dir / split / 'labels'

    if not img_dir.exists():
        return np.array([]), np.array([]), []

    X, y, meta = [], [], []
    img_files = list(img_dir.glob('*.jpg')) + list(img_dir.glob('*.png'))

    for img_path in tqdm(img_files, desc=f"    {split:5s}", leave=False):
        lbl_path = lbl_dir / (img_path.stem + '.txt')
        rois = extract_roi_from_image(img_path, lbl_path)

        for roi, label, bbox in rois:
            try:
                feats = extract_features(roi)
                X.append(feats)
                y.append(1 if label == 0 else 0)  # 0 in label file = target class = positive
                meta.append({
                    'img_path':   str(img_path),
                    'bbox':       bbox,
                    'true_label': 1 if label == 0 else 0,
                    'roi':        roi.copy()
                })
            except:
                continue

    return np.array(X), np.array(y), meta


def load_dataset(class_id, class_name):
    class_dir = Path(DATASETS_DIR) / f"class_{class_id:02d}_{class_name}"
    if not class_dir.exists():
        print(f"  ‚ùå Not found: {class_dir}")
        return None, None

    print(f"\n  üì¶ Loading: {class_name}")
    X_tr, y_tr, _        = load_split(class_dir, 'train')
    X_val, y_val, val_meta = load_split(class_dir, 'valid')

    if len(X_tr) == 0:
        print(f"  ‚ùå No training data!")
        return None, None

    print(f"    Train  : {len(X_tr):>5} samples  ({int(y_tr.sum()):>4} positive, {int((y_tr==0).sum()):>4} negative)")
    print(f"    Valid  : {len(X_val):>5} samples  ({int(y_val.sum()):>4} positive, {int((y_val==0).sum()):>4} negative)")
    print(f"    Features: {X_tr.shape[1]} dimensions")

    if y_val.sum() == 0:
        print(f"    ‚ö†Ô∏è  WARNING: 0 positives in validation! F1 may be low.")

    return (X_tr, y_tr, X_val, y_val), val_meta

# ============================================================================
# 7. MODEL TRAINING
# ============================================================================
def train_all_models(X_tr, y_tr, X_val, y_val):
    results = {}

    # LightGBM
    print("    ‚ñ∂ LightGBM  ", end='', flush=True)
    try:
        t0 = time.time()
        m  = lgb.LGBMClassifier(
            n_estimators=200, learning_rate=0.05, max_depth=7,
            num_leaves=31, min_child_samples=10,
            subsample=0.8, colsample_bytree=0.8,
            class_weight='balanced',
            random_state=RANDOM_SEED, n_jobs=-1, verbose=-1
        )
        m.fit(X_tr, y_tr, eval_set=[(X_val, y_val)],
              callbacks=[lgb.early_stopping(20, verbose=False)])
        tt = time.time() - t0
        t0 = time.time(); _ = m.predict(X_val[:50])
        it = (time.time()-t0)/50*1000
        results['lightgbm'] = {'model': m, 'train_time': tt, 'inf_time': it}
        print(f"‚Üí {tt:.1f}s  {it:.3f}ms/sample ‚úÖ")
    except Exception as e:
        print(f"‚Üí ‚ùå {e}")

    # XGBoost
    print("    ‚ñ∂ XGBoost   ", end='', flush=True)
    try:
        t0 = time.time()
        m  = xgb.XGBClassifier(
            n_estimators=200, learning_rate=0.05, max_depth=7,
            subsample=0.8, colsample_bytree=0.8,
            scale_pos_weight=(y_tr==0).sum() / max(y_tr.sum(), 1),
            random_state=RANDOM_SEED, n_jobs=-1,
            tree_method='hist', device=XGBOOST_DEVICE,
            max_bin=128, verbosity=0
        )
        m.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=False)
        tt = time.time() - t0
        m.set_params(device='cpu')
        t0 = time.time(); _ = m.predict(X_val[:50])
        it = (time.time()-t0)/50*1000
        results['xgboost'] = {'model': m, 'train_time': tt, 'inf_time': it}
        print(f"‚Üí {tt:.1f}s  {it:.3f}ms/sample ‚úÖ")
    except Exception as e:
        print(f"‚Üí ‚ùå {e}")

    # CatBoost
    print("    ‚ñ∂ CatBoost  ", end='', flush=True)
    try:
        t0 = time.time()
        m  = CatBoostClassifier(
            iterations=200, learning_rate=0.05, depth=7, l2_leaf_reg=3,
            auto_class_weights='Balanced',
            random_seed=RANDOM_SEED, task_type=CATBOOST_TASK, verbose=False
        )
        m.fit(X_tr, y_tr, eval_set=(X_val, y_val),
              early_stopping_rounds=20, verbose=False)
        tt = time.time() - t0
        t0 = time.time(); _ = m.predict(X_val[:50])
        it = (time.time()-t0)/50*1000
        results['catboost'] = {'model': m, 'train_time': tt, 'inf_time': it}
        print(f"‚Üí {tt:.1f}s  {it:.3f}ms/sample ‚úÖ")
    except Exception as e:
        print(f"‚Üí ‚ùå {e}")

    # Random Forest
    print("    ‚ñ∂ RandForest", end='', flush=True)
    try:
        t0 = time.time()
        m  = RandomForestClassifier(
            n_estimators=100, max_depth=15,
            min_samples_split=10, min_samples_leaf=4,
            max_features='sqrt', class_weight='balanced',
            random_state=RANDOM_SEED, n_jobs=-1
        )
        m.fit(X_tr, y_tr)
        tt = time.time() - t0
        t0 = time.time(); _ = m.predict(X_val[:50])
        it = (time.time()-t0)/50*1000
        results['random_forest'] = {'model': m, 'train_time': tt, 'inf_time': it}
        print(f"‚Üí {tt:.1f}s  {it:.3f}ms/sample ‚úÖ")
    except Exception as e:
        print(f"‚Üí ‚ùå {e}")

    return results


def evaluate(model, X, y):
    yp    = model.predict(X)
    yprob = model.predict_proba(X)[:, 1] if hasattr(model, 'predict_proba') else yp.astype(float)
    return {
        'accuracy':  float(accuracy_score(y, yp)),
        'precision': float(precision_score(y, yp, zero_division=0)),
        'recall':    float(recall_score(y, yp, zero_division=0)),
        'f1_score':  float(f1_score(y, yp, zero_division=0)),
        'cm':        confusion_matrix(y, yp).tolist(),
        'preds':     yp.tolist(),
        'probs':     yprob.tolist()
    }


def pick_best_model(results, X_val, y_val):
    """Score = 50% F1 + 30% Recall + 20% speed (F1 & recall prioritised for defect detection)"""
    best_name, best_score = None, -1.0
    for name, res in results.items():
        met   = evaluate(res['model'], X_val, y_val)
        res['metrics'] = met
        spd   = 1.0 / (1.0 + res['inf_time'])
        score = 0.5 * met['f1_score'] + 0.3 * met['recall'] + 0.2 * spd
        if score > best_score:
            best_score = score
            best_name  = name
    return best_name, results

# ============================================================================
# 8. SAVE OUTPUTS
# ============================================================================
def save_outputs(class_id, class_name, best_name, results,
                 scaler, X_tr, X_val, y_val, val_meta, out_dir):
    out_dir.mkdir(parents=True, exist_ok=True)
    best     = results[best_name]
    best_met = best['metrics']

    # All models
    for name, res in results.items():
        with open(out_dir / f'model_{name}.pkl', 'wb') as f:
            pickle.dump({
                'model': res['model'], 'scaler': scaler,
                'metadata': {
                    'class_id': class_id, 'class_name': class_name,
                    'model_type': name, 'feature_dim': int(X_tr.shape[1])
                }
            }, f)

    # Best model
    with open(out_dir / 'best_model.pkl', 'wb') as f:
        pickle.dump({
            'model': best['model'], 'scaler': scaler,
            'metadata': {
                'class_id': class_id, 'class_name': class_name,
                'model_type': best_name, 'feature_dim': int(X_tr.shape[1]),
                'metrics': best_met
            }
        }, f)
    size_mb = os.path.getsize(out_dir / 'best_model.pkl') / 1e6
    print(f"    üíæ best_model.pkl saved  ({size_mb:.2f} MB)")

    # Metrics JSON
    with open(out_dir / 'metrics.json', 'w') as f:
        json.dump({
            'best_model': best_name,
            'eval_set':   'validation',
            'models': {
                n: {
                    'accuracy':        r['metrics']['accuracy'],
                    'precision':       r['metrics']['precision'],
                    'recall':          r['metrics']['recall'],
                    'f1_score':        r['metrics']['f1_score'],
                    'train_time':      r['train_time'],
                    'inference_time':  r['inf_time']
                }
                for n, r in results.items() if 'metrics' in r
            }
        }, f, indent=2)

    # Confusion matrix
    cm = np.array(best_met['cm'])
    fig, ax = plt.subplots(figsize=(6, 5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=['Negative', 'Positive'],
                yticklabels=['Negative', 'Positive'])
    ax.set_title(
        f'{class_name} ‚Äî {best_name.upper()}\n'
        f'Acc={best_met["accuracy"]:.3f}  '
        f'F1={best_met["f1_score"]:.3f}  '
        f'Recall={best_met["recall"]:.3f}',
        fontweight='bold', fontsize=11
    )
    plt.tight_layout()
    plt.savefig(out_dir / 'confusion_matrix.png', dpi=150)
    plt.close()

    # Validation predictions visualization
    imgs_dict = defaultdict(list)
    for i, meta in enumerate(val_meta):
        if i < len(best_met['preds']):
            meta['pred_label'] = best_met['preds'][i]
            meta['confidence'] = best_met['probs'][i]
            imgs_dict[meta['img_path']].append(meta)

    unique_imgs = list(imgs_dict.keys())[:12]
    if unique_imgs:
        n_cols = min(4, len(unique_imgs))
        n_rows = max(1, (len(unique_imgs) + n_cols - 1) // n_cols)
        fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 5*n_rows))
        axes = np.array(axes).flatten()
        fig.suptitle(
            f'Validation Predictions: {class_name}\n'
            f'üü¢ Correct  üî¥ Wrong  |  '
            f'Acc={best_met["accuracy"]:.3f}  F1={best_met["f1_score"]:.3f}',
            fontsize=13, fontweight='bold'
        )
        for idx, img_path in enumerate(unique_imgs):
            img = cv2.imread(img_path)
            if img is None:
                continue
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            for meta in imgs_dict[img_path]:
                x1, y1, x2, y2 = meta['bbox']
                correct = (meta['true_label'] == meta['pred_label'])
                col     = (0, 200, 0) if correct else (220, 0, 0)
                cv2.rectangle(img_rgb, (x1, y1), (x2, y2), col, 3)
                lbl = f"{'‚úì' if correct else '‚úó'} {'POS' if meta['pred_label']==1 else 'NEG'} {meta['confidence']:.2f}"
                cv2.putText(img_rgb, lbl, (x1, max(18, y1-6)),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, col, 2)
            axes[idx].imshow(img_rgb)
            axes[idx].set_title(Path(img_path).name[:30], fontsize=8)
            axes[idx].axis('off')
        for idx in range(len(unique_imgs), len(axes)):
            axes[idx].axis('off')
        plt.tight_layout()
        plt.savefig(out_dir / 'validation_predictions.png', dpi=150, bbox_inches='tight')
        plt.close()
        print(f"    üñºÔ∏è  validation_predictions.png saved")

    # Training log text
    with open(out_dir / 'training_log.txt', 'w') as f:
        f.write(f"Class {class_id}: {class_name}\n")
        f.write(f"Evaluated on: VALIDATION SET\n")
        f.write(f"Best Model  : {best_name}\n\n")
        f.write(f"{'Model':<15} {'Acc':>8} {'F1':>8} {'Recall':>8} {'Prec':>8} {'ms':>8}\n")
        f.write("-"*60 + "\n")
        for n, r in results.items():
            if 'metrics' in r:
                m = r['metrics']
                marker = " ‚≠ê" if n == best_name else ""
                f.write(f"{n:<15} {m['accuracy']:>8.4f} {m['f1_score']:>8.4f} "
                        f"{m['recall']:>8.4f} {m['precision']:>8.4f} "
                        f"{r['inf_time']:>8.3f}{marker}\n")

# ============================================================================
# 9. MAIN TRAINING LOOP
# ============================================================================
print("\n" + "="*70)
print("üöÄ STARTING TRAINING")
print("="*70)

session_results = []

for class_id, class_name, reason in needs_training:
    print(f"\n{'='*70}")
    print(f"üéØ CLASS {class_id}: {class_name}  ({'NEW' if reason=='new' else 'RETRAIN ‚Äî FIX F1 BUG'})")
    print(f"{'='*70}")

    try:
        # Load data
        dataset, val_meta = load_dataset(class_id, class_name)
        if dataset is None:
            continue

        X_tr, y_tr, X_val, y_val = dataset

        # Scale features
        scaler  = StandardScaler()
        X_tr_s  = scaler.fit_transform(X_tr)
        X_val_s = scaler.transform(X_val)

        # SMOTE for class imbalance
        n_pos = int(y_tr.sum())
        if n_pos >= 5:
            k = min(5, n_pos - 1)
            print(f"  ‚öôÔ∏è  SMOTE (k={k}): {n_pos} pos + {len(y_tr)-n_pos} neg ", end='')
            smote   = SMOTE(random_state=RANDOM_SEED, k_neighbors=k)
            X_tr_s, y_tr = smote.fit_resample(X_tr_s, y_tr)
            print(f"‚Üí {len(y_tr)} balanced samples")
        else:
            print(f"  ‚ö†Ô∏è  Too few positives ({n_pos}) for SMOTE ‚Äî training as-is")

        # Train
        print(f"\n  üöÄ Training models (GPU={GPU_AVAILABLE}):")
        results = train_all_models(X_tr_s, y_tr, X_val_s, y_val)

        if not results:
            print("  ‚ùå All models failed!")
            continue

        # Pick best
        best_name, results = pick_best_model(results, X_val_s, y_val)
        best_met = results[best_name]['metrics']

        print(f"\n  üèÜ Best model : {best_name.upper()}")
        print(f"     Accuracy   : {best_met['accuracy']:.4f}")
        print(f"     Precision  : {best_met['precision']:.4f}")
        print(f"     Recall     : {best_met['recall']:.4f}")
        print(f"     F1 Score   : {best_met['f1_score']:.4f}")
        print(f"     Inference  : {results[best_name]['inf_time']:.3f} ms/sample")

        # Save everything to Drive
        print(f"\n  üíæ Saving to Drive...")
        out_dir = Path(OUTPUT_DIR) / f"class_{class_id:02d}_{class_name}"
        save_outputs(class_id, class_name, best_name, results,
                     scaler, X_tr, X_val_s, y_val, val_meta, out_dir)

        session_results.append({
            'class_id':    class_id,
            'class_name':  class_name,
            'best_model':  best_name,
            'accuracy':    best_met['accuracy'],
            'precision':   best_met['precision'],
            'recall':      best_met['recall'],
            'f1_score':    best_met['f1_score'],
            'inf_time_ms': results[best_name]['inf_time'],
            'train_n':     len(X_tr),
            'val_n':       len(X_val)
        })

        print(f"\n  ‚úÖ {class_name} COMPLETE ‚Äî saved to Drive!")

    except Exception as e:
        import traceback
        print(f"\n  ‚ùå ERROR on {class_name}: {e}")
        traceback.print_exc()
        continue

# ============================================================================
# 10. MASTER SUMMARY ‚Äî reads all 15 classes from Drive
# ============================================================================
print("\n" + "="*70)
print("üìä MASTER SUMMARY")
print("="*70)

all_metrics = []
for class_id, class_name in CLASS_NAMES.items():
    mp = Path(OUTPUT_DIR) / f"class_{class_id:02d}_{class_name}" / "metrics.json"
    if mp.exists():
        try:
            with open(mp) as f:
                m = json.load(f)
            best = m['best_model']
            all_metrics.append({
                'class_id':   class_id,
                'class_name': class_name,
                'best_model': best,
                'accuracy':   m['models'][best]['accuracy'],
                'precision':  m['models'][best]['precision'],
                'recall':     m['models'][best]['recall'],
                'f1_score':   m['models'][best]['f1_score'],
                'inf_ms':     m['models'][best]['inference_time'],
            })
        except:
            pass

if all_metrics:
    df = pd.DataFrame(all_metrics).sort_values('class_id')
    df.to_csv(f'{OUTPUT_DIR}/MASTER_TRAINING_SUMMARY.csv', index=False)

    print(f"\n{'':>3} {'Class':<25} {'Best Model':<13} {'Acc':>6} {'F1':>6} {'Recall':>7} {'ms':>6} {'Status'}")
    print("-"*78)
    for _, r in df.iterrows():
        flag = "‚úÖ" if r['f1_score'] > 0 else "‚ö†Ô∏è F1=0"
        print(f"  {int(r['class_id']):>2}  {r['class_name']:<25} {r['best_model']:<13} "
              f"{r['accuracy']:>6.3f} {r['f1_score']:>6.3f} {r['recall']:>7.3f} "
              f"{r['inf_ms']:>6.3f}  {flag}")

    # Summary charts
    fig, axes = plt.subplots(1, 3, figsize=(21, 7))
    fig.suptitle('Road Defect Detection ‚Äî Master Training Summary (All 15 Classes)',
                 fontsize=15, fontweight='bold')

    bar_colors = ['#2ECC71' if v > 0 else '#E74C3C' for v in df['f1_score']]

    axes[0].barh(df['class_name'], df['accuracy'], color='steelblue')
    axes[0].axvline(0.9, color='red', linestyle='--', linewidth=1.5, label='90% target')
    axes[0].set_xlabel('Accuracy'); axes[0].set_title('Accuracy', fontweight='bold')
    axes[0].legend(); axes[0].grid(axis='x', alpha=0.3)

    axes[1].barh(df['class_name'], df['f1_score'], color=bar_colors)
    axes[1].set_xlabel('F1 Score')
    axes[1].set_title('F1 Score  (üî¥ = still zero = needs fix)', fontweight='bold')
    axes[1].grid(axis='x', alpha=0.3)

    axes[2].barh(df['class_name'], df['inf_ms'], color='orange')
    axes[2].axvline(10, color='red', linestyle='--', linewidth=1.5, label='10ms limit')
    axes[2].set_xlabel('ms / sample')
    axes[2].set_title('Inference Speed', fontweight='bold')
    axes[2].legend(); axes[2].grid(axis='x', alpha=0.3)

    plt.tight_layout()
    plt.savefig(f'{OUTPUT_DIR}/MASTER_SUMMARY_CHART.png', dpi=150, bbox_inches='tight')
    plt.close()
    print(f"\n  üìä MASTER_SUMMARY_CHART.png saved to Drive")

    trained   = len(df[df['f1_score'] > 0])
    remaining = len(df[df['f1_score'] == 0])
    print(f"\n  ‚úÖ Properly trained (F1 > 0) : {trained} / {len(df)} classes")
    if remaining:
        print(f"  ‚ö†Ô∏è  Still need fixing (F1 = 0): {remaining} classes ‚Üí re-run this script")

print(f"\nüíæ All outputs: {OUTPUT_DIR}")
print("\n" + "="*70)
print("üéâ SCRIPT COMPLETE!")
print("="*70)

11-02-26

#remaining part

"""
================================================================================
STEP 4: FIX MISSING LOGS + PERFORMANCE TEST ‚Äî ALL 15 CLASSES
================================================================================
- Fixes missing training_log.txt for classes 8, 9, 14 (Drive sync bug)
- Skips all already-done work
- Tests all 15 models on validation data
- Shows per-class performance + master summary
- Saves all outputs to same 03_Trained_Models directory
================================================================================
"""

import subprocess, sys
print("üì¶ Installing packages...")
for pkg in ['lightgbm', 'xgboost', 'catboost', 'scikit-image', 'tqdm']:
    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', pkg])
print("‚úÖ Done\n")

import os, cv2, pickle, json, time, warnings
import numpy as np
import pandas as pd
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from collections import defaultdict
from tqdm.auto import tqdm
warnings.filterwarnings('ignore')

from sklearn.metrics import (accuracy_score, precision_score, recall_score,
                             f1_score, confusion_matrix, classification_report)
from skimage.feature import hog, local_binary_pattern
from skimage.filters import gabor
from scipy.stats import skew, kurtosis
from google.colab import drive

# ============================================================================
# MOUNT DRIVE
# ============================================================================
drive.mount('/content/drive')

OUTPUT_DIR   = '/content/drive/MyDrive/Road_Defect_Project/03_Trained_Models'
DATASETS_DIR = '/content/drive/MyDrive/Road_Defect_Project/02_Per_Class_Datasets'

CLASS_NAMES = {
    0:  'Big_Culvert',        1:  'Blocked_culvert',
    2:  'Cause_ways',         3:  'Crack',
    4:  'Culvert',            5:  'Damaged_surface_layer',
    6:  'Drainage_cover',     7:  'Edge_breaking',
    8:  'Guard_stone',        9:  'Not_painted_gs',
    10: 'Not_whitewashed',    11: 'Patching',
    12: 'Ravelling',          13: 'km_stone',
    14: 'pothole'
}

TARGET_SIZE = (128, 128)

# ============================================================================
# STEP 1: FIX MISSING TRAINING LOGS (classes 8, 9, 14)
# ============================================================================
print("=" * 70)
print("STEP 1: FIXING MISSING TRAINING LOGS")
print("=" * 70)

for class_id, class_name in CLASS_NAMES.items():
    out_dir      = Path(OUTPUT_DIR) / f"class_{class_id:02d}_{class_name}"
    log_path     = out_dir / 'training_log.txt'
    metrics_path = out_dir / 'metrics.json'

    if not out_dir.exists():
        print(f"  ‚ùå Class {class_id:2d}: {class_name:<25} ‚Üí folder missing!")
        continue

    if log_path.exists():
        print(f"  ‚úÖ Class {class_id:2d}: {class_name:<25} ‚Üí log OK")
        continue

    # Fix: create missing log from metrics.json
    out_dir.mkdir(parents=True, exist_ok=True)
    try:
        with open(metrics_path) as f:
            m = json.load(f)
        best = m['best_model']
        bm   = m['models'][best]

        with open(log_path, 'w') as f:
            f.write(f"Class {class_id}: {class_name}\n")
            f.write(f"Evaluated on : VALIDATION SET\n")
            f.write(f"Best Model   : {best}\n\n")
            f.write(f"{'Model':<15} {'Acc':>8} {'F1':>8} {'Recall':>8} {'Prec':>8} {'ms':>8}\n")
            f.write("-" * 60 + "\n")
            for n, r in m['models'].items():
                marker = " ‚≠ê" if n == best else ""
                f.write(f"{n:<15} {r['accuracy']:>8.4f} {r['f1_score']:>8.4f} "
                        f"{r['recall']:>8.4f} {r['precision']:>8.4f} "
                        f"{r['inference_time']:>8.3f}{marker}\n")

        print(f"  üîß Class {class_id:2d}: {class_name:<25} ‚Üí log FIXED ‚úÖ")

    except Exception as e:
        print(f"  ‚ùå Class {class_id:2d}: {class_name:<25} ‚Üí could not fix: {e}")

# ============================================================================
# FEATURE EXTRACTION (same as training ‚Äî must match exactly)
# ============================================================================
def extract_roi_from_image(img_path, label_path):
    img = cv2.imread(str(img_path))
    if img is None:
        return []
    h, w = img.shape[:2]
    rois = []
    lp   = Path(label_path)

    if lp.exists() and lp.stat().st_size > 0:
        with open(lp) as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) >= 5:
                    cid = int(parts[0])
                    xc  = float(parts[1]) * w
                    yc  = float(parts[2]) * h
                    bw  = float(parts[3]) * w
                    bh  = float(parts[4]) * h
                    x1  = int(max(0, xc - bw/2))
                    y1  = int(max(0, yc - bh/2))
                    x2  = int(min(w, xc + bw/2))
                    y2  = int(min(h, yc + bh/2))
                    if x2 > x1 and y2 > y1:
                        roi = img[y1:y2, x1:x2]
                        if roi.size > 0:
                            rois.append((roi, cid, (x1, y1, x2, y2)))
    else:
        cs = min(h, w) // 2
        ys, xs = h // 4, w // 4
        roi = img[ys:ys+cs, xs:xs+cs]
        if roi.size > 0:
            rois.append((roi, -1, (xs, ys, xs+cs, ys+cs)))
    return rois


def extract_features(roi):
    roi_r = cv2.resize(roi, TARGET_SIZE)
    gray  = cv2.cvtColor(roi_r, cv2.COLOR_BGR2GRAY)
    feats = []

    hog_f = hog(gray, orientations=9, pixels_per_cell=(8, 8),
                cells_per_block=(2, 2), block_norm='L2-Hys', visualize=False)
    feats.extend(hog_f)

    lbp = local_binary_pattern(gray, 24, 3, method='uniform')
    lbp_h, _ = np.histogram(lbp.ravel(), bins=26, range=(0, 26), density=True)
    feats.extend(lbp_h)

    for ch in range(3):
        h = cv2.calcHist([roi_r], [ch], None, [256], [0, 256]).flatten()
        feats.extend(h / (h.sum() + 1e-7))

    for theta in [0, np.pi/4, np.pi/2, 3*np.pi/4]:
        fr, fi = gabor(gray, frequency=0.1, theta=theta)
        feats.extend([fr.mean(), fr.std(), fi.mean(), fi.std()])

    g = gray.ravel()
    feats.extend([gray.mean(), gray.std(), gray.min(), gray.max(),
                  float(skew(g)), float(kurtosis(g)),
                  np.median(gray), np.percentile(gray, 25), np.percentile(gray, 75)])

    edges = cv2.Canny(gray, 50, 150)
    feats.extend([edges.mean(), edges.std(), (edges > 0).sum() / edges.size])

    return np.array(feats, dtype=np.float32)


def load_validation_set(class_id, class_name):
    """Load validation images fresh for testing"""
    class_dir = Path(DATASETS_DIR) / f"class_{class_id:02d}_{class_name}"
    img_dir   = class_dir / 'valid' / 'images'
    lbl_dir   = class_dir / 'valid' / 'labels'

    if not img_dir.exists():
        return None, None, None

    X, y, meta = [], [], []
    img_files  = list(img_dir.glob('*.jpg')) + list(img_dir.glob('*.png'))

    for img_path in tqdm(img_files, desc=f"  Loading {class_name}", leave=False):
        lbl_path = lbl_dir / (img_path.stem + '.txt')
        rois = extract_roi_from_image(img_path, lbl_path)
        for roi, label, bbox in rois:
            try:
                feats = extract_features(roi)
                X.append(feats)
                y.append(1 if label == 0 else 0)
                meta.append({
                    'img_path':   str(img_path),
                    'bbox':       bbox,
                    'true_label': 1 if label == 0 else 0,
                    'roi':        roi.copy()
                })
            except:
                continue

    if not X:
        return None, None, None

    return np.array(X), np.array(y), meta

# ============================================================================
# STEP 2: PERFORMANCE TEST ‚Äî ALL 15 CLASSES
# ============================================================================
print("\n" + "=" * 70)
print("STEP 2: PERFORMANCE TESTING ALL 15 MODELS")
print("=" * 70)

all_results = []

for class_id, class_name in CLASS_NAMES.items():
    model_path = Path(OUTPUT_DIR) / f"class_{class_id:02d}_{class_name}" / "best_model.pkl"

    if not model_path.exists():
        print(f"\n  ‚ùå Class {class_id}: {class_name} ‚Äî model not found, skipping")
        continue

    print(f"\n  üîç Testing Class {class_id}: {class_name}")

    # Load model
    with open(model_path, 'rb') as f:
        pkg = pickle.load(f)
    model   = pkg['model']
    scaler  = pkg['scaler']
    meta_info = pkg['metadata']

    # Load validation data fresh
    X_val, y_val, val_meta = load_validation_set(class_id, class_name)

    if X_val is None:
        print(f"     ‚ö†Ô∏è  No validation data found")
        continue

    # Scale using saved scaler
    X_val_s = scaler.transform(X_val)

    # Run inference + time it
    t0    = time.time()
    y_pred = model.predict(X_val_s)
    total_time = (time.time() - t0) * 1000  # ms
    per_sample_ms = total_time / len(X_val_s)

    y_proba = model.predict_proba(X_val_s)[:, 1] if hasattr(model, 'predict_proba') else y_pred.astype(float)

    # Metrics
    acc  = accuracy_score(y_val, y_pred)
    prec = precision_score(y_val, y_pred, zero_division=0)
    rec  = recall_score(y_val, y_pred, zero_division=0)
    f1   = f1_score(y_val, y_pred, zero_division=0)
    cm   = confusion_matrix(y_val, y_pred)

    n_pos = int(y_val.sum())
    n_neg = int((y_val == 0).sum())
    tp = cm[1, 1] if cm.shape == (2, 2) else 0
    fp = cm[0, 1] if cm.shape == (2, 2) else 0
    fn = cm[1, 0] if cm.shape == (2, 2) else 0
    tn = cm[0, 0] if cm.shape == (2, 2) else 0

    model_size_mb = os.path.getsize(model_path) / 1e6

    print(f"     Samples    : {len(X_val)} ({n_pos} positive, {n_neg} negative)")
    print(f"     Accuracy   : {acc:.4f}  {'‚úÖ' if acc >= 0.90 else '‚ö†Ô∏è '}")
    print(f"     Precision  : {prec:.4f}")
    print(f"     Recall     : {rec:.4f}")
    print(f"     F1 Score   : {f1:.4f}  {'‚úÖ' if f1 >= 0.85 else '‚ö†Ô∏è '}")
    print(f"     TP={tp}  FP={fp}  TN={tn}  FN={fn}")
    print(f"     Inference  : {per_sample_ms:.3f} ms/sample  {'‚úÖ' if per_sample_ms < 10 else '‚ö†Ô∏è '}")
    print(f"     Model size : {model_size_mb:.2f} MB")
    print(f"     Best model : {meta_info['model_type']}")

    all_results.append({
        'class_id':     class_id,
        'class_name':   class_name,
        'model_type':   meta_info['model_type'],
        'n_val_samples': len(X_val),
        'n_positive':   n_pos,
        'n_negative':   n_neg,
        'accuracy':     acc,
        'precision':    prec,
        'recall':       rec,
        'f1_score':     f1,
        'tp': tp, 'fp': fp, 'tn': tn, 'fn': fn,
        'inf_ms':       per_sample_ms,
        'model_size_mb': model_size_mb,
        'acc_pass':     acc >= 0.90,
        'f1_pass':      f1 >= 0.85,
        'speed_pass':   per_sample_ms < 10,
    })

    # Save per-class prediction viz (overwrite if exists)
    out_dir = Path(OUTPUT_DIR) / f"class_{class_id:02d}_{class_name}"
    imgs_dict = defaultdict(list)
    for i, meta in enumerate(val_meta):
        meta['pred_label'] = int(y_pred[i])
        meta['confidence'] = float(y_proba[i])
        imgs_dict[meta['img_path']].append(meta)

    unique_imgs = list(imgs_dict.keys())[:12]
    if unique_imgs:
        n_cols = min(4, len(unique_imgs))
        n_rows = max(1, (len(unique_imgs) + n_cols - 1) // n_cols)
        fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 5*n_rows))
        axes = np.array(axes).flatten()
        fig.suptitle(
            f'Performance Test: {class_name}  [{meta_info["model_type"].upper()}]\n'
            f'Acc={acc:.3f}  F1={f1:.3f}  Recall={rec:.3f}  Prec={prec:.3f}',
            fontsize=12, fontweight='bold'
        )
        for idx, img_path in enumerate(unique_imgs):
            img = cv2.imread(img_path)
            if img is None:
                axes[idx].axis('off')
                continue
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            for m in imgs_dict[img_path]:
                x1, y1, x2, y2 = m['bbox']
                correct = (m['true_label'] == m['pred_label'])
                col = (0, 200, 0) if correct else (220, 0, 0)
                cv2.rectangle(img_rgb, (x1, y1), (x2, y2), col, 3)
                lbl = f"{'‚úì' if correct else '‚úó'} {'POS' if m['pred_label']==1 else 'NEG'} {m['confidence']:.2f}"
                cv2.putText(img_rgb, lbl, (x1, max(18, y1-6)),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.55, col, 2)
            axes[idx].imshow(img_rgb)
            axes[idx].set_title(Path(img_path).name[:28], fontsize=8)
            axes[idx].axis('off')
        for idx in range(len(unique_imgs), len(axes)):
            axes[idx].axis('off')
        plt.tight_layout()
        plt.savefig(out_dir / 'performance_test_visualization.png', dpi=150, bbox_inches='tight')
        plt.close()

# ============================================================================
# STEP 3: MASTER SUMMARY TABLE + CHARTS
# ============================================================================
print("\n" + "=" * 70)
print("STEP 3: MASTER PERFORMANCE SUMMARY")
print("=" * 70)

df = pd.DataFrame(all_results).sort_values('class_id').reset_index(drop=True)
df.to_csv(f'{OUTPUT_DIR}/PERFORMANCE_TEST_SUMMARY.csv', index=False)

# Print table
print(f"\n{'ID':>3}  {'Class':<25} {'Model':<12} {'Acc':>6} {'F1':>6} {'Recall':>7} {'Prec':>7} {'ms':>6}  Status")
print("-" * 85)
for _, r in df.iterrows():
    passes = all([r['acc_pass'], r['f1_pass'], r['speed_pass']])
    status = "‚úÖ PASS" if passes else "‚ö†Ô∏è  REVIEW"
    print(f"  {int(r['class_id']):>2}  {r['class_name']:<25} {r['model_type']:<12} "
          f"{r['accuracy']:>6.3f} {r['f1_score']:>6.3f} {r['recall']:>7.3f} "
          f"{r['precision']:>7.3f} {r['inf_ms']:>6.3f}  {status}")

print("\n" + "-" * 85)
avg_acc = df['accuracy'].mean()
avg_f1  = df['f1_score'].mean()
avg_ms  = df['inf_ms'].mean()
print(f"  {'AVERAGE':<30} {avg_acc:>6.3f} {avg_f1:>6.3f} {'':>7} {'':>7} {avg_ms:>6.3f}")
print(f"\n  ‚úÖ Accuracy ‚â• 90% : {df['acc_pass'].sum()}/{len(df)} classes")
print(f"  ‚úÖ F1 ‚â• 85%       : {df['f1_pass'].sum()}/{len(df)} classes")
print(f"  ‚úÖ Speed < 10ms   : {df['speed_pass'].sum()}/{len(df)} classes")
print(f"  üì¶ Total model size: {df['model_size_mb'].sum():.2f} MB across all 15 models")

# ============================================================================
# CHARTS
# ============================================================================
fig, axes = plt.subplots(2, 2, figsize=(20, 14))
fig.suptitle('Road Defect Detection ‚Äî Performance Test Results (All 15 Classes)',
             fontsize=16, fontweight='bold')

# 1. Accuracy
ax = axes[0, 0]
colors = ['#2ECC71' if v else '#E74C3C' for v in df['acc_pass']]
bars = ax.barh(df['class_name'], df['accuracy'], color=colors)
ax.axvline(0.90, color='red', linestyle='--', linewidth=2, label='90% target')
for bar, val in zip(bars, df['accuracy']):
    ax.text(min(val + 0.005, 1.02), bar.get_y() + bar.get_height()/2,
            f'{val:.3f}', va='center', fontsize=9, fontweight='bold')
ax.set_xlim(0, 1.1)
ax.set_title('Accuracy per Class', fontweight='bold', fontsize=13)
ax.set_xlabel('Accuracy')
ax.legend(); ax.grid(axis='x', alpha=0.3)

# 2. F1 Score
ax = axes[0, 1]
colors = ['#2ECC71' if v else '#E74C3C' for v in df['f1_pass']]
bars = ax.barh(df['class_name'], df['f1_score'], color=colors)
ax.axvline(0.85, color='red', linestyle='--', linewidth=2, label='85% target')
for bar, val in zip(bars, df['f1_score']):
    ax.text(min(val + 0.005, 1.02), bar.get_y() + bar.get_height()/2,
            f'{val:.3f}', va='center', fontsize=9, fontweight='bold')
ax.set_xlim(0, 1.1)
ax.set_title('F1 Score per Class', fontweight='bold', fontsize=13)
ax.set_xlabel('F1 Score')
ax.legend(); ax.grid(axis='x', alpha=0.3)

# 3. Precision vs Recall scatter
ax = axes[1, 0]
scatter = ax.scatter(df['recall'], df['precision'],
                     c=df['f1_score'], cmap='RdYlGn',
                     s=150, zorder=5, vmin=0.5, vmax=1.0)
for _, row in df.iterrows():
    ax.annotate(row['class_name'][:10],
                (row['recall'], row['precision']),
                fontsize=7, ha='left', va='bottom',
                xytext=(4, 4), textcoords='offset points')
plt.colorbar(scatter, ax=ax, label='F1 Score')
ax.axhline(0.85, color='gray', linestyle='--', alpha=0.5)
ax.axvline(0.85, color='gray', linestyle='--', alpha=0.5)
ax.set_xlabel('Recall', fontweight='bold')
ax.set_ylabel('Precision', fontweight='bold')
ax.set_title('Precision vs Recall', fontweight='bold', fontsize=13)
ax.set_xlim(0, 1.1); ax.set_ylim(0, 1.1)
ax.grid(alpha=0.3)

# 4. Inference speed
ax = axes[1, 1]
colors = ['#2ECC71' if v else '#E74C3C' for v in df['speed_pass']]
bars = ax.barh(df['class_name'], df['inf_ms'], color=colors)
ax.axvline(10, color='red', linestyle='--', linewidth=2, label='10ms limit')
for bar, val in zip(bars, df['inf_ms']):
    ax.text(val + 0.01, bar.get_y() + bar.get_height()/2,
            f'{val:.3f}ms', va='center', fontsize=9, fontweight='bold')
ax.set_title('Inference Speed per Class', fontweight='bold', fontsize=13)
ax.set_xlabel('ms / sample')
ax.legend(); ax.grid(axis='x', alpha=0.3)

plt.tight_layout()
plt.savefig(f'{OUTPUT_DIR}/PERFORMANCE_TEST_CHART.png', dpi=150, bbox_inches='tight')
plt.close()
print(f"\n  üìä PERFORMANCE_TEST_CHART.png saved")

# ============================================================================
# FINAL STATUS
# ============================================================================
print("\n" + "=" * 70)
print("üéØ FINAL STATUS")
print("=" * 70)

needs_attention = df[~(df['acc_pass'] & df['f1_pass'])]
if len(needs_attention) == 0:
    print("\n  üéâ ALL 15 CLASSES PASS accuracy AND F1 targets!")
else:
    print(f"\n  ‚ö†Ô∏è  {len(needs_attention)} classes need attention:")
    for _, r in needs_attention.iterrows():
        issues = []
        if not r['acc_pass']: issues.append(f"Acc={r['accuracy']:.3f} (<0.90)")
        if not r['f1_pass']:  issues.append(f"F1={r['f1_score']:.3f} (<0.85)")
        print(f"     Class {int(r['class_id']):2d}: {r['class_name']:<25} ‚Üí {', '.join(issues)}")

print(f"\n  Average Accuracy : {avg_acc:.4f}")
print(f"  Average F1 Score : {avg_f1:.4f}")
print(f"  Average Inference: {avg_ms:.4f} ms/sample")
print(f"  Total model size : {df['model_size_mb'].sum():.2f} MB")

print(f"\nüíæ All outputs saved to: {OUTPUT_DIR}")
print("   ‚îú‚îÄ‚îÄ PERFORMANCE_TEST_SUMMARY.csv")
print("   ‚îú‚îÄ‚îÄ PERFORMANCE_TEST_CHART.png")
print("   ‚îî‚îÄ‚îÄ class_XX_*/performance_test_visualization.png")

print("\n" + "=" * 70)
print("‚úÖ DONE ‚Äî READY FOR INFERENCE PIPELINE!")
print("=" * 70)



"""#test"""

"""
================================================================================
STEP 5: TEST SET EVALUATION ‚Äî HOW MODELS DETECT ON UNSEEN IMAGES
================================================================================
- Loads each class best_model.pkl from Drive
- Runs on TEST set images (never seen during training or validation)
- Draws bounding boxes on real images showing detections
- Green box = correctly detected defect
- Red box   = missed or wrong prediction
- Saves visual results + metrics to Drive
================================================================================
"""

import subprocess, sys
print("üì¶ Installing packages...")
for pkg in ['lightgbm', 'xgboost', 'catboost', 'scikit-image', 'tqdm']:
    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', pkg])
print("‚úÖ Done\n")

import os, cv2, pickle, json, time, warnings
import numpy as np
import pandas as pd
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from collections import defaultdict
from tqdm.auto import tqdm
warnings.filterwarnings('ignore')

from sklearn.metrics import (accuracy_score, precision_score,
                             recall_score, f1_score, confusion_matrix)
from skimage.feature import hog, local_binary_pattern
from skimage.filters import gabor
from scipy.stats import skew, kurtosis
from google.colab import drive

# ============================================================================
# MOUNT DRIVE
# ============================================================================
drive.mount('/content/drive')

OUTPUT_DIR   = '/content/drive/MyDrive/Road_Defect_Project/03_Trained_Models'
DATASETS_DIR = '/content/drive/MyDrive/Road_Defect_Project/02_Per_Class_Datasets'
TEST_VIZ_DIR = '/content/drive/MyDrive/Road_Defect_Project/05_Test_Results'
os.makedirs(TEST_VIZ_DIR, exist_ok=True)

CLASS_NAMES = {
    0:  'Big_Culvert',        1:  'Blocked_culvert',
    2:  'Cause_ways',         3:  'Crack',
    4:  'Culvert',            5:  'Damaged_surface_layer',
    6:  'Drainage_cover',     7:  'Edge_breaking',
    8:  'Guard_stone',        9:  'Not_painted_gs',
    10: 'Not_whitewashed',    11: 'Patching',
    12: 'Ravelling',          13: 'km_stone',
    14: 'pothole'
}

TARGET_SIZE = (128, 128)

# ============================================================================
# FEATURE EXTRACTION ‚Äî same as training, must match exactly
# ============================================================================
def extract_roi_from_image(img_path, label_path):
    img = cv2.imread(str(img_path))
    if img is None:
        return []
    h, w = img.shape[:2]
    rois = []
    lp   = Path(label_path)

    if lp.exists() and lp.stat().st_size > 0:
        with open(lp) as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) >= 5:
                    cid = int(parts[0])
                    xc  = float(parts[1]) * w
                    yc  = float(parts[2]) * h
                    bw  = float(parts[3]) * w
                    bh  = float(parts[4]) * h
                    x1  = int(max(0, xc - bw/2))
                    y1  = int(max(0, yc - bh/2))
                    x2  = int(min(w, xc + bw/2))
                    y2  = int(min(h, yc + bh/2))
                    if x2 > x1 and y2 > y1:
                        roi = img[y1:y2, x1:x2]
                        if roi.size > 0:
                            rois.append((roi, cid, (x1, y1, x2, y2)))
    else:
        cs = min(h, w) // 2
        ys, xs = h // 4, w // 4
        roi = img[ys:ys+cs, xs:xs+cs]
        if roi.size > 0:
            rois.append((roi, -1, (xs, ys, xs+cs, ys+cs)))
    return rois


def extract_features(roi):
    roi_r = cv2.resize(roi, TARGET_SIZE)
    gray  = cv2.cvtColor(roi_r, cv2.COLOR_BGR2GRAY)
    feats = []

    hog_f = hog(gray, orientations=9, pixels_per_cell=(8,8),
                cells_per_block=(2,2), block_norm='L2-Hys', visualize=False)
    feats.extend(hog_f)

    lbp   = local_binary_pattern(gray, 24, 3, method='uniform')
    lbp_h, _ = np.histogram(lbp.ravel(), bins=26, range=(0,26), density=True)
    feats.extend(lbp_h)

    for ch in range(3):
        h = cv2.calcHist([roi_r], [ch], None, [256], [0,256]).flatten()
        feats.extend(h / (h.sum() + 1e-7))

    for theta in [0, np.pi/4, np.pi/2, 3*np.pi/4]:
        fr, fi = gabor(gray, frequency=0.1, theta=theta)
        feats.extend([fr.mean(), fr.std(), fi.mean(), fi.std()])

    g = gray.ravel()
    feats.extend([gray.mean(), gray.std(), gray.min(), gray.max(),
                  float(skew(g)), float(kurtosis(g)),
                  np.median(gray), np.percentile(gray, 25), np.percentile(gray, 75)])

    edges = cv2.Canny(gray, 50, 150)
    feats.extend([edges.mean(), edges.std(), (edges > 0).sum() / edges.size])

    return np.array(feats, dtype=np.float32)


# ============================================================================
# LOAD TEST SET FOR A CLASS
# ============================================================================
def load_test_set(class_id, class_name):
    class_dir = Path(DATASETS_DIR) / f"class_{class_id:02d}_{class_name}"
    img_dir   = class_dir / 'test' / 'images'
    lbl_dir   = class_dir / 'test' / 'labels'

    if not img_dir.exists():
        return None, None, None

    img_files = list(img_dir.glob('*.jpg')) + list(img_dir.glob('*.png'))
    if not img_files:
        return None, None, None

    X, y, meta = [], [], []

    for img_path in img_files:
        lbl_path = lbl_dir / (img_path.stem + '.txt')
        rois = extract_roi_from_image(img_path, lbl_path)

        for roi, label, bbox in rois:
            try:
                feats = extract_features(roi)
                X.append(feats)
                y.append(1 if label == 0 else 0)
                meta.append({
                    'img_path':   str(img_path),
                    'bbox':       bbox,
                    'true_label': 1 if label == 0 else 0,
                    'roi':        roi.copy()
                })
            except:
                continue

    if not X:
        return None, None, None

    return np.array(X), np.array(y), meta


# ============================================================================
# VISUALIZE DETECTIONS ON FULL IMAGE
# ============================================================================
def visualize_detections(class_name, meta, y_true, y_pred, y_proba,
                          out_path, max_images=16):
    """
    Shows full images with colored bounding boxes:
    üü¢ Green solid   = True Positive  (correctly found defect)
    üî¥ Red solid     = False Negative (missed defect)
    üü° Yellow dashed = False Positive (false alarm)
    ‚¨ú Gray          = True Negative  (correctly ignored)
    """
    # Group by image
    imgs_dict = defaultdict(list)
    for i, m in enumerate(meta):
        m = m.copy()
        m['pred_label'] = int(y_pred[i])
        m['confidence'] = float(y_proba[i])
        m['true_label'] = int(y_true[i])
        imgs_dict[m['img_path']].append(m)

    unique_imgs = list(imgs_dict.keys())[:max_images]
    n = len(unique_imgs)
    if n == 0:
        return

    n_cols = min(4, n)
    n_rows = max(1, (n + n_cols - 1) // n_cols)

    fig, axes = plt.subplots(n_rows, n_cols,
                             figsize=(6 * n_cols, 5 * n_rows))
    axes = np.array(axes).flatten()

    tp = int(((y_pred == 1) & (y_true == 1)).sum())
    fp = int(((y_pred == 1) & (y_true == 0)).sum())
    fn = int(((y_pred == 0) & (y_true == 1)).sum())
    tn = int(((y_pred == 0) & (y_true == 0)).sum())

    fig.suptitle(
        f'Test Set Detections: {class_name}\n'
        f'üü¢ TP={tp}  üî¥ FN={fn}  üü° FP={fp}  ‚¨ú TN={tn}  '
        f'|  Acc={accuracy_score(y_true,y_pred):.3f}  '
        f'F1={f1_score(y_true,y_pred,zero_division=0):.3f}  '
        f'Recall={recall_score(y_true,y_pred,zero_division=0):.3f}',
        fontsize=13, fontweight='bold'
    )

    for idx, img_path in enumerate(unique_imgs):
        img = cv2.imread(img_path)
        if img is None:
            axes[idx].axis('off')
            continue

        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        h, w    = img.shape[:2]

        for m in imgs_dict[img_path]:
            x1, y1, x2, y2 = m['bbox']
            tl = m['true_label']
            pl = m['pred_label']
            cf = m['confidence']

            # Color coding
            if tl == 1 and pl == 1:
                # TRUE POSITIVE ‚Äî found it correctly
                color     = (0, 200, 0)
                label_txt = f"‚úì TP {cf:.2f}"
                thickness = 3
                linetype  = cv2.LINE_AA
            elif tl == 1 and pl == 0:
                # FALSE NEGATIVE ‚Äî missed it
                color     = (220, 0, 0)
                label_txt = f"‚úó MISSED {cf:.2f}"
                thickness = 3
                linetype  = cv2.LINE_AA
            elif tl == 0 and pl == 1:
                # FALSE POSITIVE ‚Äî false alarm
                color     = (220, 180, 0)
                label_txt = f"! FP {cf:.2f}"
                thickness = 2
                linetype  = cv2.LINE_AA
            else:
                # TRUE NEGATIVE ‚Äî correctly ignored
                color     = (150, 150, 150)
                label_txt = f"‚Äî TN"
                thickness = 1
                linetype  = cv2.LINE_AA

            cv2.rectangle(img_rgb, (x1, y1), (x2, y2), color, thickness, linetype)

            # Label background
            font       = cv2.FONT_HERSHEY_SIMPLEX
            font_scale = 0.55
            (tw, th), _ = cv2.getTextSize(label_txt, font, font_scale, 2)
            ty = max(th + 6, y1 - 2)
            cv2.rectangle(img_rgb, (x1, ty - th - 6), (x1 + tw + 6, ty), color, -1)
            cv2.putText(img_rgb, label_txt, (x1 + 3, ty - 3),
                        font, font_scale, (255, 255, 255), 2, linetype)

        axes[idx].imshow(img_rgb)
        axes[idx].set_title(Path(img_path).name[:30], fontsize=8)
        axes[idx].axis('off')

    for idx in range(n, len(axes)):
        axes[idx].axis('off')

    plt.tight_layout()
    plt.savefig(out_path, dpi=150, bbox_inches='tight')
    plt.close()


# ============================================================================
# MAIN ‚Äî TEST ALL 15 CLASSES
# ============================================================================
print("=" * 70)
print("STEP 2: TESTING ALL 15 MODELS ON TEST SET")
print("=" * 70)

all_results  = []
skipped      = []

for class_id, class_name in CLASS_NAMES.items():
    model_path = Path(OUTPUT_DIR) / f"class_{class_id:02d}_{class_name}" / "best_model.pkl"

    if not model_path.exists():
        print(f"\n  ‚ùå Class {class_id}: {class_name} ‚Äî model missing")
        continue

    print(f"\n  üîç Class {class_id}: {class_name}")

    # Load model + scaler
    with open(model_path, 'rb') as f:
        pkg = pickle.load(f)
    model     = pkg['model']
    scaler    = pkg['scaler']
    meta_info = pkg['metadata']

    # Load test data
    X_test, y_test, test_meta = load_test_set(class_id, class_name)

    if X_test is None:
        print(f"     ‚ö†Ô∏è  No test images found ‚Äî skipping")
        skipped.append(class_name)
        continue

    n_pos = int(y_test.sum())
    n_neg = int((y_test == 0).sum())
    print(f"     Test samples: {len(X_test)} ({n_pos} positive, {n_neg} negative)")

    if n_pos == 0:
        print(f"     ‚ö†Ô∏è  0 positive samples in test set ‚Äî detection viz will show TN only")

    # Scale + predict
    X_test_s = scaler.transform(X_test)

    t0     = time.time()
    y_pred = model.predict(X_test_s)
    inf_ms = (time.time() - t0) / len(X_test_s) * 1000

    y_proba = (model.predict_proba(X_test_s)[:, 1]
               if hasattr(model, 'predict_proba')
               else y_pred.astype(float))

    # Metrics
    acc  = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred, zero_division=0)
    rec  = recall_score(y_test, y_pred, zero_division=0)
    f1   = f1_score(y_test, y_pred, zero_division=0)
    cm   = confusion_matrix(y_test, y_pred)

    tp = int(cm[1,1]) if cm.shape==(2,2) else 0
    fp = int(cm[0,1]) if cm.shape==(2,2) else 0
    fn = int(cm[1,0]) if cm.shape==(2,2) else 0
    tn = int(cm[0,0]) if cm.shape==(2,2) else 0

    print(f"     Accuracy  : {acc:.4f}  {'‚úÖ' if acc>=0.85 else '‚ö†Ô∏è '}")
    print(f"     F1 Score  : {f1:.4f}  {'‚úÖ' if f1>=0.80 else '‚ö†Ô∏è '}")
    print(f"     Recall    : {rec:.4f}")
    print(f"     Precision : {prec:.4f}")
    print(f"     TP={tp}  FP={fp}  TN={tn}  FN={fn}")
    print(f"     Speed     : {inf_ms:.3f} ms/sample")

    # Save detection visualization
    viz_path = Path(TEST_VIZ_DIR) / f"class_{class_id:02d}_{class_name}_test_detections.png"
    visualize_detections(class_name, test_meta, y_test, y_pred, y_proba, viz_path)
    print(f"     üñºÔ∏è  Detection image saved")

    all_results.append({
        'class_id':    class_id,
        'class_name':  class_name,
        'model_type':  meta_info['model_type'],
        'n_test':      len(X_test),
        'n_positive':  n_pos,
        'n_negative':  n_neg,
        'accuracy':    acc,
        'precision':   prec,
        'recall':      rec,
        'f1_score':    f1,
        'tp': tp, 'fp': fp, 'tn': tn, 'fn': fn,
        'inf_ms':      inf_ms,
    })

# ============================================================================
# SUMMARY
# ============================================================================
print("\n" + "=" * 70)
print("TEST SET SUMMARY")
print("=" * 70)

if skipped:
    print(f"\n  ‚ö†Ô∏è  Skipped (no test images): {', '.join(skipped)}")
    print(f"  These classes will be tested via the inference pipeline on new images\n")

if all_results:
    df = pd.DataFrame(all_results).sort_values('class_id')
    df.to_csv(f'{TEST_VIZ_DIR}/test_set_results.csv', index=False)

    print(f"\n{'ID':>3}  {'Class':<25} {'Acc':>6} {'F1':>6} {'Recall':>7} {'TP':>4} {'FP':>4} {'FN':>4} {'TN':>4}")
    print("-" * 75)
    for _, r in df.iterrows():
        flag = "‚úÖ" if r['f1_score'] >= 0.80 else "‚ö†Ô∏è "
        print(f"  {int(r['class_id']):>2}  {r['class_name']:<25} "
              f"{r['accuracy']:>6.3f} {r['f1_score']:>6.3f} {r['recall']:>7.3f} "
              f"{int(r['tp']):>4} {int(r['fp']):>4} {int(r['fn']):>4} {int(r['tn']):>4}  {flag}")

    print(f"\n  Avg Accuracy : {df['accuracy'].mean():.4f}")
    print(f"  Avg F1 Score : {df['f1_score'].mean():.4f}")
    print(f"  Avg Recall   : {df['recall'].mean():.4f}")

    # Summary chart
    fig, axes = plt.subplots(1, 2, figsize=(16, 7))
    fig.suptitle('Test Set Results ‚Äî All Classes', fontsize=15, fontweight='bold')

    colors = ['#2ECC71' if v >= 0.80 else '#E74C3C' for v in df['f1_score']]
    axes[0].barh(df['class_name'], df['f1_score'], color=colors)
    axes[0].axvline(0.80, color='red', linestyle='--', label='80% target')
    axes[0].set_title('F1 Score on Test Set', fontweight='bold')
    axes[0].set_xlabel('F1 Score')
    axes[0].legend(); axes[0].grid(axis='x', alpha=0.3)
    for i, v in enumerate(df['f1_score']):
        axes[0].text(v + 0.005, i, f'{v:.3f}', va='center', fontsize=9)

    # TP/FP/FN stacked bar
    x = np.arange(len(df))
    axes[1].bar(df['class_name'], df['tp'], label='TP (correct)', color='#2ECC71')
    axes[1].bar(df['class_name'], df['fp'], bottom=df['tp'], label='FP (false alarm)', color='#F39C12')
    axes[1].bar(df['class_name'], df['fn'],
                bottom=df['tp'] + df['fp'], label='FN (missed)', color='#E74C3C')
    axes[1].set_title('TP / FP / FN Breakdown', fontweight='bold')
    axes[1].set_xlabel('Class')
    axes[1].set_ylabel('Count')
    axes[1].tick_params(axis='x', rotation=45)
    axes[1].legend(); axes[1].grid(axis='y', alpha=0.3)

    plt.tight_layout()
    plt.savefig(f'{TEST_VIZ_DIR}/test_set_summary_chart.png', dpi=150, bbox_inches='tight')
    plt.close()
    print(f"\n  üìä Summary chart saved")

print(f"\nüíæ All test results saved to:")
print(f"   {TEST_VIZ_DIR}/")
print(f"   ‚îú‚îÄ‚îÄ test_set_results.csv")
print(f"   ‚îú‚îÄ‚îÄ test_set_summary_chart.png")
print(f"   ‚îî‚îÄ‚îÄ class_XX_*_test_detections.png  (one per class)")
print("\n" + "=" * 70)
print("‚úÖ TEST EVALUATION COMPLETE ‚Äî Review images and share findings!")
print("=" * 70)

"""
================================================================================
DATASET INVENTORY ‚Äî Complete count of images, annotations, splits per class
================================================================================
"""

import os, json
from pathlib import Path
from collections import defaultdict
from google.colab import drive

drive.mount('/content/drive')

DATASETS_DIR = '/content/drive/MyDrive/Road_Defect_Project/02_Per_Class_Datasets'

CLASS_NAMES = {
    0:  'Big_Culvert',        1:  'Blocked_culvert',
    2:  'Cause_ways',         3:  'Crack',
    4:  'Culvert',            5:  'Damaged_surface_layer',
    6:  'Drainage_cover',     7:  'Edge_breaking',
    8:  'Guard_stone',        9:  'Not_painted_gs',
    10: 'Not_whitewashed',    11: 'Patching',
    12: 'Ravelling',          13: 'km_stone',
    14: 'pothole'
}

print("=" * 90)
print("COMPLETE DATASET INVENTORY ‚Äî PER CLASS, PER SPLIT")
print("=" * 90)

grand_total_imgs = 0
grand_total_pos  = 0
grand_total_neg  = 0

for class_id, class_name in CLASS_NAMES.items():
    class_dir = Path(DATASETS_DIR) / f"class_{class_id:02d}_{class_name}"

    print(f"\n{'‚îÄ'*90}")
    print(f"  CLASS {class_id:2d}: {class_name}")
    print(f"{'‚îÄ'*90}")

    class_total_imgs = 0
    class_total_pos  = 0
    class_total_neg  = 0

    for split in ['train', 'valid', 'test']:
        img_dir = class_dir / split / 'images'
        lbl_dir = class_dir / split / 'labels'

        if not img_dir.exists():
            print(f"    {split:6s} ‚Üí ‚ùå folder not found")
            continue

        img_files = list(img_dir.glob('*.jpg')) + list(img_dir.glob('*.png'))
        n_imgs    = len(img_files)

        # Count positive vs negative by checking label files
        n_positive = 0
        n_negative = 0
        n_annotations = 0

        for img_path in img_files:
            lbl_path = lbl_dir / (img_path.stem + '.txt')
            if lbl_path.exists() and lbl_path.stat().st_size > 0:
                with open(lbl_path) as f:
                    lines = [l.strip() for l in f if l.strip()]
                if lines:
                    n_positive    += 1
                    n_annotations += len(lines)
                else:
                    n_negative += 1
            else:
                n_negative += 1

        class_total_imgs += n_imgs
        class_total_pos  += n_positive
        class_total_neg  += n_negative

        print(f"    {split:6s} ‚Üí {n_imgs:4d} images  |  "
              f"‚úÖ {n_positive:4d} positive (has defect)  |  "
              f"‚ùå {n_negative:4d} negative (no defect)  |  "
              f"üìå {n_annotations:4d} annotations")

    grand_total_imgs += class_total_imgs
    grand_total_pos  += class_total_pos
    grand_total_neg  += class_total_neg

    print(f"\n    {'TOTAL':6s} ‚Üí {class_total_imgs:4d} images  |  "
          f"‚úÖ {class_total_pos:4d} positive  |  "
          f"‚ùå {class_total_neg:4d} negative")

print(f"\n{'=' * 90}")
print(f"  GRAND TOTAL ‚Üí {grand_total_imgs} images  |  "
      f"‚úÖ {grand_total_pos} positive  |  ‚ùå {grand_total_neg} negative")
print(f"{'=' * 90}")

# ‚îÄ‚îÄ answer the key question ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
print(f"""
KEY INSIGHT FOR TESTING:
  ‚Ä¢ The test split has only 11 images ‚Äî too few to evaluate properly
  ‚Ä¢ Validation split has hundreds of images per class with real positives
  ‚Ä¢ Validation was used for model SELECTION but NOT for training
  ‚Ä¢ It is perfectly valid to use validation images for visual testing/demo
  ‚Ä¢ For a true held-out test you would need fresh images not in the dataset
""")

#test evaluation

"""
================================================================================
STEP 6: VISUAL DETECTION TEST ‚Äî VALIDATION SET, POSITIVE IMAGES ONLY
================================================================================
- Shows ONLY images that contain the defect (positive samples)
- 16 images per class
- Each image shows the bounding box with detection result
- Green  = model correctly detected the defect ‚úì
- Red    = model missed the defect ‚úó
- Saves one clean PNG per class + master summary to Drive
================================================================================
"""

import subprocess, sys
print("üì¶ Installing packages...")
for pkg in ['lightgbm', 'xgboost', 'catboost', 'scikit-image', 'tqdm']:
    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', pkg])
print("‚úÖ Done\n")

import os, cv2, pickle, json, time, warnings
import numpy as np
import pandas as pd
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from pathlib import Path
from collections import defaultdict
from tqdm.auto import tqdm
warnings.filterwarnings('ignore')

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from skimage.feature import hog, local_binary_pattern
from skimage.filters import gabor
from scipy.stats import skew, kurtosis
from google.colab import drive

# ============================================================================
# SETUP
# ============================================================================
drive.mount('/content/drive')

MODELS_DIR   = '/content/drive/MyDrive/Road_Defect_Project/03_Trained_Models'
DATASETS_DIR = '/content/drive/MyDrive/Road_Defect_Project/02_Per_Class_Datasets'
OUTPUT_DIR   = '/content/drive/MyDrive/Road_Defect_Project/06_Visual_Detection_Test'
os.makedirs(OUTPUT_DIR, exist_ok=True)

CLASS_NAMES = {
    0:  'Big_Culvert',        1:  'Blocked_culvert',
    2:  'Cause_ways',         3:  'Crack',
    4:  'Culvert',            5:  'Damaged_surface_layer',
    6:  'Drainage_cover',     7:  'Edge_breaking',
    8:  'Guard_stone',        9:  'Not_painted_gs',
    10: 'Not_whitewashed',    11: 'Patching',
    12: 'Ravelling',          13: 'km_stone',
    14: 'pothole'
}

TARGET_SIZE    = (128, 128)
IMAGES_PER_CLASS = 16   # show 16 per class

# ============================================================================
# FEATURE EXTRACTION ‚Äî must match training exactly
# ============================================================================
def get_positive_rois(img_path, label_path):
    """Return only the ROIs that ARE the target defect (label == 0 in binary label file)"""
    img = cv2.imread(str(img_path))
    if img is None:
        return []
    h, w = img.shape[:2]
    rois = []
    lp   = Path(label_path)

    if not (lp.exists() and lp.stat().st_size > 0):
        return []

    with open(lp) as f:
        for line in f:
            parts = line.strip().split()
            if len(parts) >= 5 and int(parts[0]) == 0:   # 0 = positive class in binary label
                xc = float(parts[1]) * w
                yc = float(parts[2]) * h
                bw = float(parts[3]) * w
                bh = float(parts[4]) * h
                x1 = int(max(0, xc - bw/2))
                y1 = int(max(0, yc - bh/2))
                x2 = int(min(w, xc + bw/2))
                y2 = int(min(h, yc + bh/2))
                if x2 > x1 and y2 > y1:
                    roi = img[y1:y2, x1:x2]
                    if roi.size > 0:
                        rois.append({
                            'roi':      roi,
                            'bbox':     (x1, y1, x2, y2),
                            'img':      img,
                            'img_path': str(img_path)
                        })
    return rois


def extract_features(roi):
    roi_r = cv2.resize(roi, TARGET_SIZE)
    gray  = cv2.cvtColor(roi_r, cv2.COLOR_BGR2GRAY)
    feats = []

    hog_f = hog(gray, orientations=9, pixels_per_cell=(8,8),
                cells_per_block=(2,2), block_norm='L2-Hys', visualize=False)
    feats.extend(hog_f)

    lbp = local_binary_pattern(gray, 24, 3, method='uniform')
    lbp_h, _ = np.histogram(lbp.ravel(), bins=26, range=(0,26), density=True)
    feats.extend(lbp_h)

    for ch in range(3):
        h = cv2.calcHist([roi_r], [ch], None, [256], [0,256]).flatten()
        feats.extend(h / (h.sum() + 1e-7))

    for theta in [0, np.pi/4, np.pi/2, 3*np.pi/4]:
        fr, fi = gabor(gray, frequency=0.1, theta=theta)
        feats.extend([fr.mean(), fr.std(), fi.mean(), fi.std()])

    g = gray.ravel()
    feats.extend([gray.mean(), gray.std(), gray.min(), gray.max(),
                  float(skew(g)), float(kurtosis(g)),
                  np.median(gray), np.percentile(gray, 25), np.percentile(gray, 75)])

    edges = cv2.Canny(gray, 50, 150)
    feats.extend([edges.mean(), edges.std(), (edges > 0).sum() / edges.size])

    return np.array(feats, dtype=np.float32)


# ============================================================================
# MAIN LOOP
# ============================================================================
print("=" * 70)
print("VISUAL DETECTION TEST ‚Äî POSITIVE IMAGES ONLY (VALIDATION SET)")
print("=" * 70)

summary_rows = []

for class_id, class_name in CLASS_NAMES.items():
    print(f"\n{'‚îÄ'*70}")
    print(f"  CLASS {class_id:2d}: {class_name}")

    model_path = Path(MODELS_DIR) / f"class_{class_id:02d}_{class_name}" / "best_model.pkl"
    class_dir  = Path(DATASETS_DIR) / f"class_{class_id:02d}_{class_name}"
    img_dir    = class_dir / 'valid' / 'images'
    lbl_dir    = class_dir / 'valid' / 'labels'

    if not model_path.exists():
        print(f"  ‚ùå Model not found ‚Äî skipping")
        continue
    if not img_dir.exists():
        print(f"  ‚ùå Validation images not found ‚Äî skipping")
        continue

    # Load model
    with open(model_path, 'rb') as f:
        pkg = pickle.load(f)
    model     = pkg['model']
    scaler    = pkg['scaler']
    model_type = pkg['metadata']['model_type']

    # Collect ALL positive ROIs from validation set
    all_positive_imgs = []
    img_files = list(img_dir.glob('*.jpg')) + list(img_dir.glob('*.png'))

    for img_path in img_files:
        lbl_path = lbl_dir / (img_path.stem + '.txt')
        rois = get_positive_rois(img_path, lbl_path)
        all_positive_imgs.extend(rois)

    if not all_positive_imgs:
        print(f"  ‚ö†Ô∏è  No positive images in validation ‚Äî skipping")
        continue

    print(f"  Found {len(all_positive_imgs)} positive ROIs in validation set")

    # Limit to first 16 unique IMAGES (not ROIs) for clean display
    # Group by image path first, then pick up to 16 images
    by_image = defaultdict(list)
    for item in all_positive_imgs:
        by_image[item['img_path']].append(item)

    selected_imgs = list(by_image.keys())[:IMAGES_PER_CLASS]
    selected_rois = []
    for ip in selected_imgs:
        selected_rois.extend(by_image[ip])

    print(f"  Showing {len(selected_imgs)} images ({len(selected_rois)} ROIs)")

    # Extract features + predict
    X = np.array([extract_features(r['roi']) for r in selected_rois])
    X_s = scaler.transform(X)

    y_pred  = model.predict(X_s)
    y_proba = (model.predict_proba(X_s)[:, 1]
               if hasattr(model, 'predict_proba') else y_pred.astype(float))

    # Attach predictions back
    for i, r in enumerate(selected_rois):
        r['pred']  = int(y_pred[i])
        r['conf']  = float(y_proba[i])

    # Count TP / FN across all positives (not just selected)
    all_X = np.array([extract_features(r['roi']) for r in all_positive_imgs])
    all_X_s = scaler.transform(all_X)
    all_pred = model.predict(all_X_s)
    tp_all = int(all_pred.sum())
    fn_all = len(all_pred) - tp_all
    recall_all = tp_all / len(all_pred) if len(all_pred) > 0 else 0

    print(f"  Full validation positive recall: {tp_all}/{len(all_pred)} = {recall_all:.3f}")

    summary_rows.append({
        'class_id':   class_id,
        'class_name': class_name,
        'model':      model_type,
        'total_positives': len(all_positive_imgs),
        'tp':         tp_all,
        'fn':         fn_all,
        'recall':     recall_all,
    })

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # BUILD VISUALIZATION ‚Äî 4 columns √ó 4 rows = 16 images
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    n_cols = 4
    n_rows = max(1, (len(selected_imgs) + n_cols - 1) // n_cols)

    fig, axes = plt.subplots(n_rows, n_cols,
                             figsize=(6 * n_cols, 5 * n_rows))
    axes = np.array(axes).flatten()

    # Title with stats
    fig.suptitle(
        f'Class {class_id}: {class_name}  [{model_type.upper()}]\n'
        f'Validation Positive Images ‚Äî '
        f'Recall: {tp_all}/{len(all_positive_imgs)} = {recall_all:.1%}  |  '
        f'üü¢ Detected  üî¥ Missed',
        fontsize=14, fontweight='bold', y=1.01
    )

    # Group predictions back by image for drawing
    pred_by_img = defaultdict(list)
    for r in selected_rois:
        pred_by_img[r['img_path']].append(r)

    for idx, img_path in enumerate(selected_imgs):
        img = cv2.imread(img_path)
        if img is None:
            axes[idx].axis('off')
            continue

        img_rgb  = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img_h, img_w = img.shape[:2]

        detected_count = 0
        missed_count   = 0

        for r in pred_by_img[img_path]:
            x1, y1, x2, y2 = r['bbox']
            detected = r['pred'] == 1

            if detected:
                color = (0, 200, 0)       # Green ‚Äî found it
                icon  = '‚úì'
                detected_count += 1
            else:
                color = (220, 30, 30)     # Red ‚Äî missed
                icon  = '‚úó'
                missed_count += 1

            # Draw box
            cv2.rectangle(img_rgb, (x1, y1), (x2, y2), color, 3)

            # Label with confidence
            label = f"{icon} {r['conf']:.2f}"
            font  = cv2.FONT_HERSHEY_SIMPLEX
            fscale = 0.6
            thickness = 2
            (tw, th), _ = cv2.getTextSize(label, font, fscale, thickness)
            # Background bar
            ty = max(th + 8, y1 - 2)
            cv2.rectangle(img_rgb,
                          (x1, ty - th - 8),
                          (x1 + tw + 8, ty),
                          color, -1)
            cv2.putText(img_rgb, label,
                        (x1 + 4, ty - 4),
                        font, fscale, (255, 255, 255), thickness)

        axes[idx].imshow(img_rgb)

        # Subplot title: image name + result
        result_str = ""
        if detected_count > 0 and missed_count == 0:
            result_str = f"‚úÖ All {detected_count} detected"
        elif missed_count > 0 and detected_count == 0:
            result_str = f"‚ùå All {missed_count} missed"
        else:
            result_str = f"‚úÖ{detected_count} ‚ùå{missed_count}"

        axes[idx].set_title(
            f"{Path(img_path).name[:22]}\n{result_str}",
            fontsize=8, fontweight='bold'
        )
        axes[idx].axis('off')

    # Hide unused subplots
    for idx in range(len(selected_imgs), len(axes)):
        axes[idx].axis('off')

    plt.tight_layout()
    out_path = Path(OUTPUT_DIR) / f"class_{class_id:02d}_{class_name}.png"
    plt.savefig(out_path, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"  üíæ Saved: class_{class_id:02d}_{class_name}.png")

# ============================================================================
# MASTER SUMMARY
# ============================================================================
print("\n" + "=" * 70)
print("MASTER SUMMARY")
print("=" * 70)

df = pd.DataFrame(summary_rows).sort_values('class_id')
df.to_csv(f'{OUTPUT_DIR}/visual_test_summary.csv', index=False)

print(f"\n{'ID':>3}  {'Class':<25} {'Model':<12} {'Pos':>5} {'TP':>5} {'FN':>5} {'Recall':>8}")
print("-" * 65)
for _, r in df.iterrows():
    flag = "‚úÖ" if r['recall'] >= 0.90 else "‚ö†Ô∏è "
    print(f"  {int(r['class_id']):>2}  {r['class_name']:<25} {r['model']:<12} "
          f"{int(r['total_positives']):>5} {int(r['tp']):>5} {int(r['fn']):>5} "
          f"{r['recall']:>8.3f}  {flag}")

print(f"\n  Avg Recall: {df['recall'].mean():.4f}")
print(f"  Classes ‚â• 90% recall: {(df['recall'] >= 0.90).sum()}/{len(df)}")

# Summary chart
fig, ax = plt.subplots(figsize=(12, 8))
colors = ['#2ECC71' if v >= 0.90 else '#E74C3C' for v in df['recall']]
bars = ax.barh(df['class_name'], df['recall'], color=colors)
ax.axvline(0.90, color='red', linestyle='--', linewidth=2, label='90% target')
for bar, val in zip(bars, df['recall']):
    ax.text(min(val + 0.005, 1.02), bar.get_y() + bar.get_height()/2,
            f'{val:.3f}', va='center', fontsize=10, fontweight='bold')
ax.set_xlim(0, 1.12)
ax.set_xlabel('Recall on Positive Validation Images', fontsize=12)
ax.set_title('Detection Recall ‚Äî All 15 Classes\n(Validation Positive Images Only)',
             fontsize=14, fontweight='bold')
ax.legend(fontsize=11)
ax.grid(axis='x', alpha=0.3)
plt.tight_layout()
plt.savefig(f'{OUTPUT_DIR}/recall_summary_chart.png', dpi=150, bbox_inches='tight')
plt.close()

print(f"\nüíæ All outputs saved to:")
print(f"   {OUTPUT_DIR}/")
print(f"   ‚îú‚îÄ‚îÄ recall_summary_chart.png")
print(f"   ‚îú‚îÄ‚îÄ visual_test_summary.csv")
print(f"   ‚îî‚îÄ‚îÄ class_XX_<name>.png  ‚Üê 15 detection images")
print("\n" + "=" * 70)
print("‚úÖ VISUAL TEST COMPLETE ‚Äî Check the images in Drive!")
print("=" * 70)

#hog

"""
================================================================================
STEP 7b: TEST SLIDING WINDOW ON DATASET IMAGES
================================================================================
- Picks sample images from our validation set (images with known defects)
- Runs sliding window detector on them
- Compares: Ground Truth boxes vs Detected boxes side by side
- Green box  = Ground truth (where defect actually is)
- Blue box   = What our sliding window detected
- Shows how well the detector finds the right location
================================================================================
"""

import subprocess, sys
print("üì¶ Installing packages...")
for pkg in ['lightgbm', 'xgboost', 'catboost', 'scikit-image', 'tqdm']:
    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', pkg])
print("‚úÖ Done\n")

import os, cv2, pickle, time, warnings
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from pathlib import Path
from collections import defaultdict
warnings.filterwarnings('ignore')

from skimage.feature import hog, local_binary_pattern
from skimage.filters import gabor
from scipy.stats import skew, kurtosis
from google.colab import drive

drive.mount('/content/drive')

MODELS_DIR   = '/content/drive/MyDrive/Road_Defect_Project/03_Trained_Models'
DATASETS_DIR = '/content/drive/MyDrive/Road_Defect_Project/02_Per_Class_Datasets'
OUTPUT_DIR   = '/content/drive/MyDrive/Road_Defect_Project/07_Sliding_Window_Results'
os.makedirs(OUTPUT_DIR, exist_ok=True)

CLASS_NAMES = {
    0:  'Big_Culvert',        1:  'Blocked_culvert',
    2:  'Cause_ways',         3:  'Crack',
    4:  'Culvert',            5:  'Damaged_surface_layer',
    6:  'Drainage_cover',     7:  'Edge_breaking',
    8:  'Guard_stone',        9:  'Not_painted_gs',
    10: 'Not_whitewashed',    11: 'Patching',
    12: 'Ravelling',          13: 'km_stone',
    14: 'pothole'
}

# Distinct color per class (BGR)
CLASS_COLORS = {
    0:  (255,100,0),   1:  (255,0,100),   2:  (0,200,100),
    3:  (0,0,255),     4:  (200,0,200),   5:  (0,165,255),
    6:  (0,255,255),   7:  (50,205,50),   8:  (255,215,0),
    9:  (128,0,255),   10: (255,128,0),   11: (0,128,255),
    12: (255,0,0),     13: (0,255,128),   14: (30,144,255)
}

TARGET_SIZE = (128, 128)

# ============================================================================
# SLIDING WINDOW SETTINGS
# ============================================================================
WINDOW_SIZES   = [128, 192, 256]
STEP_SIZE      = 64
CONF_THRESHOLD = 0.70
NMS_THRESHOLD  = 0.30

# How many sample images to test per class
SAMPLES_PER_CLASS = 3

# ============================================================================
# LOAD ALL 15 MODELS
# ============================================================================
def load_all_models():
    print("üìÇ Loading all 15 models...")
    models = {}
    for class_id, class_name in CLASS_NAMES.items():
        path = Path(MODELS_DIR) / f"class_{class_id:02d}_{class_name}" / "best_model.pkl"
        if path.exists():
            with open(path, 'rb') as f:
                pkg = pickle.load(f)
            models[class_id] = {
                'model':      pkg['model'],
                'scaler':     pkg['scaler'],
                'class_name': class_name,
            }
    print(f"  ‚úÖ Loaded {len(models)}/15 models\n")
    return models


# ============================================================================
# FEATURE EXTRACTION
# ============================================================================
def extract_features(roi):
    roi_r = cv2.resize(roi, TARGET_SIZE)
    gray  = cv2.cvtColor(roi_r, cv2.COLOR_BGR2GRAY)
    feats = []

    hog_f = hog(gray, orientations=9, pixels_per_cell=(8,8),
                cells_per_block=(2,2), block_norm='L2-Hys', visualize=False)
    feats.extend(hog_f)

    lbp = local_binary_pattern(gray, 24, 3, method='uniform')
    lbp_h, _ = np.histogram(lbp.ravel(), bins=26, range=(0,26), density=True)
    feats.extend(lbp_h)

    for ch in range(3):
        h = cv2.calcHist([roi_r], [ch], None, [256], [0,256]).flatten()
        feats.extend(h / (h.sum() + 1e-7))

    for theta in [0, np.pi/4, np.pi/2, 3*np.pi/4]:
        fr, fi = gabor(gray, frequency=0.1, theta=theta)
        feats.extend([fr.mean(), fr.std(), fi.mean(), fi.std()])

    g = gray.ravel()
    feats.extend([gray.mean(), gray.std(), gray.min(), gray.max(),
                  float(skew(g)), float(kurtosis(g)),
                  np.median(gray), np.percentile(gray, 25), np.percentile(gray, 75)])

    edges = cv2.Canny(gray, 50, 150)
    feats.extend([edges.mean(), edges.std(), (edges > 0).sum() / edges.size])

    return np.array(feats, dtype=np.float32)


# ============================================================================
# NMS
# ============================================================================
def nms(detections, iou_threshold=0.30):
    if not detections:
        return []

    by_class = {}
    for d in detections:
        by_class.setdefault(d[4], []).append(d)

    final = []
    for cid, dets in by_class.items():
        boxes  = np.array([[d[0],d[1],d[2],d[3]] for d in dets], dtype=np.float32)
        scores = np.array([d[5] for d in dets], dtype=np.float32)
        x1,y1,x2,y2 = boxes[:,0],boxes[:,1],boxes[:,2],boxes[:,3]
        areas  = (x2-x1)*(y2-y1)
        order  = scores.argsort()[::-1]
        keep   = []

        while order.size > 0:
            i = order[0]; keep.append(i)
            xx1 = np.maximum(x1[i], x1[order[1:]])
            yy1 = np.maximum(y1[i], y1[order[1:]])
            xx2 = np.minimum(x2[i], x2[order[1:]])
            yy2 = np.minimum(y2[i], y2[order[1:]])
            w   = np.maximum(0, xx2-xx1)
            h   = np.maximum(0, yy2-yy1)
            iou = (w*h) / (areas[i] + areas[order[1:]] - w*h + 1e-7)
            order = order[np.where(iou <= iou_threshold)[0] + 1]

        for k in keep:
            final.append(dets[k])
    return final


# ============================================================================
# SLIDING WINDOW DETECTION ON ONE IMAGE
# ============================================================================
def detect_image(img, models):
    h, w = img.shape[:2]
    windows = []

    for win_size in WINDOW_SIZES:
        for y in range(0, h - win_size + 1, STEP_SIZE):
            for x in range(0, w - win_size + 1, STEP_SIZE):
                roi = img[y:y+win_size, x:x+win_size]
                if roi.size > 0:
                    windows.append((x, y, x+win_size, y+win_size, roi))

    if not windows:
        return []

    X = np.array([extract_features(w[4]) for w in windows])

    raw = []
    for class_id, m in models.items():
        try:
            X_s   = m['scaler'].transform(X)
            proba = m['model'].predict_proba(X_s)[:, 1]
            for i, (x1,y1,x2,y2,_) in enumerate(windows):
                if proba[i] >= CONF_THRESHOLD:
                    raw.append((x1,y1,x2,y2, class_id, float(proba[i])))
        except:
            continue

    return nms(raw, NMS_THRESHOLD)


# ============================================================================
# READ GROUND TRUTH BOXES FROM YOLO LABEL FILE
# ============================================================================
def read_ground_truth(img_path, label_path, original_class_id):
    """
    In the per-class binary dataset:
    label 0 = positive (target defect)
    We map label 0 back to the original class_id for display
    """
    img = cv2.imread(str(img_path))
    if img is None:
        return [], img
    h, w = img.shape[:2]
    boxes = []

    lp = Path(label_path)
    if lp.exists() and lp.stat().st_size > 0:
        with open(lp) as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) >= 5 and int(parts[0]) == 0:
                    xc = float(parts[1]) * w
                    yc = float(parts[2]) * h
                    bw = float(parts[3]) * w
                    bh = float(parts[4]) * h
                    x1 = int(max(0, xc - bw/2))
                    y1 = int(max(0, yc - bh/2))
                    x2 = int(min(w, xc + bw/2))
                    y2 = int(min(h, yc + bh/2))
                    if x2 > x1 and y2 > y1:
                        boxes.append((x1, y1, x2, y2))
    return boxes, img


# ============================================================================
# MAIN ‚Äî TEST ON DATASET IMAGES
# ============================================================================
print("=" * 70)
print("SLIDING WINDOW TEST ON DATASET VALIDATION IMAGES")
print("=" * 70)

models = load_all_models()

all_class_results = []

for class_id, class_name in CLASS_NAMES.items():
    img_dir = Path(DATASETS_DIR) / f"class_{class_id:02d}_{class_name}" / 'valid' / 'images'
    lbl_dir = Path(DATASETS_DIR) / f"class_{class_id:02d}_{class_name}" / 'valid' / 'labels'

    if not img_dir.exists():
        continue

    # Get positive images only (images that have this defect)
    img_files = list(img_dir.glob('*.jpg')) + list(img_dir.glob('*.png'))
    positive_imgs = []
    for ip in img_files:
        lp = lbl_dir / (ip.stem + '.txt')
        if lp.exists() and lp.stat().st_size > 0:
            positive_imgs.append(ip)

    if not positive_imgs:
        continue

    # Pick SAMPLES_PER_CLASS images
    samples = positive_imgs[:SAMPLES_PER_CLASS]

    print(f"\n{'‚îÄ'*70}")
    print(f"  CLASS {class_id:2d}: {class_name}  ({len(positive_imgs)} positive val images available)")

    class_detected = 0
    class_total    = 0

    # Build figure: 3 images √ó 2 columns (original | detected)
    n_samples = len(samples)
    fig, axes = plt.subplots(n_samples, 2,
                             figsize=(14, 5 * n_samples))
    if n_samples == 1:
        axes = axes[np.newaxis, :]

    fig.suptitle(
        f'Class {class_id}: {class_name} ‚Äî Sliding Window Detection\n'
        f'üü¢ Ground Truth Box   üîµ Detected by Model',
        fontsize=13, fontweight='bold'
    )

    for row, img_path in enumerate(samples):
        lbl_path = lbl_dir / (img_path.stem + '.txt')

        # Ground truth
        gt_boxes, img = read_ground_truth(img_path, lbl_path, class_id)
        class_total += len(gt_boxes)

        # Run detector
        t0 = time.time()
        detections = detect_image(img, models)
        elapsed = time.time() - t0

        # Count how many GT boxes were "hit" by a detection of correct class
        hits = 0
        color_map = CLASS_COLORS.get(class_id, (255,255,255))

        for gt in gt_boxes:
            gx1,gy1,gx2,gy2 = gt
            for d in detections:
                if d[4] == class_id:
                    # Check IoU > 0.1 (loose ‚Äî just checking if detector found the right area)
                    ix1 = max(gx1, d[0]); iy1 = max(gy1, d[1])
                    ix2 = min(gx2, d[2]); iy2 = min(gy2, d[3])
                    iw  = max(0, ix2-ix1); ih = max(0, iy2-iy1)
                    inter = iw * ih
                    union = ((gx2-gx1)*(gy2-gy1) +
                             (d[2]-d[0])*(d[3]-d[1]) - inter)
                    if union > 0 and inter/union > 0.10:
                        hits += 1
                        break
        class_detected += hits

        # ‚îÄ‚îÄ LEFT: Original + Ground Truth ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        left = cv2.cvtColor(img.copy(), cv2.COLOR_BGR2RGB)
        for (x1,y1,x2,y2) in gt_boxes:
            cv2.rectangle(left, (x1,y1),(x2,y2), (0,200,0), 3)
            cv2.putText(left, f'GT: {class_name}',
                        (x1, max(20,y1-6)),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,200,0), 2)

        axes[row, 0].imshow(left)
        axes[row, 0].set_title(
            f'Ground Truth  |  {img_path.name[:30]}',
            fontsize=9, fontweight='bold'
        )
        axes[row, 0].axis('off')

        # ‚îÄ‚îÄ RIGHT: Detected boxes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        right = cv2.cvtColor(img.copy(), cv2.COLOR_BGR2RGB)

        # Also draw GT lightly for reference
        for (x1,y1,x2,y2) in gt_boxes:
            cv2.rectangle(right, (x1,y1),(x2,y2), (0,200,0), 2)

        det_count = 0
        for d in detections:
            dx1,dy1,dx2,dy2 = d[0],d[1],d[2],d[3]
            dc = CLASS_COLORS.get(d[4], (255,255,0))
            dc_rgb = (dc[2], dc[1], dc[0])   # BGR‚ÜíRGB
            cv2.rectangle(right, (dx1,dy1),(dx2,dy2), dc_rgb, 3)
            lbl = f"{d[5]:.2f} {CLASS_NAMES[d[4]]}"
            cv2.putText(right, lbl, (dx1, max(20,dy1-6)),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, dc_rgb, 2)
            det_count += 1

        hit_str = f"‚úÖ {hits}/{len(gt_boxes)} GT hit" if hits==len(gt_boxes) else f"‚ö†Ô∏è {hits}/{len(gt_boxes)} GT hit"
        axes[row, 1].imshow(right)
        axes[row, 1].set_title(
            f'Detected: {det_count} box(es)  |  {hit_str}  |  {elapsed:.1f}s',
            fontsize=9, fontweight='bold'
        )
        axes[row, 1].axis('off')

        print(f"    {img_path.name[:35]:<35} GT={len(gt_boxes)}  "
              f"Det={det_count}  Hit={hits}  {elapsed:.1f}s")

    plt.tight_layout()
    out_path = Path(OUTPUT_DIR) / f"sw_test_{class_id:02d}_{class_name}.png"
    plt.savefig(str(out_path), dpi=130, bbox_inches='tight')
    plt.close()

    recall = class_detected / class_total if class_total > 0 else 0
    print(f"    ‚Üí Hit {class_detected}/{class_total} GT boxes  |  Recall={recall:.2f}")
    print(f"    üíæ Saved: sw_test_{class_id:02d}_{class_name}.png")

    all_class_results.append({
        'class_id':   class_id,
        'class_name': class_name,
        'gt_boxes':   class_total,
        'hits':       class_detected,
        'recall':     recall
    })

# ============================================================================
# SUMMARY
# ============================================================================
print("\n" + "=" * 70)
print("SLIDING WINDOW TEST SUMMARY")
print("=" * 70)

import pandas as pd
df = pd.DataFrame(all_class_results).sort_values('class_id')

print(f"\n{'ID':>3}  {'Class':<25} {'GT Boxes':>9} {'Hits':>6} {'Recall':>8}")
print("-" * 55)
for _, r in df.iterrows():
    flag = "‚úÖ" if r['recall'] >= 0.50 else "‚ö†Ô∏è "
    print(f"  {int(r['class_id']):>2}  {r['class_name']:<25} "
          f"{int(r['gt_boxes']):>9} {int(r['hits']):>6} "
          f"{r['recall']:>8.3f}  {flag}")

print(f"\n  Avg Recall (localization): {df['recall'].mean():.3f}")
print(f"\n  ‚ö†Ô∏è  NOTE: Recall here means how many GT boxes the sliding")
print(f"  window found at the right location (IoU > 0.10).")
print(f"  This is harder than classification ‚Äî detector must find")
print(f"  the right location AND classify correctly.")

print(f"\nüíæ Results saved to: {OUTPUT_DIR}")
print("=" * 70)
print("‚úÖ DONE! Review images in Drive to see Ground Truth vs Detected boxes")
print("=" * 70)

